{"pub": "theverge", "url": "https://theverge.com/2019/10/15/20914575/openai-dactyl-robotic-hand-rubiks-cube-one-handed-solve-dexterity-ai", "downloaded_at": "2019-10-15 16:22:45.329695+00:00", "title": "OpenAI\u2019s AI-powered robot learned how to solve a Rubik\u2019s cube one-handed", "language": "en", "text": "Artificial intelligence research organization OpenAI has achieved a new milestone in its quest to build general purpose, self-learning robots. The group\u2019s robotics division says Dactyl, its humanoid robotic hand first developed last year, has learned to solve a Rubik\u2019s cube one-handed. OpenAI sees the feat as a leap forward both for the dexterity of robotic appendages and its own AI software, which allows Dactyl to learn new tasks using virtual simulations before it is presented with a real, physical challenge to overcome.\n\nIn a demonstration video showcasing Dactyl\u2019s new talent, we can see the robotic hand fumble its way toward a complete cube solve with clumsy yet accurate maneuvers. It takes many minutes, but Dactyl is eventually able to solve the puzzle. It\u2019s somewhat unsettling to see in action, if only because the movements look noticeably less fluid than human ones and especially disjointed when compared to the blinding speed and raw dexterity on display when a human speedcuber solves the cube in a matter of seconds.\n\nBut for OpenAI, Dactyl\u2019s achievement brings it one step closer to a much sought-after goal for the broader AI and robotics industries: a robot that can learn to perform a variety of real-world tasks, without having to train for months to years of real-world time and without needing to be specifically programmed.\n\n\u201cPlenty of robots can solve Rubik\u2019s cubes very fast. The important difference between what they did there and what we\u2019re doing here is that those robots are very purpose-built,\u201d says Peter Welinder, a research scientist and robotics lead at OpenAI. \u201cObviously there\u2019s no way you can use the same robot or same approach to perform another task. The robotics team at OpenAI have very different ambitions. We\u2019re trying to build a general purpose robot. Similar to how humans and how our human hands can do a lot of things, not just a specific task, we\u2019re trying to build something that is much more general in its scope.\u201d\n\nWelinder is referencing a series of robots over the last few years that have pushed Rubik\u2019s cube solving far beyond the limitations of human hands and minds. In 2016, semiconductor maker Infineon developed a robot specifically to solve a Rubik\u2019s cube at superhuman speeds, and the bot managed to do so in under one second. That crushed the sub-five-second human world record at the time. Two years later, a machine developed by MIT solved a cube in less than 0.4 seconds. In late 2018, a Japanese YouTube channel called Human Controller even developed its own self-solving Rubik\u2019s cube using a 3D-printed core attached to programmable servo motors.\n\nMachines have been able to solve the Rubik\u2019s cube at superhuman speeds for years\n\nIn other words, a robot built for one specific task and programmed to perform that task as efficiently as possible can typically best a human, and Rubik\u2019s cube solving is something software has long ago mastered. So developing a robot to solve the cube, even a humanoid one, is not all that remarkable on its own, and less so at the sluggish speed Dactyl operates.\n\nBut OpenAI\u2019s Dactyl robot and the software that powers it are much different in design and purpose than a dedicated cube-solving machine. As Welinder says, OpenAI\u2019s ongoing robotics work is not aimed at achieving superior results in narrow tasks, as that only requires you develop a better robot and program it accordingly. That can be done without modern artificial intelligence.\n\nInstead, Dactyl is developed from the ground up as a self-learning robotic hand that approaches new tasks much like a human would. It\u2019s trained using software that tries, in a rudimentary way at the moment, to replicate the millions of years of evolution that help us learn to use our hands instinctively as children. That could one day, OpenAI hopes, help humanity develop the kinds of humanoid robots we know only from science fiction, robots that can safely operate in society without endangering us and perform a wide variety of tasks in environments as chaotic as city streets and factory floors.\n\nTo learn how to solve a Rubik\u2019s cube one-handed, OpenAI did not explicitly program Dactyl to solve the toy; free software on the internet can do that for you. It also chose not to program individual motions for the hand to perform, as it wanted it to discern those movements on its own. Instead, the robotics team gave the hand\u2019s underlying software the end goal of solving a scrambled cube and used modern AI \u2014 specifically a brand of incentive-based deep learning called reinforcement learning \u2014 to help it along the path toward figuring it out on its own. The same approach to training AI agents is how OpenAI developed its world-class Dota 2 bot.\n\nBut until recently, it\u2019s been much easier to train an AI agent to do something virtually \u2014 playing a computer game, for example \u2014 than to train it to perform a real-world task. That\u2019s because training software to do something in a virtual world can be sped up, so that the AI can spend the equivalent of tens of thousands of years training in just months of real-world time, thanks to thousands of high-end CPUs and ultra-powerful GPUs working in parallel.\n\nDoing that same level of training performing a physical task with a physical robot isn\u2019t feasible. That\u2019s why OpenAI is trying to pioneer new methods of robotic training using simulated environments in place of the real world, something the robotics industry has only barely experimented with. That way, the software can practice extensively at an accelerated pace across many different computers simultaneously, with the hope that it retains that knowledge when it begins controlling a real robot.\n\nOpenAI\u2019s Dactyl robotic hand is powered by AI software\n\nBecause of the training limitation and obvious safety concerns, robots used commercially today do not utilize AI and instead are programmed with very specific instructions. \u201cThe way it\u2019s been approached in the past is that you use very specialized algorithms to solve tasks, where you have an accurate model of both the robot and the environment in which you\u2019re operating,\u201d Welinder says. \u201cFor a factory robot, you have very accurate models of those and you know exactly the environment you\u2019re working on. You know exactly how it will be picking up the particular part.\u201d\n\nThis is also why current robots are far less versatile than humans. It requires large amounts of time, effort, and money to reprogram a robot that assembles, say, one specific part of an automobile or a computer component to do something else. Present a robot that hasn\u2019t been properly trained with even a simple task that involves any level of human dexterity or visual processing and it would fail miserably. With modern AI techniques, however, robots could be modeled like humans, so that they can use the same intuitive understanding of the world to do everything from opening doors to frying an egg. At least, that\u2019s the dream.\n\nWe\u2019re still decades away from that level of sophistication, and the leaps the AI community has made on the software side \u2014 like self-driving cars, machine translation, and image recognition \u2014 has not exactly translated to next-generation robots. Right now, OpenAI is just trying to mimic the complexity of one human body part and to get that robotic analog to operate more naturally.\n\nThat\u2019s why Dactyl is a 24-joint robotic hand modeled after a human hand, instead of the claw or pincer style robotic grippers you see in factories. And for the software that powers Dactyl to learn how to utilize all of those joints in a way a human would, OpenAI put it through thousands of years of training in simulation before trying the physical cube solve.\n\n\u201cIf you\u2019re training things on the real world robot, obviously whatever you\u2019re learning is working on what you actually want to deploy your algorithm on. In that way, it\u2019s much simpler. But algorithms today need a lot of data. To train a real world robot, to do anything complex, you need many years of experience,\u201d Welinder says. \u201cEven for a human, it takes a couple of years, and humans have millions of years of evolution to have the learning capabilities to operate a hand.\u201d\n\nIn a simulation, however, Welinder says training can be accelerated, just like with game-playing and other tasks popular as AI benchmarks. \u201cThis takes on the order of thousands of years to train the algorithm. But this only takes a few days because we can parallelize the training. You also don\u2019t have to worry about the robots breaking or hurting someone as you\u2019re training these algorithms,\u201d he adds. Yet researchers have in the past has run into considerable trouble trying to get virtual training to work on physical robots. OpenAI says it is among the first organizations to really see progress in this regard.\n\nWhen it was given a real cube, Dactyl put its training to use and solved it on its own, and it did so under a variety of conditions it had never been explicitly trained for. That includes solving the cube one-handed with a glove on, with two of its fingers taped together, and while OpenAI members continuously interfered with it by poking it with other objects and showering it with bubbles and pieces of confetti-like paper.\n\nOpenAI trained Dactyl for thousands of years using simulation before testing its skills in the real world\n\n\u201cWe found that in all of those perturbations, the robot was still able to successfully turn the Rubik\u2019s cube. But it did not go through that in training,\u201d says Matthias Plappert, Welinder\u2019s fellow OpenAI\u2019s robotic team lead. \u201cThe robustness that we found when we tried this on the physical robot was surprising to us.\u201d\n\nThat\u2019s why OpenAI sees Dactyl\u2019s newly acquired skill as equally important for both the advancement of robotic hardware and AI training. Even the most advanced robots in the world right, like the humanoid and dog-like bots developed by industry leader Boston Dynamics, cannot operate autonomously, and they require extensive task-specific programming and frequent human intervention to carry out even basic actions.\n\nOpenAI says Dactyl is a small but vital step toward the kind of robots that might one day perform manual labor or household tasks and even work alongside humans, instead of in closed-off environments, without any explicit programming governing their actions.\n\nIn that vision for the future, the ability for robots to learn new tasks and adapt to changing environments will be as much about the flexibility of the AI as it is about the robustness of the physical machine. \u201cThese methods are really starting to demonstrate that these are the solutions to handling all the inherent complication and the messiness of the physical world we live in,\u201d Plappert says.", "description": "Artificial intelligence research organization OpenAI has achieved a new milestone in its quest to build general purpose, self-learning robots. The group\u2019s robotics division says that Dactyl, its humanoid robotic hand first developed last year, has learned to solve a Rubik\u2019s cube one-handed.", "authors": ["Nick Statt", "Oct"], "top_image": "https://cdn.vox-cdn.com/thumbor/kmHg0aintkNE44GNGm-18mtXTIc=/0x144:2000x1191/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/19287241/openai_dactyl_one_handed_solve.jpeg", "published_at": "2019-10-15"}