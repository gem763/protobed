{"pub": "guardian", "url": "https://theguardian.com/society/2019/oct/25/healthcare-algorithm-racial-biases-optum", "downloaded_at": "2019-10-25 16:24:47.616383+00:00", "title": "Healthcare algorithm used across America has dramatic racial biases", "language": "en", "text": "System sold by Optum estimates health needs based on medical costs, which are much less than for white patients, report finds\n\nAn algorithm used to manage the healthcare of millions of Americans shows dramatic biases against black patients, a new study has found.\n\nHospitals around the United States use the system sold by Optum, a UnitedHealth Group-owned service, to determine which patients have the most intensive healthcare needs over time. But the algorithm, which has been applied to more than 200 million people each year, significantly underestimates the amount of care black patients need compared with white patients, research published on Friday in Science magazine found.\n\nWhy being pregnant while black can seriously damage your health | Miriam Zoila P\u00e9rez Read more\n\nAlthough the algorithm did not explicitly apply racial identification to patients, it still played out racial biases in effect. That\u2019s because the parameter the algorithm used to signify health \u2013 cost of care \u2013 had racial biases baked into it.\n\nLess money is spent on black patients with the same level of need as white patients, causing the algorithm to conclude that black patients were less sick, the researchers found. The study showed black patients incurred about $1,800 in medical costs each year less than white patients at the same level of illness.\n\nReformulating these biases in the algorithm would more than double the number of black patients flagged for additional care, the study showed. In fact, when the company replicated the analysis on a different data set, they found black patients actually had 48,772 more active chronic conditions than white patients who had been ranked at the same level of risk.\n\nBiases like these are inadvertently built into the technology we use at many different stages, said Ruha Benjamin, author of Race After Technology and associate professor of African American studies at Princeton University.\n\n\u201cPre-existing social processes shape data collection, algorithm design and even the formulation of problems that need addressing by technology,\u201d she said.\n\nSuch algorithms are used to determine which patients could benefit from additional care like monitoring overall health and managing prescription use or doctor visits. The researchers are working with Optum on a fix.\n\nWhen researchers tweaked the algorithm to make predictions about patients\u2019 future health conditions rather than which patients would incur the highest costs, it reduced biases by 84%. \u201cThese results suggest that label biases are fixable,\u201d the study said.\n\nMeanwhile, Optummaintains its system helps \u201cclinicians provide more effective patient care every day\u201d.\n\n\u201cPredictive algorithms that power these tools should be continually reviewed and refined, and supplemented by information such as socio-economic data, to help clinicians make the best-informed care decisions for each patient,\u201d an Optum spokesman, Tyler Mason, said. \u201cAs we advise our customers, these tools should never be viewed as a substitute for a doctor\u2019s expertise and knowledge of their patients\u2019 individual needs.\u201d\n\nAlthough this study was conducted on just one healthcare system algorithm, the researchers suggested similar biases probably exist across a number of industries. As algorithms are increasingly used for job recruiting, housing loans and policing, Benjamin noted that more legislation is needed to ensure algorithms take into consideration historical biases.\n\n\u201cThe design of different kinds of systems, whether we\u2019re talking about legal systems or computer systems, can create and reinforce hierarchies precisely because the people who create them are not thinking about how social norms and structures shape their work,\u201d she said. \u201cIndifference to social reality is, perhaps, more dangerous than outright bigotry.\u201d", "description": "System sold by Optum estimates health needs based on medical costs, which are much less than for white patients, report finds", "authors": ["Kari Paul"], "top_image": "https://i.guim.co.uk/img/media/866aa965a215e67f3ee2e2367c3be2b0bf3891e8/0_20_4800_2880/master/4800.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=319987c6a11dce8ccf821fdc0af19610", "published_at": "2019-10-25"}