{"pub": "guardian", "url": "https://theguardian.com/technology/2019/oct/09/children-interested-in-gambling-and-alcohol-facebook", "downloaded_at": "2019-10-09 18:46:42.372107+00:00", "title": "Children 'interested in' gambling and alcohol, according to Facebook", "language": "en", "text": "Facebook has marked hundreds of thousands of children as \u201cinterested in\u201d adverts about gambling and alcohol, a joint investigation by the Guardian and the Danish Broadcasting Corporation has found.\n\nThe social network\u2019s advertising tools reveal 740,000 children under the age of 18 are flagged as being interested in gambling, including 130,000 in the UK. Some 940,000 minors \u2013 150,000 of whom are British \u2013 are flagged as being interested in alcoholic beverages.\n\nThese \u201cinterests\u201d are automatically generated by Facebook, based on what it has learned about a user by monitoring their activity on the social network. Advertisers can then use them to specifically target messages to subgroups who have been flagged as interested in the topic.\n\nIn a statement, Facebook said: \u201cWe don\u2019t allow ads that promote the sale of alcohol or gambling to minors on Facebook and we enforce against this activity when we find it. We also work closely with regulators to provide guidance for marketers to help them reach their audiences effectively and responsibly.\u201d\n\nThe company does allow advertisers to specifically target messages to children based on their interest in alcohol or gambling. A Facebook insider gave the example of an anti-gambling service that may want to reach out to children who potentially have a gambling problem and offer them help and support.\n\nBut advertisers can target the interests for other purposes as well. The developers of an exploitative video game with profitable \u201cloot box\u201d mechanics, for instance, could target their adverts to children with an interest in gambling without breaching any of Facebook\u2019s regulations.\n\nThe presence of automated interests also means that alcohol and gambling advertisers who do try to avoid Facebook\u2019s rules about advertising to children have an audience already selected for them by the social network. Facebook relies primarily on automated review for flagging adverts that break its policies. But the automated review is not guaranteed to find breaches before the adverts start to run. Facebook recently settled a lawsuit with the financial expert Martin Lewis over the company\u2019s long-term failure to keep his image out of scam adverts.\n\nFacebook\u2019s automatic categorisation of users has been criticised before. In May 2018, the social network was found to be targeting users it thought were interested in subjects such as homosexuality, Islam or liberalism, despite religion, sexuality and political beliefs being explicitly marked out as \u201csensitive information\u201d by the EU\u2019s GDPR data protection laws.\n\nA month later, the Guardian and DBC discovered that the social network had algorithmically labelled 65,000 Russians as \u201cinterested in treason\u201d, potentially putting them at risk from the repressive state. Facebook removed that label following inquiries from the Guardian.\n\nFacebook\u2019s desire to offer as much information as possible to advertisers for their targeting of consumers has repeatedly led to issues regarding advertisers\u2019 ability to misuse that targeting data in ways that are often borderline, or outright illegal. In March, the US Department of Housing and Urban Development charged Facebook with violating the Fair Housing Act, arguing that the site\u2019s targeting features allowed advertisers to restrict housing adverts in a way that \u201cunlawfully discriminates based on race, colour, national origin, religion, familial status, sex, and disability\u201d. Facebook said at the time that it would work with the department and civil rights groups to improve its ad-targeting systems.", "description": "Exclusive: algorithm may expose thousands of under-18s to harmful targeted adverts", "authors": ["Alex Hern"], "top_image": "https://i.guim.co.uk/img/media/caaa51f58e3153abb609bb04bf4cfb5c9b22ec7d/0_0_4089_2453/master/4089.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=9357df02576a123eb1d7a5a033ccc01d", "published_at": "2019-10-09"}