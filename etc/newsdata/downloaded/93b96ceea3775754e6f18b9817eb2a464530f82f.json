{"pub": "yahoo", "url": "https://news.yahoo.com/tesla-model-crashed-fire-truck-010118455.html", "downloaded_at": "2019-09-04 08:08:51.757956+00:00", "title": "Tesla Model S That Crashed Into Fire Truck Had Autopilot Engaged", "language": "en", "published_at": "2019-09-04", "text": "Consumer Reports has no financial relationship with advertisers on this site.\n\nConsumer Reports has no financial relationship with advertisers on this site.\n\nA Tesla Model S driver who hit a fire truck in a January 2018 crash on a California highway was using Autopilot and rarely touched his steering wheel during the last 13 minutes and 48 seconds leading up to the collision, according to new investigation documents.\n\nThe driver, Robin Geoulla, appeared to be looking down and not at the road at impact, according to an eyewitness who saw the Model S pass him on the Culver City highway. The National Transportation Safety Board, which has been investigating the crash, made statements from the driver, the witness and technical findings of crash investigators public on its website Tuesday.\n\nPhone records indicate Geoulla wasn\u2019t using his phone to make a call or text before the crash, the NTSB said. Investigators didn\u2019t rule out the possibility that he was looking at his phone for some other reason. Geoulla told police at the crash scene he had been looking at his radio. He told the NTSB he saw the fire truck for the first time after the crash.\n\nAs systems like Autopilot become better at steering and braking, it\u2019s extremely important that consumers are aware of the system's limitations, according to Kelly Funkhouser, head of connected and automated vehicle testing at Consumer Reports. It\u2019s human nature to become complacent after technology works well numerous times, Funkhouser said.\n\n\u201cThis is not about blaming the driver or requiring driver training,\u201d Funkhouser said. \u201cThis is about designing a system that safeguards drivers and keeps them engaged.\u201d\n\nAdvanced driver assistance systems like Autopilot aren\u2019t the same as self-driving cars -- meaning the human driver is still responsible for paying attention to the road. Cadillac, Infiniti, Mercedes-Benz, Nissan, and Volvo offer systems similar to Autopilot, under various names. These systems can maintain a vehicle\u2019s place in the flow of traffic and keep it within the lines of its lane well enough to lull drivers into complacency. Only Cadillac's Super Cruise has a driver-facing camera that will issue warnings if the driver stops looking at the road.\n\nLike in some other high-profile Tesla crashes, the Model S was in Autopilot mode as it followed another vehicle in traffic. When the leading vehicle changed lanes, Geoulla said his vehicle didn\u2019t slow down, and he didn\u2019t see the fire truck until he hit it.\n\nThe NTSB\u2019s report said the Model S hit the fire truck at a speed between 4 mph and 24 mph. Geoulla told police and investigators he thought he had been going 65 mph and that Autopilot had been set at 65 mph. Post-crash photos show the car\u2019s front-end smashed and the airbags deployed. Neither Geoulla nor the occupants in the fire truck were injured.\n\nGeoulla was touching the steering wheel for only 51 seconds of the final 13 minutes and 48 seconds leading up to the crash, the NTSB report says. Geoulla told the NTSB that he bought his Model S because he wanted Autopilot. He added that he knew Autopilot wasn\u2019t able to fully drive his car.\n\nAutopilot in Crashes\n\nIn his interview with NTSB investigators, Geoulla said he used Autopilot from the first days he owned his Model S and that he quickly learned the system\u2019s flaws, according to a transcript of an interview he gave to NTSB investigators. He said that his Autopilot was unreliable on roads with sharp turns and could become confused when a car directly in front left the lane. Autopilot also didn\u2019t work well when driving directly into the sun, he told the NTSB.\n\n\u201cI think it was named wrong,\u201d Geoulla told NTSB investigators. \u201cIt's a very good cruise control with a little bit more advanced technology in it.\u201d\n\nAutopilot has been engaged in at least three fatal crashes\u2014all of which have been investigated by the NTSB. The safety board investigates a limited number of highway crashes each year, and it has taken a special interest in incidents involving new driver-assist technology. In its probe into a fatal May 2016 Florida crash, the NTSB faulted Tesla for not doing more to program Autopilot so it could only be used on highways with exit ramps. The safety board also said the auto industry more broadly needed to do more with technology to monitor whether drivers were paying attention to the road.\n\nSeveral Tesla crashes follow a common scenario. A Tesla vehicle operating on cruise control is following another vehicle. The lead vehicle suddenly leaves the lane to avoid something ahead that's stationary or moving slowly. The Tesla driver-assist systems don\u2019t have time to react to the object suddenly in its path, such as a stopped fire truck, and there's a collision.\n\nA Tesla spokeswoman, Danielle Meister, didn\u2019t immediately respond to an email seeking comment on the NTSB documents.\n\nTesla has said that limitations of Autopilot, adaptive cruise control, and automatic emergency braking are detailed in its owner's manuals. Adaptive cruise control cannot brake or accelerate in response to stationary vehicles, especially when traveling over 50 mph. AEB is designed to reduce the severity of an impact, not to avoid a collision, the company says, and Autosteer won\u2019t steer a vehicle around objects that jut into the driving lane.\n\nAfter a fatal crash in March 2018, Tesla said that Autopilot doesn\u2019t prevent all accidents and that such a standard would be impossible. Autopilot makes it less likely that crashes will occur and it \u201cunequivocally makes the world safer for the vehicle occupants, pedestrians and cyclists,\u201d it said.\n\nMore from Consumer Reports:\n\nConsumer Reports is an independent, nonprofit organization that works side by side with consumers to create a fairer, safer, and healthier world. CR does not endorse products or services, and does not accept advertising. Copyright \u00a9 2019, Consumer Reports, Inc.", "description": "A Tesla Model S driver who hit a fire truck in a January 2018 crash on a California highway was using Autopilot and rarely touched his steering wheel during the last 13 minutes and 48 seconds lea...", "authors": ["Jeff Plungis"], "top_image": "https://s.yimg.com/uu/api/res/1.2/3vq.Gc2mt9U5DFk5zEosXA--~B/aD02NzQ7dz0xMTk5O3NtPTE7YXBwaWQ9eXRhY2h5b24-/https://media.zenfs.com/en/autos.consumerreports.org/ae175634c1ddb78d0269068ca76439ac"}