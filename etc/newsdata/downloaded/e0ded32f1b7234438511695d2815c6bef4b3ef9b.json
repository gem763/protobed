{"pub": "axios", "url": "https://axios.com/deepfake-authentication-privacy-5fa05902-41eb-40a7-8850-5450bcad0475.html", "downloaded_at": "2019-10-19 17:04:17.521606+00:00", "title": "A digital breadcrumb trail for deepfakes", "language": "en", "text": "Experts are developing methods to verify photos and videos at the precise moment they're taken, leaving no room for doubt about their authenticity. This portends a cynical future in which media must leave a detailed digital breadcrumb trail in order to be believed.\n\nSome worry that if authentication becomes the default, people without access to verification technology \u2014 or who can't give up sensitive information about their location \u2014 will lose out.\n\nOne possible outcome: a bifurcated world in which some photos and videos, published by those who can afford the tools and visibility, are accompanied by a green checkmark \u2014 but other media languish in obscurity and doubt.\n\n\"My concern is that if they actually achieve their end-state goal that they describe, that might work against people who are already marginalized, and might perpetuate data surveillance,\" says Sam Gregory, a program manager at the human-rights nonprofit WITNESS.\n\nWhere it stands: The consensus today is that detecting deepfakes after they've been created is a stopgap \u2014 not a permanent solution.\n\nWith billions of photos now uploaded to social media every day \u2014 and deepfakes becoming increasingly easy to make \u2014 catching forgeries needs automated detection tools, which are unlikely to ever catch even the majority of fakes.\n\n\"I don't believe forensics can work in the long run,\" says Pawel Korus, a professor of engineering at NYU. \"It was never reliable enough to begin with, and it's starting to break as cameras are doing more and more interesting things.\"\n\nWhat's happening: The main alternative is to verify a photo or video at the source, using unique information about the specific camera that's taking it.\n\nThe ultimate vision is a universal indicator of veracity to accompany photos and videos on Facebook, YouTube, and other social media.\n\nis a universal indicator of veracity to accompany photos and videos on Facebook, YouTube, and other social media. But in this future, the all-important imprimatur of truth may not be in everyone's reach.\n\nthe all-important imprimatur of truth may not be in everyone's reach. \"The people who will be de facto excluded in a system of authentication will be people who are in the Global South, use a jailbroken phone, probably are women, probably are in rural areas,\" Gregory tells Axios.\n\nSeveral startups are working on this nascent technology.\n\nTruePic, a venture-backed startup, wants to work with hardware manufacturers \u2014 Qualcomm, for now \u2014 to log of photos and videos the instant they're captured.\n\na venture-backed startup, wants to work with hardware manufacturers \u2014 Qualcomm, for now \u2014 to log of photos and videos the instant they're captured. Amber, a small San Francisco startup, sends an encrypted record of photos and videos to a blockchain, so viewers can check if clips were later altered.\n\na small San Francisco startup, sends an encrypted record of photos and videos to a blockchain, so viewers can check if clips were later altered. Serelay, based in the U.K., saves about 100 phone sensor readings every time you snap a photo \u2014 GPS, pressure sensor, gyroscope, etc. \u2014 to check its veracity.\n\nWhat's next: All three companies told Axios that a widespread built-in verification system is still years away. For now, they are working with industries that need to be able to trust incoming videos and photos \u2014 TruePic with insurers, Amber with body camera makers, and Serelay with media companies.", "description": "Tracing a photo or video to its source may be the only way to know if it's real.", "authors": [], "top_image": "https://images.axios.com/1VG37asG9ESRiW7OZDBlPNPJUTo=/0x0:1920x1080/1920x1080/2019/07/11/1562876083781.jpg", "published_at": "2019-07-12"}