{"pub": "businessinsider", "url": "https://businessinsider.com/apple-designed-siri-to-deflect-questions-about-feminism-metoo-report-2019-9", "downloaded_at": "2019-09-07 02:36:46.071633+00:00", "title": "Leaked Apple documents reveal that Siri was designed to deflect questions about feminism and #MeToo, report says", "language": "en", "text": "Apple has instructed those working on its Siri digital assistant to design it to \"deflect\" questions about hot-button issues such as feminism and the #MeToo movement, according to The Guardian. The revelation comes after the iPhone maker and other tech firms had been criticized for how their virtual helpers respond to queries about sexual harassment in the past.\n\nThe internal project reported by The Guardian tells Siri's development team to design the virtual assistant's responses to such questions in the following ways: \"don't engage,\" \"deflect,\" and \"inform.\" Siri's responses should be written to suggest that it is in favor of equality while avoiding the word \"feminism,\" says The Guardian, which obtained leaked documents that had been last updated in June 2018.\n\nThat's because Apple wants Siri to remain \"guarded\" and \"neutral\" when dealing with sensitive topics, according to the report. When asking Siri if it's a feminist or what it thinks of feminism, the digital assistant will offer a response like: \"I am a believer in equality, and treating people with respect.\"\n\n\"Siri is a digital assistant designed to help users get things done,\" Apple said in a statement to Business Insider. \"The team works hard to ensure Siri responses are relevant to all customers. Our approach is to be factual with inclusive responses rather than offer opinions.\"\n\nRead more: Apple's former Siri chief says today's digital assistants still have a long way to go before they can really understand us\n\nThe publication says it received the documents from a former Siri grader \u2014 a contractor that had been hired to evaluate Siri's responses to improve its accuracy.\n\nApple scrapped its grading program for Siri after a previous report from The Guardian revealed that human workers regularly overheard private conversations. The company will reinstate the program in the fall after making several changes and issuing software updates. Apple will stop recording Siri conversations by default and instead allow users to opt in to share recordings to improve Siri.\n\nThe internal project leaked to The Guardian comes after Apple and other tech firms like Amazon, Microsoft, and Google came under fire for the way their respective voice-enabled assistants respond to requests involving insults and sexual comments.\n\nAn experiment conducted by Quartz in 2017 found that such comments sometimes resulted in evasive or flirtatious answers or jokes. Following the report, a petition asking tech companies to change the way their digital assistants respond to such requests appeared on the website Care2, garnering nearly 17,000 signatures.\n\nAmazon has also made changes to the way Alexa responds to such queries by creating a \"disengagement mode\" that enables it to say something like \"I'm not going to respond to that\" when presented with sexually explicit requests, according to Quartz.\n\nApple's guidelines for Siri that were leaked to The Guardian also note that Siri is \"non human\" and \"doesn't have a point of view,\" describing the digital helper's presence as \"genderless\" and \"playful.\" That echoes the approach Google has taken with the Google Assistant, as the search giant's personality team seeks to craft responses that feel human without pretending to be human, which TIME reported in 2017.\n\nDo you or have you ever worked as a Siri grader for Apple? If so, we want to hear from you. Contact this reporter securely at lisaeadicicco@protonmail.com.", "description": "Apple's Siri digital assistant is designed to deflect questions about feminism and #MeToo, according to leaked documents viewed by The Guardian.", "authors": ["Lisa Eadicicco"], "top_image": "https://amp.businessinsider.com/images/5d7266462e22af29965304b8-1536-768.jpg", "published_at": "2019-09-06"}