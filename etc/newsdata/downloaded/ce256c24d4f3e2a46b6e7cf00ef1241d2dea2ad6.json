{"pub": "yahoo", "url": "https://news.yahoo.com/putin-chef-takes-russian-disinformation-182836681.html", "downloaded_at": "2019-10-30 23:31:35.349342+00:00", "title": "\u2018Putin\u2019s Chef' Takes Russian Disinformation Tools to Africa, Report Says", "language": "en", "text": "(Bloomberg) -- Russia\u2019s cybermeddlers have found elections in parts of Africa to be fertile venues for their maturing disinformation tactics on social media, according to a report published Wednesday by the Stanford Internet Observatory in conjunction with Facebook Inc.\n\nThe tactics include subcontracting the spread of disinformation to local sources, better masking the origin of fake news and propaganda. The groups are also using tools such as Facebook Live and Google Forms to target a broader audience, according to the report.\n\nThe findings come as U.S. officials worry that Russia, and other adversaries, may be looking for new ways to meddle in the 2020 presidential election. In the 2016 election, Russia agents hacked and released Democratic Party emails while the Russia-based Internet Research Agency waged a social media campaign designed to sow political discord.\n\nThe report ties the evolving Russian activity in Africa -- including Sudan, Mozambique and Madagascar -- back to indicted Russian oligarch Yevgeny Prigozhin, who funded the Internet Research Agency, according to U.S. officials, and is known as \u2018Putin\u2019s Chef\u2019 because one of his companies has provided food services to the Kremlin.\n\nPrigozhin was indicted by Special Counsel Robert Mueller in February 2018 for his alleged role in interfering in the 2016 election. He\u2019s denied having a relationship with the IRA or interfering in the election.\n\nThe report\u2019s findings were reported earlier by the New York Times.\n\nChanged Tactics\n\nThe report demonstrates how Russia has changed its tactics since the 2016 election to evade detection and attribution. For instance, the use of local groups to communicate with those on social media in Arabic allowed the campaign to build credibility with the platforms while going undetected for longer periods of time.\n\n\u201cWhat\u2019s happening is these entities linked to Prigozhin are testing new strategies that they haven\u2019t tried in the U.S. before,\u201d said Shelby Grossman, an author of the report and a research scholar at the Stanford Internet Observatory. \u201cWe definitely are seeing an evolution in strategies that make attribution much harder going forward.\u201d\n\nThe new tactics appear to have allowed for the spread of disinformation more swiftly and to a wider audience. The IRA posted on Facebook 2,442 times a month on average in 2016, according to the New York Times. In five African nations, the groups posted 8,900 times in October alone, according to the Stanford report.\n\nFacebook announced that it has removed three Russian-backed influence networks of pages, groups and accounts that often communicated with each other and used fake accounts to misrepresent themselves.\n\n\u201cWe are making progress rooting out this abuse, but as we\u2019ve said before, it\u2019s an ongoing challenge,\u201d said Nathaniel Gleicher, Facebook\u2019s head of cybersecurity policy, in a blog post.\n\nTo contact the reporter on this story: Kartikay Mehrotra in San Francisco at kmehrotra2@bloomberg.net\n\nTo contact the editors responsible for this story: Andrew Martin at amartin146@bloomberg.net, Andrew Pollack\n\nFor more articles like this, please visit us at bloomberg.com\n\n\u00a92019 Bloomberg L.P.", "description": "(Bloomberg) -- Russia\u2019s cybermeddlers have found elections in parts of Africa to be fertile venues for their maturing disinformation tactics on social media, according to a report published Wednesday by the Stanford Internet Observatory in conjunction with Facebook Inc.The tactics include subcontracting", "authors": ["Kartikay Mehrotra"], "top_image": "https://s.yimg.com/cv/apiv2/social/images/yahoo_default_logo.png", "published_at": "2019-10-30"}