{"pub": "guardian", "url": "https://theguardian.com/technology/commentisfree/2019/oct/23/facebook-influence-next-election-democratic", "downloaded_at": "2019-10-23 09:39:28.018133+00:00", "title": "Facebook isn't going to influence the next election \u2013 until it does | Alex Hern", "language": "en", "text": "If you live in the US or UK, Facebook wants you to know that it isn\u2019t going to influence who wins the next election.\n\nBut the company also wants you to know that it\u2019s going to do its best to make sure that no one else exploits its platform to tilt the elections through attacks on democracy, deliberate misinformation or foreign interference.\n\nUnless the deliberate misinformation comes from a political candidate \u2013 in which case Facebook\u2019s not going to do anything, because, again, it doesn\u2019t want to influence who wins the next election.\n\nIf this all seems a bit confusing, you aren\u2019t alone. Facebook has set itself an impossible challenge. It needs to reassure everyone \u2013 of every political persuasion, in every country it operates in \u2013 that it\u2019s not going to do anything to harm the democratic process. And it wants to convey this message without reminding everyone of the elephant in the room: that, if it wanted, Facebook could almost certainly choose the winner of the next election, completely legally and without anyone knowing.\n\nUK queries Facebook decision to exempt political statements from fact-checking Read more\n\nMark Zuckerberg doesn\u2019t want that power. He\u2019s said so, again and again. Last week, in a speech at Georgetown University, he defended the company\u2019s laissez-faire approach to political misinformation, saying: \u201cAs a principle, in a democracy, I believe people should decide what is credible, not tech companies. Of course there are exceptions, and even for politicians we don\u2019t allow content that incites violence or risks imminent harm \u2013 and of course we don\u2019t allow voter suppression.\u201d\n\nThat same desire, to absent himself and his company from any responsibility to shepherd the democratic process, is also what lies behind Facebook\u2019s tortuous third-party factchecking programme, introduced in 2016. To wit: the company selects professional factchecking organisations, ranging from respected impartial nonprofits (FullFact in the UK, FactCheck.org in the US) to \u2026 others (Tucker Carlson\u2019s Daily Caller).\n\nIt pays those nonprofits to focus some of their time and attention on viral posts on Facebook and Instagram. If they flag a specific post or claim as false, Facebook then marks it as such on its own sites, and makes unspecified tweaks to its undocumented algorithms to reduce how many people see the posts. On Monday, the company announced that it would also start hiding false pictures and videos behind a clickthrough link declaring them as incorrect, and warning users if the post they are about to share is untrue.\n\nAll of which, three years after the programme was launched, adds up to a vaguely reasonable system to keep some of the clearest falsehoods from going mega-viral on Facebook\u2019s social networks. But the bizarre hoops the company has jumped through to achieve those ends have nothing to do with whether or not they are the best way to actually fight misinformation, and everything to do with Facebook\u2019s desire to be seen as a company that is powerless over the content it hosts.\n\nIt\u2019s this same factchecking programme that Facebook recently exempted political candidates from, in a move that had the knock-on effect of explicitly allowing those candidates to lie in adverts on the site. Not content with tying itself to the mast, Facebook bound the factcheckers alongside it: it wasn\u2019t going to decide what was credible, but neither were they. Never mind that that\u2019s their job; Facebook needs to be seen to have its hands off politics.\n\nBut Facebook\u2019s problem is that politics is always in its hands. There\u2019s a longstanding myth about the 1960 presidential election: that Richard Nixon came off better among voters who listened to the debates on radio, but that John F Kennedy won amongst those who watched on TV. The story goes that the shifting technological base of the US helped the eventual winner shore up his vote.\n\nSixty years on, we have another shifting technological base. God help a candidate who comes off worse in vertical video, the format favoured by so many mobile apps. But not every change in the media environment is purely technological. Some are deliberate. Over the past few years, for instance, Facebook has artificially intervened in its timeline to boost video, then live video, then quality news, then posts from your friends.\n\nFacebook Twitter Pinterest \u2018Facebook\u2019s problem is that politics is always in its hands.\u2019 Facebook and Instagram ads that appeared during the 2016 presidential campaign. Photograph: Jon Elswick/AP\n\nSuppose one of the presidential candidates in the 2020 election comes off better in livestreams, while the other looks more natural in slickly edited videos. What would Facebook do in response? Would it commit to boosting both types of content equally? Would it freeze its algorithm in place for six months? Or declare that it doesn\u2019t want to pick which candidate gets an advantage, so it\u2019s ditching videos altogether until after the election? Of course not. But if Facebook did decide to boost livestreams over the following period, it would be hard to escape the conclusion that, just like in 1960, the medium had defined the message.\n\n'Too much power': it's Warren v Facebook in a key 2020 battle Read more\n\nPerhaps that\u2019s too far-fetched. Suppose, instead, that one candidate were extremely good at wielding falsehoods for political gain, while another had built a reputation for their deep knowledge of arcane policy issues. What would we say, then, about a decision to crack down on misinformation in politics? Or, conversely, a decision to explicitly allow any and all falsehoods to gain the full weight of the viral machine?\n\nFacebook is like a giant who wanders into a busy town, then closes its eyes and declares that if it can\u2019t see where it\u2019s going, it\u2019s not their fault who gets crushed underfoot. Ultimately there\u2019s only two ways to stop it changing everything: keep it away entirely \u2013 or bring it down to size.\n\n\u2022 Alex Hern is the UK technology editor for the Guardian", "description": "The social media giant\u2019s election policy is to ignore its own power and hope for the best, says Alex Hern, Guardian technology editor", "authors": ["Alex Hern"], "top_image": "https://i.guim.co.uk/img/media/d9e99575f9521d7d7a0e663a8721d615518bc5d2/0_172_2587_1553/master/2587.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctb3BpbmlvbnMucG5n&enable=upscale&s=0bf219d8d533b56fe97377bc6dcebb98", "published_at": "2019-10-23"}