{"pub": "washingtonpost", "url": "https://washingtonpost.com/news/powerpost/paloma/the-technology-202/2019/09/27/the-technology-202-lawmakers-warn-about-threat-of-political-deepfakes-by-creating-one/5d8cfa5288e0fa4b0ec24691", "downloaded_at": "2019-09-27 15:03:00.876961+00:00", "title": "The Technology 202: Lawmakers warn about threat of political deepfakes by creating one", "language": "en", "text": "Rep. Michael Waltz (R-Fla.).\n\nCtrl + N\n\nRep. Michael Waltz called for Navy to beat Army in this year\u2019s football game. That's essentially treason for a former Army Green Beret.\n\nAnd it's not something he'd ever say in real life: The statement came from a newly released political deepfake -- a video doctored with artificial intelligence.\n\nWaltz teamed up with Rep. Don Beyer (D-Va.) to craft a mock deepfake for the House Science subcommittee to illustrate just how realistic this kind of disinformation can be. The SUNY-Albany and University of Chicago researchers took a recorded video statement from Beyer and transposed it onto Waltz's image -- designed to be a jarring sight for subcommittee chair and former Navy pilot Mikie Sherill (D-N.J).\n\nThe resulting video is a warning for lawmakers -- and the public -- that bad actors could abuse this technology for much more nefarious purposes than having a friendly joke about a sports rivalry. Watch it here:\n\n\u201cYou see how dangerous and misleading it could be; I\u2019m sure we fooled a couple of people,\u201d Beyer said. \u201cFor instance, what if instead of \u2018Go Navy, Beat Army,\u2019 I said, 'It\u2019s time to impeach the president'? That would be viral everywhere.\u201d\n\n\u201cMy friends might appreciate that, but I think he would not,\u201d he added of his Republican colleague.\n\nAs the 2020 election looms, Washington lawmakers are increasingly concerned that bad actors will use deepfake technology to sow chaos and stoke divisions among the American public \u2014 much like Russian actors did with traditional social media posts during the 2016 election.\n\nWaltz and Beyer are warning that United States needs to be investing in technology to quickly detect such fakes to keep up in an arms race, as the tools to create misleading videos become even cheaper and more widely available.\n\n\u201cThese videos and this technology have the potential to truly be a weapon for our adversaries,\u201d Waltz said.\n\nExpert witnesses who specialize in computer science and disinformation gave the lawmakers sobering testimony in a hearing yesterday about the state of the country's preparedness to address deepfakes and other hoaxes.\n\nSiwei Lyu, who led the SUNY researchers in developing the mock deepfake, said he was able to train his software in eight hours using a minute-long video they found of Waltz on YouTube. Though Lyu doesn\u2019t widely share the software tools he used to make the video, he told lawmakers that right now similar technology is widely available online.\n\n\"The technical capability of making high quality deepfakes is already at the disposal of whoever wants to make it,\" Lyu said.\n\nDisinformation isn't a new problem, but it's one that is being exacerbated by social media, which can help it spread much more quickly, the witnesses said.\n\nHany Farid, a professor at the Univeristy of California, Berkeley, warned lawmakers that the major technology platforms like Facebook and Google need to play a role in addressing deepfakes, but the tech companies have been slow to address the problem.\n\n\"You have to understand here that we are fighting against business interests,\" Farid said. \"In the last six months, the language coming out of the technology sector is encouraging, but I don't know there's a lot of action yet.\"\n\nTechnology companies are increasingly partnering with academics to address deepfakes and build better technology to detect such videos on their platforms. But the companies haven't yet publicly released policies explaining how they will address deepfakes spotted on their platforms.\n\nFarid said the recent video of House Speaker Nancy Pelosi that was altered to appear as if she was slurring her words underscores the impending challenges. Facebook allowed the video to remain on its platform, and the company defended that decision saying it did not want to be responsible for separating reality from fiction online.\n\n\"I can help with the technology problem, but I don't know what I can do with the policy problem when you say you aren't arbiters are the truth,\" Farid said. \"They have to start getting serious about how their platforms are being weaponized to great effect and disrupting elections, inciting violence and sowing civil unrest.\"\n\nFarid said it's difficult to predict exactly when a convincing deepfake will be released to disrupt a U.S. election.\n\n\"I think it's coming, but I don't know whether it will be in 2020, 2022 or 2024,\" Farid said. \"Largely because the cheap stuff still works. I think we'll eventually get ahead of that and then this will be the next front.\"\n\nBITS, NIBBLES AND BYTES\n\nSheryl Sandberg. (Andrew Harrer/Bloomberg News)\n\nBITS: Top Facebook executives toured Washington this week to promote the company\u2019s election security efforts. The tour included briefings with policymakers and their staffs, a person familiar with the meetings who spoke on the condition of anonymity because they were not authorized to speak publicly told me. The tour comes a week after CEO Mark Zuckerberg made the rounds to discuss a wide scope of policy issues.\n\nFacebook's delegation included Cybersecurity Director Nathaniel Gleicher, Global Elections Director Katie Harbath and Engineering Director for Civic Integrity Kaushik Iyer. They met with about 150 bipartisan staff in the House and Senate as well as presidential campaign staffers, national political campaign committees, national security experts and advocacy groups. The briefings touched on Facebook's efforts to better enforce its political advertising policies and advancements in the use of artificial intelligence to detect violating behavior.\n\nThe goodwill tour may not be enough to overcome growing doubts that Facebook simply doesn\u2019t have enough resources \u2014 or desire \u2014 to make meaningful changes. Facebook communications head Nick Clegg drew criticism when he announced in his speech that the company would not intervene if politicians violated its content standards. Earlier this week Facebook also took down a coordinated network of Ukrainian-run pages spreading political content targeting Americans, raising doubts about Facebook's ability to curb foreign influence on its platform before the 2020 elections.\n\nMeanwhile, other top Facebook executives \u2014 including COO Sheryl Sandberg \u2014 were in Atlanta meeting with civil rights advocacy groups at an event organized by Color of Change, where the groups called on Facebook to make changes to its content moderation policies to better address hate and violence.\n\n\u201cThe credibility of Facebook\u2019s efforts to create a safe and inclusive platform depends on meaningful engagement with our communities\u2019 expertise \u2014 and an urgent, thoughtful response to the concerns and priorities we shared today,\u201d Color Of Change President Rashad Robinson said in a statement.\n\nNest Secure. (Eric Risberg/AP)\n\nNIBBLES: Sen. Cory Gardner (R-Colo.) introduced legislation today that would require technology companies to disclose whether their smart home devices have cameras or microphones. Gardner cited an incident earlier this year when Google failed to disclose that its Nest Secure devices had a hidden microphone as part of the inspiration for the bill.\n\nThe Protecting Privacy in our Homes Act would charge the Federal Trade Commission with devising regulations requiring manufacturers to notify consumers whether Internet-connected devices contain cameras or microphones.\n\n\u201cConsumers face a number of challenges when it comes to their privacy, but they shouldn\u2019t have a challenge figuring out if a device they buy has a camera or a microphone embedded into it,\u201d Gardner said.\n\nWhile the legislation centers on Internet-connected devices, Gardner points out that unknown consumer surveillance extends well outside the home. Earlier this year, USA Today reported that several airlines used seat-back cameras, though the airlines claimed they didn't intend to use them. Gardner hopes the new legislation will empower consumers to ask companies what data they\u2019re collecting and where it\u2019s being sent.\n\nJessica Ferreira, a DoorDash driver, leaves Baskin-Robbins. (Christie Hemm Klok/For The Washington Post)\n\nBYTES: DoorDash says an unauthorized third party accessed the personal data of nearly 5 million consumers, contractors and merchants in May, according to a company blog post. The data accessed included 100,000 contractors' driver's license numbers, and it could trigger fines under certain state data breach laws.\n\nHackers also accessed names, addresses and phone numbers. The breach affected only users who joined before April 5, 2018, according to the company. The last four digits of payment cards for consumers and the last four digits of bank account numbers for contractors and merchants were exposed, but the hackers did not gain access to enough information to allow for fraudulent charges.\n\nThe company said it only noticed the \u201cunusual activity\u201d from a third-party service provider this month and immediately blocked the user. DoorDash said it has since added additional security protections and brought in an outside expert to assess its systems. The incident comes just a year after DoorDash denied reports of a separate breach.\n\nPRIVATE CLOUD\n\n\u2014 News from the private sector:\n\nTechnology Uber makes changes amid swarm of criticism over rider safety The app will allow on-trip reporting of safety incidents that don't rise to the level of an emergency. Faiz Siddiqui\n\nInstagram\u2019s Content Factories Are Huge\u2014And That\u2019s a Problem for Facebook The draw of 1 billion monthly users has spawned an aggressive behind-the-scenes advertising economy that threatens the site\u2019s originality and appeal, and the bottom line for its parent company. Wall Street Journal\n\nWall Street Skeptics Poke at Start-Up Bubble Companies like WeWork and Uber were expected to become a new generation of corporate giants. But investors have backed away. The New York Times\n\nAt Tech\u2019s Leading Edge, Worry About a Concentration of Power A.I. research is becoming increasingly expensive, leaving few people with easy access to the computing firepower necessary to develop the technology. The New York Times\n\nPUBLIC CLOUD\n\n\u2014 News from the public sector:\n\nCyber rules for self-driving cars stall in Congress Major automakers are moving full steam ahead with their plans to put self-driving cars on the road, even as lawmakers and regulators in Washington fall behind on creating a cybersecurity framework for those vehicles. The Hill\n\nWhat's in Trump's Super Classified Server and Why Is He Hiding Things There Putting a politically-damaging phone call with Ukraine on the \"codeword-classified\" system is highly inappropriate and would give Trump \"maximum control over who sees it.\" Motherboard\n\nGoogle Says Google Translate Can\u2019t Replace Human Translators. Immigration Officials Have Used It to Vet Refugees. \u2014 ProPublica Documents shared with ProPublica show that immigration officials have been told to vet refugees\u2019 social media posts using Google Translate. Language experts caution even students against using the service. Pro Publica\n\n#TRENDING\n\n\u2014 Tech news generating buzz around the Web:\n\nWeWork\u2019s Yoga-Obsessed School for the Ultra-Rich Could Be in Trouble With its parent company in chaos, education consultants say stay away: \u201cNone of our clients are applying now. They don\u2019t know if the school will be open tomorrow.\u201d The Daily Beast\n\nTwitch Has the Gamers but Yearns for a Wider Audience (Like YouTube\u2019s?) The live-streaming platform, owned by Amazon, has more viewers than many cable channels. But a new ad campaign aims to show it\u2019s good for more than video games. The New York Times\n\nIt's Not Just Greta. Trolls Are Swarming Young Climate Activists Online. A new movement of teenage climate activists \u2014 most of whom are girls \u2014 are getting dragged, doxed, hacked, and harassed online. BuzzFeed News\n\n@MENTIONS\n\nKate O'Connor will join the senior staff for Energy and Commerce Committee Republicans as chief counsel for the subcommittee on communications and technology. O'Connor previously served as chief of staff and deputy director of congressional and intergovernmental affairs for the National Telecommunications and Information Administration (NTIA).\n\nCHECK-INS\n\n\u2014 Today:\n\nThe House Energy and Commerce Committee will host a hearing to discuss securing America's wireless future and the deployment of 5G communications on Friday at 9:30 am.\n\n\u2014 Coming up:\n\nTechCrunch Disrupt SF will take place Oct 2 - Oct 4.\n\nThe House Energy and Commerce Committee will host a hearing to discuss the pros and cons of Section 230 of the Communications Decency Act on October 16.\n\nWIRED IN\n\nFrom earbuds to eyeglasses, Amazon wants Alexa to be everywhere you are:", "description": "Bad actors could do worse in election season.", "authors": ["Cat Zakrzewski", "Technology Policy Reporter", "September At Am"], "top_image": "https://www.washingtonpost.com/pbox.php?url=https://palomaimages.washingtonpost.com/pr2/ccd5e4ca9f1d6e139cebdf566daa84b8-3500-2302-70-8-SLXO5IHAVII6TPUWNLNYDAQ6SA.jpg&w=1484&op=resize&opt=1&filter=antialias&t=20170517", "published_at": "2019-09-27"}