{"pub": "zdnet", "url": "https://www.zdnet.com/article/facebook-microsoft-well-pay-out-10m-for-tech-to-spot-deepfake-videos", "downloaded_at": "2019-09-07 02:17:33.080610+00:00", "title": "Facebook, Microsoft: We'll pay out $10m for tech to spot deepfake videos", "language": "en", "text": "Facebook Dating: Why Match doesn't have much to worry about Facebook Dating is rolling out and the social networking giant has some interesting features, but it lacks the demographic coverage, know-how and dating data that Match and its army of sites such as Tinder have.\n\nIf AI-generated 'deepfake' videos are going to spread like wildfire and cause social chaos in the future, it's probably going to happen on Facebook or Facebook-owned WhatsApp and Instagram.\n\nTo boost the chances of technology being used to detect deepfake video when humans can't, the social network and advertising giant has launched the Deepfake Detection Challenge, offering $10m in research grants and rewards.\n\nThe effort is also being backed by the Partnership on AI, Microsoft, and academics from Cornell Tech, MIT, University of Oxford, UC Berkeley, University of Maryland, College Park, and State University of New York at Albany.\n\nFacebook has in the past conducted mind experiments on users without gaining their consent. But this time the company stresses no Facebook user data will be used. Instead, it is \"commissioning a realistic dataset that will use paid actors, with the required consent obtained, to contribute to the challenge\".\n\nThe aim is to create tech that everyone can use to detect when a video has been manipulated with AI.\n\nHowever, to do that, it needs to have a larger dataset of deepfake content to work with, and so far the industry doesn't have it or a benchmark for detecting deepfakes, according to Facebook.\n\nSo, Facebook is going to help create that dataset of deepfake video and audio with paid actors using the latest deepfake techniques.\n\nFacebook shows a side-by-side demo video of a real actor speaking next to one it created using other actors.\n\nBut as a recent CEO fraud case demonstrated, deepfake video used to disrupt society is not the only threat. A UK CEO was recently duped by deepfake audio of his superior into wiring $243,000 to a fraudster's account in a new twist on the lucrative business email compromise fraud.\n\nFacebook's deepfake detection drive follows the Defense Advanced Research Projects Agency's (DARPA) latest efforts at building detection systems using 'semantic forensics'\" or SemaFor.\n\nAnnouncing a new tender at the end of August, DARPA notes the connection between media manipulation and social media when it comes to the threat of disinformation causing unrest in the real world.\n\nThe new program is focusing on spotting semantic errors that often occur in models based on training data.\n\n\"There is a difference between manipulations that alter media for entertainment or artistic purposes and those that alter media to generate a negative real-world impact,\" said Dr Matt Turek, a program manager in DARPA's Information Innovation Office (I2O).\n\n\"The algorithms developed on the SemaFor program will help analysts automatically identify and understand media that was falsified for malicious purposes.\"\n\nImage: Facebook\n\nMore on deepfakes and security", "description": "Facebook will create its own deepfake videos to help build a system that can detect them.", "authors": ["Liam Tung"], "top_image": "https://zdnet4.cbsistatic.com/hub/i/r/2019/09/06/b55671f6-a379-4864-a4ba-3495e4f3dd87/thumbnail/770x578/ef20e56d0627a353caf292a740e975f0/facebookdeepfakesept19.jpg", "published_at": "2019-09-06"}