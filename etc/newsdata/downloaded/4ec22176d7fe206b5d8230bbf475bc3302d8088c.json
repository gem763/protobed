{"pub": "thenextweb", "url": "https://thenextweb.com/google/2019/10/15/mozilla-unveils-28-horror-stories-about-youtubes-recommendation-algorithm", "downloaded_at": "2019-10-15 04:25:00.854984+00:00", "title": "Mozilla unveils 28 horror stories about YouTube\u2019s recommendation algorithm", "language": "en", "text": "Mozilla just launched a site featuring 28 user-submitted stories, detailing incidents where YouTube\u2019s recommendation algorithm served bizarre and horrifying videos the users had shown no interest in. This included recommendations featuring racism, conspiracies, and violence.\n\n\n\nYouTube\u2019s recommendation algorithm has faced a lot of scrutiny this year for radicalization, pedophilia, and for generally being \u201ctoxic\u201d \u2014 which is problematic because 70 percent of the platform\u2019s viewing time comes from recommendations. That\u2019s why Mozilla launched the #YouTubeRegrets project, to highlight the issue and urge YouTube to change its practice.\n\nCredit: Mozilla The stories gathered by Mozilla show how YouTube\u2018s recommendations can go wrong.\n\nThe stories of the darker sides of YouTube\u2019s recommendations are chilling, and put the spotlight on whether or not their purpose is justified.\n\n\u201cThe stories show the algorithm values engagement over all else \u2014 it serves up content that keeps people watching, whether or not that content is harmful,\u201d Ashley Boyd, Mozilla\u2019s VP of Advocacy, told TNW.\n\nGore, violence, and hate\n\nMany of the stories describe the effects of recommendations on more vulnerable groups such as children:\n\nWhen my son was preschool age, he liked to watch \u201cThomas the Tank Engine\u201d videos on YouTube. One time when I checked on him, he was watching a video compilation that contained graphic depictions of train wrecks.\n\nUsers can\u2019t turn recommendations off, so children can be fed problematic content without having the means to steer clear of it. But that doesn\u2019t mean adults are unaffected:\n\n\n\nI started by watching a boxing match, then street boxing matches, and then I saw videos of street fights, then accidents and urban violence\u2026 I ended up with a horrible vision of the world and feeling bad, without really wanting to.\n\nOften the recommendations go completely against the viewer\u2019s interests in harmful and upsetting ways:\n\nI used to occasionally watch a drag queen who did a lot of positive affirmation/confidence building videos and vlogs. Otherwise, I watched very little that wasn\u2019t mainstream music. But my recommendations and the sidebar were full of anti-LGBT and similar hateful content. It got to the point where I stopped watching their content and still regretted it, as the recommendations followed me for ages after.\n\nCredit: Mozilla Conspiracy theory videos are also mentioned as they\u2019re frequently recommended, causing students to be misinformed, elderly people being duped, and feeding into the paranoia of people with mental health problems.\n\nMozilla acknowledges that the stories are anecdotal and not cold hard data, but they do highlight the bigger issue at hand.\n\n\u201cWe believe these stories accurately represent the broad problem with YouTube\u2019s algorithm: recommendations that can aggressively push bizarre or dangerous content,\u201d Boyd explains. \u201cThe fact that we can\u2019t study these stories more in-depth \u2014 there\u2019s no access to the proper data \u2014 reinforces that the algorithm is opaque and beyond scrutiny.\u201d\n\nAnd therein lies the issue. YouTube has denounced methodologies employed by critics of the recommendation algorithm, but doesn\u2019t explain why they\u2019re inaccurate.\n\n\n\nMozilla points out that YouTube hasn\u2019t even provided data for researchers to verify the company\u2019s own claim that it has reduced recommendations of \u201cborderline content and harmful misinformation\u201d by 50 percent. So there\u2019s now way to know whether YouTube actually has made any progress.\n\nSolution?\n\nJudging by these personal stories and recent news reports, it does seem something needs to happen \u2014 and fast. Earlier this year, Guillaume Chaslot, a former Google employee, told TNW the \u201cbest short-term solution is to simply delete the recommendation function.\u201d\n\nWhile that particular solution might not be realistic, Mozilla presented YouTube with three concrete steps the company could take to improve its service in late September:\n\nProvide independent researchers with access to meaningful data , including impression data (e.g. number of times a video is recommended, number of views as a result of a recommendation), engagement data (e.g. number of shares), and text data (e.g. creator name, video description, transcription and other text extracted from the video)\n\n, including impression data (e.g. number of times a video is recommended, number of views as a result of a recommendation), engagement data (e.g. number of shares), and text data (e.g. creator name, video description, transcription and other text extracted from the video) Build simulation tools for researchers , which allow them to mimic user pathways through the recommendation algorithm\n\n, which allow them to mimic user pathways through the recommendation algorithm Empower, rather than restrict, researchers by changing its existing API rate limit and providing researchers with access to a historical archive of videos\n\nBoyd says YouTube\u2018s representatives acknowledged that they have a problem with their recommendation algorithm, and said they\u2019re working to fix it. \u201cBut, we don\u2019t think this is a problem that can be solved in-house. It\u2019s too serious and too complex. YouTube must empower independent researchers to help solve this problem,\u201d says Boyd.\n\nYou can read all the stories on Mozilla\u2019s website. And if you\u2019re looking to get rid of some algorithms in your life, then try an extension called Nudge which removes addictive online features like Facebook\u2019s News feed and YouTube recommendations.", "description": "Mozilla gathered 28 user-submitted stories, detailing incidents where YouTube\u2019s recommendation served videos featuring racism, conspiracies, and violence.", "authors": ["M\u00e1r M\u00e1sson Maack"], "top_image": "https://img-cdn.tnwcdn.com/image/tnw?filter_last=1&fit=1280%2C640&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2019%2F10%2FUntitled-design2.png&signature=78dd84c7af79bd05cdb10d05b30ea4b7", "published_at": "2019-10-15"}