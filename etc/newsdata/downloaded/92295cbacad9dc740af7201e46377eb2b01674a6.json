{"pub": "guardian", "url": "https://theguardian.com/lifeandstyle/2019/sep/19/its-a-violation-the-war-on-unwanted-dick-pics-has-begun", "downloaded_at": "2019-09-19 06:02:00.026250+00:00", "title": "'It's a violation': the war on (unwanted) dick pics has begun", "language": "en", "text": "A web developer asked men to send her pictures of their genitals in order to build a filter that \u2018recognises\u2019 a penis and blurs it. Which raises the question: why haven\u2019t tech companies taken this on yet?\n\nEarlier this month, after waking up to find an unwelcome dick pic in her Twitter account\u2019s DMs, web developer Kelsey Bressler, 28, co-created an AI filter she claims is capable of preventing over 95% of sexually explicit images from reaching her inbox.\n\nTo test the filter, Bressler solicited pictures of male genitalia en masse, receiving hundreds to the trial account @ShowYoDiq, \u201cfor science\u201d.\n\n(Bressler is unsure of the exact final number of volunteer pics because she is still processing them manually and many respondents jokingly messaged her pictures of President Trump, which she must now weed out).\n\nK E L S E Y (@raeBress) I'm soliciting dick pics at the handle @showyodiq .\n\n\n\nThis is not a joke.\n\n\n\nI am testing a filter that is under development which will automatically detect dick pics in DMs and handle them on behalf of the user (delete, delete&block).\n\n\n\n18+ , consensual, human dicks only please.\n\nSome of the more unusual images sent to Bressler slipped through the filter. One penis, covered in purple glitter, confused the AI, which was trained to spot flesh-toned appendages by processing a lot of porn. But when it comes to regular appendages, the filter sees and deletes them before the recipient must.\n\nAt this point, you may be wondering why do men send women unwanted explicit pictures of their genitals. It varies, yet according to researchers at Kwantlen Polytechnic University in Canada, who released the first empirical study on the subject this summer, the behavior is linked to heightened levels of narcissism and sexism. \u201cMen may find this exertion of power over women arousing itself, or they may find the shocked, hurt and angry reactions to be humorous or satisfying,\u201d researchers wrote.\n\nAccording to a 2017 Pew Research Study on cyber harassment, 53% of women ages 18 to 29 report that they have been sent an unsolicited lewd image online. While there\u2019s nothing inherently wrong with sexy pictures \u2013 and senders may not always intend to cause harm \u2013 the fact that these images are shared without the recipient\u2019s consent qualifies as sexual harassment. \u201cIt\u2019s a violation \u2026 they\u2019re just forcing it on you,\u201d says Bressler of how it feels to receive unwanted pictures.\n\nBressler\u2019s AI has already piqued the attention of at least one major social networking site, but the speed and ease with which her filter was created raises the question of why more tech companies don\u2019t already use effective anti-harassment software, and why the measures they have taken to protect their users often seem half-baked.\n\nTwitter, for instance, features a setting that, when activated, blocks images other users have flagged as \u201csensitive content\u201d \u2013 but that won\u2019t stop a dick pic from being sent directly to your inbox. (Twitter did not reply to a request to comment for this article.) And while you can block and report users who bother you on almost any platform, you can\u2019t unsee the harassing images in the first place.\n\nPart of the reason why platforms are reticent to crack down on the nonconsensual sharing of nudes is because, unlike flashing someone in the subway, the digital practice is not yet widely illegal, nor are companies required to protect their users. Even in cases of extreme harassment, such as that suffered by Grindr user Matthew Herrick, companies are able to defend their refusal to protect victims by citing Section 230 of the Communications Decency Act (CDA), which, because they are not technically publishers, absolves them of responsibility for the content their users share. Lawyer Carrie Goldberg recently told the Guardian that the CDA \u201cis the enabler of every asshole, troll, psycho and perv on the internet\u201d.\n\nThanks in part to Goldberg\u2019s advocacy, 46 states now enforce laws against the distribution of nonconsensual pornography, or \u201crevenge porn\u201d, but the war on dick pics has just begun.\n\nLast year, councilman Joseph Borelli, a Republican from Staten Island, co-sponsored a bill (yet to pass) that would make cyberflashing \u2013 sharing nudes via Apple\u2019s AirDrop feature, which allows people to anonymously send content to other devices within a 10-meter radius \u2013 punishable by up to a $1,000 fine or one year in jail.\n\n\u201cIn the old days, you had to have a long trench coat and good running shoes,\u201d Borelli told the New York Times. \u201cTechnology has made it significantly easier to be a creep.\u201d\n\nCyberflashing has been illegal in Scotland since 2010, and Singapore criminalized the practice this May. In the state of South Carolina, anonymously sending an \u201cobscene, profane, indecent, vulgar, suggestive, or immoral\u201d file without the recipient\u2019s consent can be punished by up to three years of imprisonment.\n\nAs of 1 September, Texas also has an anti-lewd imagery law, stewarded by the Texas Republican representative Morgan Meyer and \u201cfeminist dating app\u201d Bumble, which is headquartered in Austin.\n\n\u201cSafety and holding our users accountable online are two of the most important things that go into our day-to-day thinking about how we\u2019re going to end misogyny,\u201d says Bumble\u2019s chief of staff, Caroline Ellis Roche, of the company\u2019s interest in pursuing legislation.\n\n\u201cHaving this bill where it is now illegal to send an unsolicited lewd photo in the state of Texas is like a deterrent, like adding stop signs to the internet,\u201d says Roche of the law, which classifies sending an unwanted dick pic as a class C misdemeanor punishable by a fine of up to $500. \u201cWe\u2019re working to take this to the federal level.\u201d\n\nCritics have pointed out the law may be difficult to enforce due to its nonspecific terminology, and that sending explicit images may be a first amendment right. As free speech is closely protected by courts, lewd imagery laws could be hindered by \u201cintent to harm\u201d clauses \u2013 meaning perpetrators could claim innocence by arguing they did not mean to harass the recipient of their explicit imagery, and rather thought a dick pic would brighten their day.\n\nA safer future for women online may require both legislation and efforts from tech companies to meaningfully reduce cyber harassment and send the message that sharing nudes without consent is unacceptable. To that end, this month Bumble launched Private Detector, an image filter similar to Bressler\u2019s, which blurs images it deems potentially sensitive so users may delete them without taking a look at their contents. This way, hopefully the only people looking at nudes online should be those who want to be.", "description": "Legislators and tech companies are finally working to protect women from receiving unwanted sexually explicit images online \u2013 will it work?", "authors": ["Adrienne Matei"], "top_image": "https://i.guim.co.uk/img/media/546935859907ba9f2de52e38a1b27ab2797cca73/0_0_3000_1800/master/3000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=956e6da4ed17f23427ea86814c9d6a44", "published_at": "2019-09-19"}