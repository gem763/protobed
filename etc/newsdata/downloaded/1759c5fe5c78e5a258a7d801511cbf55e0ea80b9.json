{"pub": "theverge", "url": "https://theverge.com/2019/2/1/18205174/automation-background-check-criminal-records-corelogic", "downloaded_at": "2019-10-05 15:06:09.376567+00:00", "title": "Automated background checks are deciding who\u2019s fit for a home", "language": "en", "text": "Mikhail Arroyo had made it out of the coma, but he was still frail when his mother, Carmen, tried to move him in with her. The months had been taxing: Mikhail was severely injured in a devastating fall in 2015. He had spent time in the hospital, and by 2016 was in a nursing home where his mother visited him daily, waiting until they could live together again. Carmen planned to move him to a new apartment with her in the Connecticut residential complex where she was staying. The only task left was the paperwork.\n\nAt a meeting, she says, the management company broke the news. Mikhail wouldn\u2019t be allowed in to the apartment. Carmen was shocked.\n\n\u201cOn what basis?\u201d she asked.\n\nThe woman she spoke to couldn\u2019t tell her. Although Carmen couldn\u2019t have known all of the details, Mikhail had been flagged by a criminal screening tool run by a company called CoreLogic. She says she was only shown a single sheet of paper \u2014 one she couldn\u2019t take with her, and that scarcely helped \u2014 and given a CoreLogic phone number to call.\n\nShe got nowhere. She waited on hold, was transferred back and forth. Carmen was Mikhail\u2019s designated conservator, giving her legal decision-making power, but the company needed documentation for her and Mikhail \u2014 a passport, a driver\u2019s license \u2014 and she wasn\u2019t getting through. Carmen was \u201clivid.\u201d At one point, she says, she was told to get in touch with the legal department, but they weren\u2019t available. Was this over a credit check? And didn\u2019t the circumstances count for anything? She started to worry, wondering whether the number was somehow fraudulent and she\u2019d handed over all of her personal information.\n\nCarmen was \u201clivid\u201d\n\nThe process dragged on for months. \u201cThey just kept giving me the runaround,\u201d Carmen says. Meanwhile, she looked for another place to live, and found one spot, even if it was in a worse neighborhood. But it had stairs, and Mikhail couldn\u2019t walk at the time \u2014 so he wouldn\u2019t be able to live there. He wasn\u2019t able to fully speak yet, either, but when it was time to bring him back to the nursing home, he\u2019d point to tell her he wanted to go back to the apartment. Some days, he\u2019d cry. \u201cIt was heartbreaking for him,\u201d she says, \u201cbecause he wanted to go home.\u201d\n\nAs landlords decide who to rent to, CoreLogic offers an array of screening tools. They might use a product called ScorePLUS, which the company describes as a \u201cstatistical lease screening model\u201d that calculates \u201ca single score\u201d to determine the potential risk of someone signing a lease. A landlord might also turn to a product called CrimCHECK, which conducts a database search for criminal records. The breadth of records the company advertises is impressive. The company says it uses an arrest records database of more than 80 million booking and incarceration records from approximately 2,000 facilities, updated every 15 minutes. CrimSAFE, the system that flagged Mikhail, is described by the company as an \u201cautomated tool [that] processes and interprets criminal records and notifies leasing staff when criminal records are found that do not meet the criteria you establish for your community.\u201d\n\nThe ability to outsource decisions is a key pitch to prospective screeners. \u201cWhatever decision or information service you use, you\u2019ll find the same simple data entry process, rapid turnaround and clear concise results that eliminate the need for judgment calls by your leasing professionals,\u201d the company tells visitors to its website. Should there be a problem, and a landlord must send an \u201cadverse action\u201d letter, the company advertises an automated system for that as well.\n\nAdvocates say eliminating \u201cjudgment calls\u201d is the problem\n\nBut for some housing advocates, the rise of automation and elimination of human \u201cjudgment calls\u201d is increasingly the problem, not the solution. When screening tools bypass more human forms of decision-making, they say, those decisions are more likely to collapse complex matters into simple, algorithmically generated pass-fail mechanisms \u2014 leaving behind people looking for a home.\n\nEric Dunn, the director of litigation at the National Housing Law Project, has seen how the tools used by landlords have evolved in recent years. Over time, he\u2019s watched more people move away from what he calls \u201cold guard screening,\u201d where research was done by humans and landlords were provided extensive documentation. Instead, systems are more likely now to map \u201cidentifiers,\u201d selecting options like certain types of crime, against massive databases of obscure origin.\n\nFair housing proponents like Dunn say nuance is lost when landlords rely on automated screening tools that turn a personal history \u2014 one person\u2019s story, which a landlord might have to grapple with, weighing actual risk \u2014 into a list of variables to be machine-verified. If there are extenuating circumstances around a record, they can\u2019t always be captured in the rigid framework of the system, advocates argue. No matter how expedient it might be for landlords and background check companies to use those tools, they say, it will lead to blocking people who otherwise would have been accepted by a more personalized form of screening.\n\nThe companies that offer these tools frame them as recommendations for landlords, which they can override. But Dunn questions that line of thinking. If the machine calculates a failing decision, he argues, there\u2019s little other basis for a landlord to come to a different conclusion, especially if the landlord isn\u2019t provided the complete history.\n\nFederal law prohibits landlords from selecting their tenants based on protected characteristics \u2014 an applicant\u2019s race, sex, or religion, can\u2019t be used to determine whether they\u2019re offered a place to live. But criminal records are more complex. If a record involves property damage, for example, a landlord might be within their legal right to decline an application, on the basis that it indicates a potential problem in the future.\n\nIn the past few years, some of the boundaries of those protections have been extended. The Supreme Court, in a major 5\u20134 decision in 2015, ruled that the law extended to decisions that disproportionately affected certain groups, even if it was indirectly. If a policy affects a black neighborhood more than a nearby white one, for example, the policy could be unlawful. The legal theory is known as the \u201cdisparate impact\u201d standard.\n\nHUD issued major new guidance for real estate transactions in 2016\n\nNoting the disproportionate effect of criminal records on minority groups, the Department of Housing and Urban Development issued new guidance for real estate transactions in 2016. Under the guidelines, a landlord, or someone else determining whether to offer someone a home, might be able to use a criminal record to make a decision about a tenant. But that decision, according to the guidance, requires a close look at individual cases. If the screening policy fails to consider the severity or relevance of the record, or how long ago the incident happened, it likely wouldn\u2019t pass HUD\u2019s test. The Arroyos are currently involved in a suit with CoreLogic over these protections.\n\nMonica Welby, deputy director of litigation at the Legal Action Center, says commercial checks are also \u201cnotoriously\u201d inaccurate. Dunn sees similar issues. \u201cI\u2019ve looked at more criminal records reports than I could count, and I would say that well over half the ones I\u2019ve looked at had some kind of inaccuracy,\u201d he says.\n\nA record might, for example, include information from someone with a similar name, leading to a denial. \u201cThis happens all the time,\u201d Dunn says. A similarly named relative \u2014 or maybe someone completely unrelated, who happens to share a name with a rental applicant \u2014 can derail a tenant\u2019s application. The problems, Dunn says, often might have been caught by a more individualized screening system.\n\nCoreLogic has faced lawsuits over such errors. Under the Fair Credit Reporting Act, companies are required to make an effort to ensure accuracy as well as they reasonably can, but some have questioned the depth of that commitment. In 2015, a South Carolina man said in a lawsuit that he and his wife were seeking a new place to stay after flooding damaged their home. When he applied for a new apartment, though, he was flagged by a CoreLogic tool as a registered sex offender \u2014 apparently due to someone with a similar name. In court documents, the man said he was eventually able to reach someone to correct the discrepancy, but the process for removing the information would take two weeks, as the apartment slipped away.\n\nA dispute can be hard to fight, as Carmen discovered. She eventually found legal representation from a local nonprofit, the Connecticut Fair Housing Center. The group filed an administrative complaint with the management company.\n\nThe CoreLogic system that flagged Mikhail, according to court documents, allows landlords to select certain options about criminal history to screen against. This means the decision largely remains in the landlord\u2019s hands, the company argues, since the landlord chooses the parameters. CoreLogic has said its system only makes a check based on what it\u2019s told to do, and is compliant with housing law. (CoreLogic declined to answer questions about its screening process, citing pending legal disputes, several of which it has faced in federal court. The company would not provide more information on precisely what landlords can screen for, or how it ensures accuracy in its results.)\n\nA dispute can be hard to fight\n\nIf the company flags your application, and you believe it\u2019s relying on inaccurate information, CoreLogic offers a helpline to call. The company says it will conduct a reinvestigation that will be completed within 30 days, and if any errors are found, will fix the issues. Still, some argue that even if the errors are corrected, whatever home an applicant has applied for will likely be gone after a month.\n\nThe Connecticut Fair Housing Center tried to get the management company to overlook the background check. Whatever caused Mikhail to be flagged, they argued, it was clearly moot. If a criminal screening is predicated on the theory that it could predict future behavior, Mikhail was hardly likely to commit a crime in the future \u2014 he was disabled now, reliant on others for help. There was no basis to think he was somehow a danger to people or property.\n\nThe argument, according to Salmun Kazerounian, a staff attorney at the center, didn\u2019t sway the management. \u201cThey responded, essentially, \u2018how can we agree to overlook a criminal record if we don\u2019t know what it is?\u2019\u201d he says.\n\nCoreLogic\u2019s documentation was a sparse source of clues. The company provided a \u201cresult\u201d that said there was a \u201cdisqualifying record,\u201d but not enough to deduce what the problem was. The report generated a \u201cjurisdiction\u201d entry that was seemingly nonsensical: \u201c000000033501.PA.\u201d\n\nThe \u201cresult\u201d showed a \u201cdisqualifying record\u201d\n\nAt first, they had no idea how to find out what the record could mean. It took more digging to determine the circumstances, but eventually the story could be pieced together. Before his accident, Mikhail faced a retail theft charge in Pennsylvania. The charge, according to the center, was for a \u201csummary offense\u201d \u2014 a charge below misdemeanor that\u2019s also called a \u201cnon-traffic citation.\u201d The level of the charge suggested the incident involved less than $150 and was Mikhail\u2019s first offense. He was 20 years old at the time. \u201cIt was as minor as they come,\u201d Kazerounian says. Last year, the charge was withdrawn. (Mikhail was also arrested following a burglary in 2013, according to statements from local authorities; Kazerounian stressed that, regardless, the Pennsylvania charge was the only item on his record.)\n\nWhile it\u2019s hard to determine the exact rate of disputes like the Arroyos\u2019, experts say there are broader issues around accuracy in background screening. \u201cDisputing information with consumer reporting agencies can be extremely challenging for individuals,\u201d Welby says.\n\nIn one CoreLogic case recently settled, a man named Abdullah James George Wilson was sent to prison after a 1992 robbery, but years later, after his counsel was found to be ineffective, Wilson was granted a favorable ruling on appeal. His record was sealed.\n\nBut in 2014, Wilson, looking for a place to live, found that his application was rejected anyway. The problem: a CoreLogic system flagged the record from the New York correctional record. Wilson was barred from the apartment.\n\n\u201cIn this age of technology and widespread use of criminal background checks, it is more important than ever that background check companies get it right,\u201d Wilson, who reached a settlement in a lawsuit, said in a statement to The Verge provided by the Legal Action Center. \u201cThey must take the proper steps to ensure that the criminal record information they report is accurate. The stakes are high for people \u2014 it can be the difference between having a place to call home or not.\u201d\n\nMikhail was finally allowed to move in with Carmen in June 2017, after the charge was withdrawn. Had the screening been done effectively, the Connecticut Fair Housing Center alleges in a lawsuit against CoreLogic, they could have been reunited a year earlier, saving the Arroyos time, money, and emotional energy. \u201cI\u2019m bringing it because I think it was wrong, what they\u2019ve done,\u201d Carmen says.\n\n\u201cI\u2019m bringing [a lawsuit] because I think it was wrong, what they\u2019ve done.\u201d\n\nThe suit is ongoing. It argues that the screening tool disproportionately affects black and Latinx tenants, and fails to properly take into account mitigating circumstances of a criminal record, allegedly a violation of the Fair Housing Act as it was outlined in HUD\u2019s 2016 guidance. The complaint seeks damages for the Arroyos, to be determined later, and asks for a judgment that would require CoreLogic to take steps that would prevent situations like the Arroyos\u2019 in the future.\n\nThe company has responded that, as a background check business, they are not subject to the Act. Only the people using their tools are, they argue. The HUD rules, they say, support that claim.\n\nWhen Mikhail got home, about two years after the accident, Carmen says she was \u201ca bag of great emotions.\u201d He remains in a wheelchair, and has physical therapy twice a week, but can say phrases like, \u201cHi, mom.\u201d He cried when he got home.\n\nWhen he made it back, he had moments of concern about whether he\u2019d have to leave again. \u201cI would always reassure him,\u201d Carmen says, \u201cno, you\u2019re home, this is it.\u201d", "description": "Automation has turned criminal background checks into pass-fail mechanisms, but advocates say simple algorithms can\u2019t capture the complexity of records.", "authors": ["Colin Lecher", "Feb"], "top_image": "https://cdn.vox-cdn.com/thumbor/QtrBA0qkSaGHDiTRln-hmxcdJVs=/0x146:2040x1214/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/13728612/acastro_190129_3199_Housing_AI_001.jpg", "published_at": "2019-02-01"}