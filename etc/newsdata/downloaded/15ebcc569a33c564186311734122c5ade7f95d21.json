{"pub": "thenextweb", "url": "https://thenextweb.com/artificial-intelligence/2019/10/10/california-bans-law-enforcement-from-using-facial-recognition-software-for-the-next-3-years", "downloaded_at": "2019-10-10 00:43:52.968235+00:00", "title": "California bans law enforcement from using facial recognition software for the next 3 years", "language": "en", "text": "California lawmakers today passed a bill placing a three-year state-wide moratorium on the use of facial recognition technology by law enforcement agencies.\n\nAB 1215, The Body Camera Accountability Act, was introduced earlier this year by assemblymember Phil Tang, a Democrat. Both San Francisco and Oakland previously passed similar bills preventing the use of facial recognition by law enforcement agencies, now the ban\u2019s gone state-wide.\n\nThe bill goes into effect on 1 January, 2020, and will be reviewed under a \u201csunset provision\u201d in 2023.\n\nTang, according to an ACLU statement, says the bill will protect Californians:\n\nWithout my bill, facial recognition technology essentially turns body cameras into a 24-hour surveillance tool, giving law enforcement the ability to track our every movement. Let\u2019s not become a police state and keep body cameras as they were originally intended \u2013 to provide police accountability and transparency.\n\nUS citizens have the right to privacy and the reasonable expectation that public surveillance systems are in place to protect us in the event that a crime is committed.\n\nBut AI-powered facial recognition systems aren\u2019t designed to monitor public spaces for crimes. As we\u2019ve seen in leaked Palantir documents, these systems are meant to connect to a database wherein police officers have access to the private details of any citizen. Here\u2019s a graphic showing what kind of information law enforcement officers have available to them with the Palantir app:\n\nCredit: Vice / DOJ US DOJ Records / Image from Vice\n\nIn essence, these tools give police officers the kind of data and information that a detective 20 years ago couldn\u2019t have gleaned with a search warrant and six months to investigate \u2013 today there\u2019s literally an app for that.\n\nAs Electronic Frontier Foundation Associate Director of Community Organizing Nathan Sheard put it, use of these tools would force citizens to decide \u201cbetween actively avoiding interaction and cooperation with law enforcement, or having their images collected, analyzed, and stored as perpetual candidates for suspicion.\u201d\n\nOur right to privacy, like our right to keep a well-regulated militia, is meant to protect us from tyranny. Thousands of US law enforcement agents have been outed over the past year as members of online hate-groups, and the Supreme Court is currently deciding whether it\u2019s okay for an employer to fire someone for being queer. The risk posed to marginalized communities by rogue law enforcement agents is only exacerbated by facial recognition software.\n\nHere\u2019s hoping the rest of the country catches up to California before it\u2019s too late.", "description": "", "authors": ["Tristan Greene"], "top_image": "https://img-cdn.tnwcdn.com/image/tnw?filter_last=1&fit=1280%2C640&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2018%2F08%2FFacial-recognition.jpg&signature=23966d7c45a4124126bf905550bfc7f2", "published_at": "2019-10-10"}