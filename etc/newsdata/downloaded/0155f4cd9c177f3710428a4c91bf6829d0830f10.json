{"pub": "guardian", "url": "https://theguardian.com/technology/2019/sep/17/revealed-catastrophic-effects-working-facebook-moderator", "downloaded_at": "2019-09-17 13:10:04.216339+00:00", "title": "Revealed: catastrophic effects of working as a Facebook moderator", "language": "en", "text": "Exclusive: Job has left some \u2018addicted\u2019 to extreme material and pushed others to far right\n\nThe task of moderating Facebook continues to leave psychological scars on the company\u2019s employees, months after efforts to improve conditions for the company\u2019s thousands of contractors, the Guardian has learned.\n\nA group of current and former contractors who worked for years at the social network\u2019s Berlin-based moderation centres has reported witnessing colleagues become \u201caddicted\u201d to graphic content and hoarding ever more extreme examples for a personal collection. They also said others were pushed towards the far right by the amount of hate speech and fake news they read every day.\n\nThey describe being ground down by the volume of the work, numbed by the graphic violence, nudity and bullying they have to view for eight hours a day, working nights and weekends, for \u201cpractically minimum pay\u201d.\n\nA little-discussed aspect of Facebook\u2019s moderation was particularly distressing to the contractors: vetting private conversations between adults and minors that have been flagged by algorithms as likely sexual exploitation.\n\nSuch private chats, of which \u201c90% are sexual\u201d, were \u201cviolating and creepy\u201d, one moderator said. \u201cYou understand something more about this sort of dystopic society we are building every day,\u201d he added. \u201cWe have rich white men from Europe, from the US, writing to children from the Philippines \u2026 they try to get sexual photos in exchange for $10 or $20.\u201d\n\nGina, a contractor, said: \u201cI think it\u2019s a breach of human rights. You cannot ask someone to work fast, to work well and to see graphic content. The things that we saw are just not right.\u201d\n\nThe workers, whose names have been changed, were speaking on condition of anonymity because they had signed non-disclosure agreements with Facebook. Daniel, a former moderator, said: \u201cWe are a sort of vanguard in this field \u2026 It\u2019s a completely new job, and everything about it is basically an experiment.\u201d\n\nJohn, his former colleague, said: \u201cI\u2019m here today because I would like to avoid other people falling into this hole. As a contemporary society, we are running into this new thing \u2013 the internet \u2013 and we have to find some rules to deal with it.\n\n\u201cIt\u2019s important to create a team, for example in a social network, aiming to protect users from abusers, hate speech, racial prejudice, better pornographic software, etc. But I think it\u2019s important to open a debate about this job. We need to share our stories, because people don\u2019t know anything about us, about our job, about what we do to earn a living.\u201d\n\nSome of the moderators\u2019 stories were similar to the problems experienced in other countries. Daniel said: \u201cOnce, I found a colleague of ours checking online, looking to purchase a Taser, because he started to feel scared about others. He confessed he was really concerned about walking through the streets at night, for example, or being surrounded by foreign people.\n\n\u201cMaybe because all this hate speech we have to face every day affects our political view somehow. So a normal person, a liberal person, maybe also a progressive person, can get more conservative, more concerned about issues like migrants for example. Indeed, many of the hate speech contents we receive on a daily basis are fake news \u2026 which aim to share very particular political views.\u201d\n\nIn February, the technology site the Verge produced one of the first behind-the-scenes reports from a US Facebook contractor. Similar to their Berlin colleagues, the Americans reported that \u201cthe conspiracy videos and memes that they see each day gradually led them to embrace fringe views\u201d, and that a former moderator \u201cnow sleeps with a gun at his side\u201d after he was traumatised by a video of a stabbing.\n\nOthers were dealing with trauma by self-medicating. Just as the Arizona moderators were reportedly turning to drugs and alcohol, so were those in Germany. \u201cI saw a lot of big consumer drugs in the company,\u201d Daniel said. \u201cWe don\u2019t have any way to destress. The company, technically, is against drugs.\u201d\n\nWhen trying to go down a more legitimate route of self-help, the American moderators complained about the psychological help that was provided. \u201cThe on-site counsellors were largely passive,\u201d the Verge reporter Casey Newton wrote, \u201crelying on workers to recognise the signs of anxiety and depression and seek help.\u201d\n\nBerlin moderators were also critical of the counselling services provided and suggested they leaned too heavily on the state\u2019s universal healthcare.\n\nDaniel said: \u201cIn the end, we didn\u2019t have proper psychological support. We had some colleagues who went to the [counsellor], and when they showed that they had real problems, they were invited to go outside the company and find a proper psychologist.\u201d\n\nThe Verge report appeared to trigger reforms. Moderators in Berlin said after the article was published there had been immediate interest from Facebook\u2019s head office in their workload. Previously, they had been required to moderate 1,000 pieces of content a day \u2013 more than one every 30 seconds over an eight-hour shift.\n\nIn February, an official from Facebook\u2019s Dublin office visited, John said. \u201cThis person after this meeting decided to take off the limit of 1,000. We didn\u2019t have any limit for a while, but now they have re-established another limit. The limit now is between 400 and 500 tickets.\u201d The new cap \u2013 or number of tickets \u2013 was half that of the previous one but still required workers achieve about a ticket a minute. However, that volume of work was what their American colleagues had faced before the reforms.\n\nBerlin moderators have discussed whether to seek help from the unions, but say the nature of the work makes it difficult. Gina said: \u201cI wouldn\u2019t say no one is interested, but no one has the possibility to do something for real.\u201d\n\nJohn added: \u201cThey are so tired.\u201d\n\nWhile the moderators agreed such work was necessary they said the problems were fixable. \u201cI think it\u2019s important to open a debate about this job,\u201d he said, adding that the solution was simple \u2013 \u201chire more people\u201d.\n\nIn a statement, Facebook said: \u201cContent moderators do vital work to keep our community safe, and we take our responsibility to ensure their wellbeing incredibly seriously. We work closely with our partners to ensure they provide the support people need, including training, psychological support and technology to limit their exposure to graphic content.\n\n\u201cContent moderation is a new and challenging industry, so we are always learning and looking to improve how it is managed. We take any reports that our high standards are not being met seriously and are working to look into these concerns.\u201d\n\n\u2022 In the UK and Ireland, Samaritans can be contacted on 116 123 or email jo@samaritans.org or jo@samaritans.ie. In the US, the National Suicide Prevention Lifeline is 1-800-273-8255. In Australia, the crisis support service Lifeline is 13 11 14. Other international helplines can be found at www.befrienders.org.", "description": "Exclusive: Job has left some \u2018addicted\u2019 to extreme material and pushed others to far right", "authors": ["Alex Hern", "John Naughton"], "top_image": "https://i.guim.co.uk/img/media/bca904f27648161836d90eecaf7ff58ca860ceeb/0_200_6095_3658/master/6095.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=cd2c53d4bc448af21fb5b85a36653720", "published_at": "2019-09-17"}