{"pub": "techcrunch", "url": "https://techcrunch.com/2019/10/28/facebook-is-failing-to-prevent-another-human-rights-tragedy-playing-out-on-its-platform-report-warns", "downloaded_at": "2019-10-29 06:11:14.112133+00:00", "title": "Facebook is failing to prevent another human rights tragedy playing out on its platform, report warns \u2013 TechCrunch", "language": "en", "text": "A report by campaign group Avaaz examining how Facebook\u2019s platform is being used to spread hate speech in the Assam region of North East India suggests the company is once again failing to prevent its platform from being turned into a weapon to fuel ethnic violence.\n\nAssam has a long-standing Muslim minority population but ethnic minorities in the state look increasingly vulnerable after India\u2019s Hindu nationalist government pushed forward with a National Register of Citizens (NRC), which has resulted in the exclusion from that list of nearly 1.9 million people \u2014 mostly Muslims \u2014 putting them at risk of statelessness.\n\nIn July the United Nations expressed grave concern over the NRC process, saying there\u2019s a risk of arbitrary expulsion and detention, with those those excluded being referred to Foreigners\u2019 Tribunals where they have to prove they are not \u201cirregular\u201d.\n\nAt the same time, the UN warned of the rise of hate speech in Assam being spread via social media \u2014 saying this is contributing to increasing instability and uncertainty for millions in the region. \u201cThis process may exacerbate the xenophobic climate while fuelling religious intolerance and discrimination in the country,\u201d it wrote.\n\nThere\u2019s an awful sense of deja-vu about these warnings. In March 2018 the UN criticized Facebook for failing to prevent its platform being used to fuel ethnic violence against the Rohingya people in the neighboring country of Myanmar \u2014 saying the service had played a \u201cdetermining role\u201d in that crisis.\n\nFacebook\u2019s response to devastating criticism from the UN looks like wafer-thin crisis PR to paper over the ethical cracks in its ad business, given the same sorts of alarm bells are being sounded again, just over a year later. (If we measure the company by the lofty goals it attached to a director of human rights policy job last year \u2014 when Facebook wrote that the responsibilities included \u201cconflict prevention\u201d and \u201cpeace-building\u201d \u2014 it\u2019s surely been an abject failure.)\n\nAvaaz\u2019s report on hate speech in Assam takes direct aim at Facebook\u2019s platform, saying it\u2019s being used as a conduit for whipping up anti-Muslim hatred.\n\nIn the report, entitled Megaphone for Hate: Disinformation and Hate Speech on Facebook During Assam\u2019s Citizenship Count, the group says it analysed 800 Facebook posts and comments relating to Assam and the NRC, using keywords from the immigration discourse in Assamese, assessing them against the three tiers of prohibited hate speech set out in Facebook\u2019s Community Standards.\n\nAvaaz found that at least 26.5% of the posts and comments constituted hate speech. These posts had been shared on Facebook more than 99,650 times \u2014 adding up to at least 5.4 million views for violent hate speech targeting religious and ethnic minorities, according to its analysis.\n\nBengali Muslims are a particular target on Facebook in Assam, per the report, which found comments referring to them as \u201ccriminals,\u201d \u201crapists,\u201d \u201cterrorists,\u201d \u201cpigs,\u201d and \u201cdogs\u201d, among other dehumanizing terms.\n\nIn further disturbing comments there were calls for people to \u201cpoison\u201d daughters, and legalise female foeticide, as well as several posts urging \u201cIndian\u201d women to be protected from \u201crape-obsessed foreigners\u201d.\n\nAvaaz suggests its findings are just a drop in the ocean of hate speech that it says is drowning Assam via Facebook and other social media. But it accuses Facebook directly of failing to provide adequate human resource to police hate speech spread on its dominant platform.\n\nCommenting in a statement, Alaphia Zoyab, senior campaigner, said: \u201cFacebook is being used as a megaphone for hate, pointed directly at vulnerable minorities in Assam, many of whom could be made stateless within months. Despite the clear and present danger faced by these people, Facebook is refusing to dedicate the resources required to keep them safe. Through its inaction, Facebook is complicit in the persecution of some of the world\u2019s most vulnerable people.\u201d\n\nIts key complaint is that Facebook continues to rely on AI to detect hate speech which has not been reported to it by human users \u2014 using its limited pool of (human) content moderator staff to review pre-flagged content, rather than proactively detect it.\n\nFacebook founder Mark Zuckerberg has previously said AI has a very long way to go to reliably detect hate speech. Indeed, he\u2019s suggested it may never be able to do that.\n\nIn April 2018 he told US lawmakers it might take five to ten years to develop \u201cAI tools that can get into some of the linguistic nuances of different types of content to be more accurate, to be flagging things to our systems\u201d, while admitting: \u201cToday we\u2019re just not there on that.\u201d\n\nThat sums to an admission that in regions such as Assam \u2014 where inter-ethnic tensions are being whipped up in a politically charged atmosphere that\u2019s also encouraging violence \u2014 Facebook is essentially asleep on the job. The job of enforcing its own \u2018Community Standards\u2019 and preventing its platform being weaponized to amplify hate and harass the vulnerable, to be clear.\n\nAvaaz says it flagged 213 of \u201cthe clearest examples\u201d of hate speech which it found directly to Facebook \u2014 including posts from an elected official and pages of a member of an Assamese rebel group banned by the Indian Government. The company removed 96 of these posts following its report.\n\nIt argues there are similarities in the type of hate speech being directed at ethnic minorities in Assam via Facebook and that which targeted at Rohingya people in Myanmar, also on Facebook, while noting that the context is different. But it did also find hateful content on Facebook targeting Rohingya people in India.\n\nIt is calling on Facebook to do more to protect vulnerable minorities in Assam, arguing it should not rely solely on automated tools for detecting hate speech \u2014 and should instead apply a \u201chuman-led \u2018zero tolerance\u2019 policy\u201d against hate speech, starting by beefing up moderators\u2019 expertise in local languages.\n\nIt also recommends Facebook launch an early warning system within its Strategic Response team, again based on human content moderation \u2014 and do so for all regions where the UN has warned of the rise of hate speech on social media.\n\n\u201cThis system should act preventatively to avert human rights crises, not just reactively to respond to offline harm that has already occurred,\u201d it writes.\n\nOther recommendations include that Facebook should correct the record on false news and disinformation by notifying and providing corrections from fact-checkers to each and every user who has seen content deemed to have been false or purposefully misleading, including if the disinformation came from a politician; that it should be transparent about all page and post takedowns by publishing its rational on the Facebook Newsroom so the issue of hate speech is given proportionate prominence and publicity to the size of the problem on Facebook; and it should agree to an independent audit of hate speech and human rights on its platform in India.\n\n\u201cFacebook has signed up to comply with the UN Guiding Principles on Business and Human Rights,\u201d Avaaz notes. \u201cWhich require it to conduct human rights due diligence such as identifying its impact on vulnerable groups like women, children, linguistic, ethnic and religious minorities and others, particularly when deploying AI tools to identify hate speech, and take steps to subsequently avoid or mitigate such harm.\u201d\n\nWe reached out to Facebook with a series of questions about Avaaz\u2019s report and also how it has progressed its approach to policing inter-ethnic hate speech since the Myanmar crisis \u2014 including asking for details of the number of people it employs to monitor content in the region.\n\nFacebook did not provide responses to our specific questions. It just said it does have content reviewers who are Assamese and who review content in the language, as well as reviewers who have knowledge of the majority of official languages in India, including Assamese, Hindi, Tamil, Telugu, Kannada, Punjabi, Urdu, Bengali and Marathi.\n\nIn 2017 India overtook the US as the country with the largest \u201cpotential audience\u201d for Facebook ads, with 241M active users, per figures it reports the advertisers.\n\nFacebook also sent us this statement, attributed to a spokesperson:\n\nWe want Facebook to be a safe place for all people to connect and express themselves, and we seek to protect the rights of minorities and marginalized communities around the world, including in India. We have clear rules against hate speech, which we define as attacks against people on the basis of things like caste, nationality, ethnicity and religion, and which reflect input we received from experts in India. We take this extremely seriously and remove content that violates these policies as soon as we become aware of it. To do this we have invested in dedicated content reviewers, who have local language expertise and an understanding of the India\u2019s longstanding historical and social tensions. We\u2019ve also made significant progress in proactively detecting hate speech on our services, which helps us get to potentially harmful content faster. But these tools aren\u2019t perfect yet, and reports from our community are still extremely important. That\u2019s why we\u2019re so grateful to Avaaz for sharing their findings with us. We have carefully reviewed the content they\u2019ve flagged, and removed everything that violated our policies. We will continue to work to prevent the spread of hate speech on our services, both in India and around the world.\n\nFacebook did not tell us exactly how many people it employs to police content for an Indian state with a population of more than 30 million people.\n\nGlobally the company maintains it has around 35,000 people working on trust and safety, less than half of whom (~15,000) are dedicated content reviewers. But with such a tiny content reviewer workforce for a global platform with 2.2BN+ users posting night and day all around the world there\u2019s no plausible no way for it to stay on top of its hate speech problem.\n\nCertainly not in every market it operates in. Which is why Facebook leans so heavily on AI \u2014 shrinking the cost to its business but piling content-related risk onto everyone else.\n\nFacebook claims its automated tools for detecting hate speech have got better, saying that in Q1 this year it increased the proactive detection rate for hate speech to 65.4% \u2014 up from 58.8% in Q4 2017 and 38% in Q2 2017.\n\nHowever it also says it only removed 4 million pieces of hate speech globally in Q1. Which sounds incredibly tiny vs the size of Facebook\u2019s platform and the volume of content that will be generated daily by its millions and millions of active users.\n\nWithout tools for independent researchers to query the substance and spread of content on Facebook\u2019s platform it\u2019s simply not possible to know how many pieces of hate speech are going undetected. But \u2014 to be clear \u2014 this unregulated company still gets to mark its own homework.\n\nIn just one example of how Facebook is able to shrink perception of the volume of problematic content it\u2019s fencing, of the 213 pieces of content related to Assam and the NCR that Avaaz judged to be hate speech and reported to Facebook it removed less than half (96).\n\nYet Facebook also told us it takes down all content that violates its community standards \u2014 suggesting it is applying a far more dilute definition of hate speech than Avaaz. Unsurprising for a US company whose nascent crisis PR content review board\u2018s charter includes the phrase \u201cfree expression is paramount\u201d. But for a company that also claims to want to prevent conflict and peace-build it\u2019s rather conflicted, to say the least.\n\nAs things stand, Facebook\u2019s self-reported hate speech performance metrics are meaningless. It\u2019s impossible for anyone outside the company to quantify or benchmark platform data. Because no one except Facebook has the full picture \u2014 and it\u2019s not opening its platform for ethnical audit. Even as the impacts of harmful, hateful stuff spread on Facebook continue to bleed out and damage lives around the world.", "description": "A report by campaign group Avaaz examining how Facebook\u2019s platform is being used to spread hate speech in the Assam region of North East India suggests the company is once again failing to prevent its platform from being turned into a weapon to fuel ethnic violence. Assam has a long-standing Muslim minority population but ethnic [\u2026]", "authors": [], "top_image": "https://techcrunch.com/wp-content/uploads/2019/10/GettyImages-1177748098.jpg?w=600", "published_at": "2019-10-28"}