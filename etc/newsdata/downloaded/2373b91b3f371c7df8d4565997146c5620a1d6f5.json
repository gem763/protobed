{"pub": "zdnet", "url": "https://www.zdnet.com/article/hpe-launches-ml-ops-container-software-service", "downloaded_at": "2019-09-10 23:34:08.179067+00:00", "title": "HPE launches ML Ops container software service", "language": "en", "text": "Hewlett Packard Enterprise (HPE) on Tuesday introduced HPE ML Ops, a container-based software service that stems from its BlueData acquisition a year ago. HPE said ML Ops aims to provide a DevOps-like process to standardize machine learning workflows and accelerate AI deployments.\n\nThe ML Ops service is meant to extend the capabilities of BlueData's EPIC software platform, which allows enterprises to create Hadoop and Spark clusters in virtual environments. The pitch with EPIC is that the combination of Docker containers, virtualization and big data tools makes it easier to deploy within data centers.\n\nThe launch of ML Ops lines up with HPE's strategy that it set forth when it bought BlueData, which was to combine BlueData's software platform with its existing software-defined infrastructure to offer customers an container-based service for AI, machine learning and big data analytics.\n\n\"Only operational machine learning models deliver business value,\" said Kumar Sreekanti, SVP and CTO of Hybrid IT at HPE. \"And with HPE ML Ops, we provide the only enterprise-class solution to operationalize the end-to-end machine learning lifecycle for on-premises and hybrid cloud deployments. We're bringing DevOps speed and agility to machine learning, delivering faster time-to-value for AI in the enterprise.\"\n\nHPE said ML Ops works with a range of open source machine learning and deep learning frameworks, including Keras, MXNet, PyTorch, and TensorFlow, along with commercial machine learning applications from Dataiku and H2O.ai. The service is generally available now as a software subscription, together with HPE Pointnext Services and customer support.", "description": "The ML Ops service is meant to extend the capabilities of BlueData's EPIC software platform, which allows enterprises to create Hadoop and Spark clusters in virtual environments.", "authors": ["Natalie Gagliordi"], "top_image": "https://zdnet1.cbsistatic.com/hub/i/r/2019/09/10/3a81d645-3fe9-488a-8037-8554bdc6df4b/thumbnail/770x578/151d9e2f054e9c62e7443e9d84ed190b/hpe-ml-ops.jpg", "published_at": "2019-09-10"}