{"pub": "bbc", "url": "https://bbc.com/news/technology-50129402", "downloaded_at": "2019-10-28 07:36:41.465658+00:00", "title": "Molly Russell: Instagram extends self-harm ban to drawings", "language": "en", "text": "Media playback is unsupported on your device Media caption Molly Russell's father Ian travels to the United States and meets other parents bereaved by suicide\n\nInstagram has pledged to remove images, drawings and even cartoons showing methods of self-harm or suicide.\n\nThe move is its latest response to the public outcry over the death of British teenager Molly Russell.\n\nThe 14-year-old killed herself in 2017 after viewing graphic content on the platform.\n\nMolly's father has described the Facebook-owned app's commitment as \"sincere\" but said managers needed to act more swiftly.\n\nImage copyright Russell Family Image caption Molly Russell's father believes her use of Instagram was a factor in her suicide\n\nInstagram's latest promise covers explicit drawings, cartoons and memes about suicide, in addition to any other method \"promoting\" self-harm.\n\n\"It will take time to fully implement... but it's not going to be the last step we take,\" Instagram chief Adam Mosseri told BBC News.\n\nImage caption Adam Mosseri took charge of Instagram in October 2018\n\nIt extends measures announced in February, which banned \"graphic images of self-harm\" and restricted those with suicidal themes. This included both stills and videos.\n\nInstagram has been under pressure to act after Mr Russell said he believed the US-based service had been partly responsible for his daughter's death.\n\nAfter she died, Mr Russell found large amounts of graphic material about self-harm and suicide on her Instagram account. He also found similar content on her Pinterest login.\n\nThe 56-year-old went public in January of this year.\n\nThe UK government, charities and the media were among those who subsequently called on Instagram and other technology companies to make changes.\n\n'Lack of responsibility'\n\nInstagram's latest announcement coincided with a visit by Mr Russell to Silicon Valley.\n\nThere, he told BBC News: \"The big platforms really don't seem to be doing much about it.\"\n\nImage caption Ian Russell discussed online safety with schoolchildren in New Jersey on a recent trip to the US\n\nDuring his visit, Florida-based internet safety campaigner and paediatrician Dr Free Hess showed him content still available on Instagram.\n\nIt included graphic photographs, videos of self-harm and cartoons advocating suicide.\n\nShe said hashtags had helped lead young people to the content.\n\n\"It's grooming that young person to self-harm more, consider suicide more,\" the doctor said.\n\nIan responded: \"I was rather hoping that the steps taken would made it at least harder to find that stuff.\"\n\nMr Russell also met Jim Steyer, the founder of Common Sense Media - the US's largest charity dealing with child safety online.\n\n\"The lack of responsibility of the social media platforms is absolutely mindboggling,\" said Mr Steyer, who wants new regulations to be imposed on the companies.\n\nInstagram response\n\nInstagram says it has doubled the amount of material removed related to self-harm and suicide since the first quarter of 2019.\n\nBetween April and June this year, it said, it had removed 834,000 pieces of content, 77% of which had not been reported by users.\n\n\"There is still very clearly more work to do, this work never ends,\" said Mr Mosseri.\n\nTo which Mr Russell responded: \"I just hope he delivers.\"\n\nIf you've been affected by self-harm, eating disorders or emotional distress, help and support is available via the BBC Action Line.", "description": "The father of a teenager who killed herself after viewing graphic images says the app needs to act.", "authors": ["Angus Crawford", "Bbc News"], "top_image": "https://ichef.bbci.co.uk/images/ic/1024x576/p07s6vml.jpg", "published_at": "2019-10-28"}