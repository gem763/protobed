{"pub": "atlantic", "url": "https://theatlantic.com/science/archive/2019/09/people-speak-faster-less-efficient-languages/597391", "downloaded_at": "2019-09-04 23:40:39.603540+00:00", "title": "A Rare Universal Pattern in Human Languages", "language": "en", "published_at": "2019-09-04", "text": "Read: The randomness of language evolution\n\nThe basic problem of \u201cefficiency,\u201d in linguistics, starts with the trade-off between effort and communication. It takes a certain amount of coordination, and burns a certain number of calories, to make noises come out of your mouth in an intelligible way. And those noises can be more or less informative to a listener, based on how predictable they are. If you and I are discussing dinosaurs, you wouldn\u2019t be surprised to hear me rattle off the names of my favorite species. But if a stranger walks up to you on the street and announces, \u201cDiplodocus!\u201d it\u2019s unexpected. It narrows the scope of possible conversation topics greatly and is therefore highly informative.\n\nInformativity in linguistics is usually calculated per syllable, and it\u2019s measured in bits, just like computer files. The concept can be rather slippery when you\u2019re talking about talking, but essentially, a bit of linguistic information is the amount of information that reduces uncertainty by half. In other words, if I utter a syllable, and that utterance narrows down the set of things I could be talking about from everything in the world to only half the things in the world, that syllable carries one bit of information.\n\nIn the new study, the authors calculated the average information density\u2014that is, bits per syllable\u2014of a set of 17 Eurasian languages and compared it with the average speech rate, in syllables per second, of 10 speakers for each language. They found that the rate of information transferred stayed constant\u2014at about 39.15 bits per second, to be exact.\n\nFran\u00e7ois Pellegrino, the senior author of the new study, says linguists aren\u2019t likely to be surprised to learn that there\u2019s a trade-off between speech rate and information density: \u201cIt just confirms what the intuition would be.\u201d But what\u2019s special about his and his team\u2019s work is that, for the first time, they were able \u201cto prove that it holds\u201d for this set of languages.\n\nThe speed-efficiency trade-off is likely to be fodder for a long-standing debate among linguists about what language is, and what it\u2019s for. \u201cOne of the big divisions in the field of linguistics right now is whether it\u2019s useful to think about language as a code for communication or whether it\u2019s more useful to think about language as something like a mathematical language,\u201d says Richard Futrell, an assistant language-science professor at UC Irvine. This controversy is often described as a fight over whether linguistic universals exist: The language-as-math camp, a.k.a. the generativists, follow in the footsteps of Noam Chomsky and think that certain grammatical rules apply to all languages, while the language-as-communication camp, a.k.a. the functionalists, think that\u2019s bunk.\n\nRead: How \u2018F\u2019 sounds might break a fundamental rule of linguistics", "description": "Some languages are spoken more quickly than others, but the rate of information they get across is the same.", "authors": ["Rachel Gutman"], "top_image": "https://cdn.theatlantic.com/assets/media/img/mt/2019/09/GettyImages_514976174/facebook.jpg?1567621839"}