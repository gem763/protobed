{"pub": "zdnet", "url": "https://www.zdnet.com/article/trying-to-augment-intelligence-with-ai-fails-when-data-scientists-and-designers-dont-collaborate", "downloaded_at": "2019-09-23 19:13:44.814920+00:00", "title": "Trying to augment intelligence with AI fails when data scientists and designers don\u2019t collaborate", "language": "en", "text": "Digital transformation: Four most disruptive technologies Thomas Siebel, author and CEO of C3.ai, tells Tonya Hall about four of the most disruptive technologies in digital transformation and their effects in the tech industry.\n\nAugmenting human intelligence is the fastest way to get value from AI. The problem? Human-centered design (HCD) is missing from most attempts to augment human intelligence.\n\nSure, the AI teams doing this work sincerely care about humans -- but that's not the same thing as knowing and applying proven HCD methods like iterative prototyping paired with a disciplined observation of users. Think about it this way: What if designers believed they could produce rock-solid code because they care about quality, not recognizing that software quality requires proven software engineering methods?\n\nLet's examine the evidence:\n\nResearch from Carnegie Mellon reports: Despite success in labs, many clinician-facing decision support tools failed when moving to clinical practice; researchers identified a lack of HCI consideration, rather than poor technical performance, as the main cause for these failures. (HCI means human-computer interaction.)\n\nA researcher at Stanford points out it's a problem in the legal world, too. Legal professionals ask: \"Why should they follow the recommendations of a model built by a company that they know nothing about, using data they do not control?\" The issue here isn't the source of the data; it's that somewhere along the way, users' functional and emotional goals aren't being met.\n\nThere are many other examples out there. Argodesign founder Mark Rolston pointed out that this kind of augmentation is one of the most interesting design challenges today. He asked, \"How do you educate users that the machine might be wrong?\" His perspective: \"If the interface is constructed right, being wrong is OK.\"\n\nWe agree because getting the user interface right means ensuring that users know when a computer is simply presenting existing information as opposed to recommendations that are speculative because they're based on an educated guess derived from detecting patterns in data.\n\nArgodesign tackled this in the Sano wearable -- a device focused on glucose monitoring for diabetics that gives them guidance and recommendations, with helpful markers in this spirit. The app includes dotted lines to indicate predicted blood sugar, solid lines to show previous days, a confidence score, and recommended corrective actions. Argodesign isn't the only design provider working on this challenge -- other services companies have recognized the need and are creating offerings focused on designing for augmented intelligence.\n\nDon't forget to register for CX SF where Forrester plans to dig into how perceptions shape successful innovation, growth, engagement, satisfaction, and retention -- and what you can do about it.\n\nThis post was written by Principal Analyst Andrew Hogan, and originally appeared here.\n\n\n\n", "description": "Companies are starting to combine data science and design to create data-fueled products based on pattern-finding algorithms.", "authors": ["Forrester Research"], "top_image": "https://zdnet1.cbsistatic.com/hub/i/r/2019/09/23/7a1cf24f-643c-40be-a8eb-f74fe89cd600/thumbnail/770x578/83df19fa1501c6edb52f604f0756981f/istock-1025745040.jpg", "published_at": "2019-09-23"}