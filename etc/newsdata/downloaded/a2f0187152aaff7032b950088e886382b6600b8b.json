{"pub": "washingtonpost", "url": "https://washingtonpost.com/technology/2019/09/04/an-artificial-intelligence-first-voice-mimicking-software-reportedly-used-major-theft", "downloaded_at": "2019-09-04 23:48:12.743415+00:00", "published_at": "2019-09-04", "title": "An artificial-intelligence first: Voice-mimicking software reportedly used in a major theft", "language": "en", "text": "The request was \u201crather strange,\u201d the director noted later in an email, but the voice was so lifelike that he felt he had no choice but to comply. The insurer, whose case was first reported by the Wall Street Journal, provided new details on the theft to The Washington Post on Wednesday, including an email from the employee tricked by what the insurer is referring to internally as \u201cthe false Johannes.\u201d\n\nAD\n\nAD\n\nNow being developed by a wide range of Silicon Valley titans and AI start-ups, such voice-synthesis software can copy the rhythms and intonations of a person\u2019s voice and be used to produce convincing speech. Tech giants such as Google and smaller firms such as the \u201cultrarealistic voice cloning\u201d start-up Lyrebird have helped refine the resulting fakes and made the tools more widely available free for unlimited use.\n\nBut the synthetic audio and AI-generated videos, known as \u201cdeepfakes,\u201d have fueled growing anxieties over how the new technologies can erode public trust, empower criminals and make traditional communication \u2014 business deals, family phone calls, presidential campaigns \u2014 that much more vulnerable to computerized manipulation.\n\n\u201cCriminals are going to use whatever tools enable them to achieve their objectives cheapest,\u201d said Andrew Grotto, a fellow at Stanford University\u2019s Cyber Policy Center and a senior director for cybersecurity policy at the White House during the Obama and Trump administrations.\n\nAD\n\nAD\n\n\u201cThis is a technology that would have sounded exotic in the extreme 10 years ago, now being well within the range of any lay criminal who's got creativity to spare,\u201d Grotto added.\n\nViral Chinese app Zao puts your face in place of Leonardo DiCaprio\u2019s in \u2018deepfake\u2019 videos\n\nDevelopers of the technology have pointed to its positive uses, saying it can help humanize automated phone systems and help mute people speak again. But its unregulated growth has also sparked concern over its potential for fraud, targeted hacks and cybercrime.\n\nResearchers at the cybersecurity firm Symantec said they have found at least three cases of executives\u2019 voices being mimicked to swindle companies. Symantec declined to name the victim companies or say whether the Euler Hermes case was one of them, but it noted that the losses in one of the cases totaled millions of dollars.\n\nAD\n\nThe systems work by processing a person\u2019s voice and breaking it down into components, like sounds or syllables, that can then be rearranged to form new phrases with similar speech patterns, pitch and tone. The insurer did not know which software was used, but a number of the systems are freely offered on the Web and require little sophistication, speech data or computing power.\n\nAD\n\nLyrebird, for instance, advertises the \u201cmost realistic artificial voices in the world\u201d and allows anyone to create a voice-mimicking \u201cvocal avatar\u201d by uploading at least a minute of real-world speech.\n\nThe company, which did not respond to requests for comment, has defended releasing the software widely, saying it will help acclimate people to the new reality of a fast-improving and \u201cinevitable\u201d technology \u201cso that society can adapt.\u201d In an ethics statement, the company wrote: \u201cImagine that we had decided not to release this technology at all. Others would develop it and who knows if their intentions would be as sincere as ours.\u201d\n\nAD\n\nTop AI researchers race to detect \u2018deepfake\u2019 videos: \u2018We are outgunned\u2019\n\nSaurabh Shintre, a senior researcher who studies such \u201cadversarial attacks\u201d in Symantec\u2019s California-based research lab, said the audio-generating technology has in recent years made \u201ctransformative\u201d progress because of breakthroughs in how the algorithms process data and compute results. The amount of recorded speech needed to train the voice-impersonating tools to produce compelling mimicries, he said, is also shrinking rapidly.\n\nAD\n\nThe technology is imperfect, and some of the faked voices wouldn\u2019t fool a listener in a \u201ccalm, collected environment,\u201d Shintre said. But in some cases, thieves have employed methods to explain the quirks away, saying the fake audio\u2019s background noises, glitchy sounds or delayed responses are the result of the speaker\u2019s being in an elevator or car or in a rush to catch a flight.\n\nBeyond the technology\u2019s capabilities, the thieves have also depended on age-old scam tactics to boost their effectiveness, using time pressure, such as an impending deadline, or social pressure, such as a desire to appease the boss, to make the listener move past any doubts. In some cases, criminals have targeted the financial gatekeepers in company accounting or budget departments, knowing they may have the capability to send money instantly.\n\nAD\n\n\u201cWhen you create a stressful situation like this for the victim, their ability to question themselves for a second \u2014 \u2018Wait, what the hell is going on? Why is the CEO calling me?\u2019 \u2014 goes away, and that lets them get away with it,\u201d Shintre said.\n\nAD\n\nA Google program can pass as a human on the phone. Should it be required to tell people it\u2019s a machine?\n\nEuler Hermes representatives said the company, a German energy firm\u2019s subsidiary in Britain, contacted law enforcement but has yet to name any potential suspects. The insurer, which sells policies to businesses covering fraud and cybercrime, said it is covering the company\u2019s full claim.\n\nThe victim director was first called late one Friday afternoon in March, and the voice demanded he urgently wire money to a supplier in Hungary to help the company avoid late-payment fines. The fake executive referred to the director by name and sent the financial details by email.\n\nAD\n\nThe director and his boss had spoken directly a number of times, said Euler Hermes spokeswoman Antje Wolters, who noted that the call was not recorded. \u201cThe software was able to imitate the voice, and not only the voice: the tonality, the punctuation, the German accent,\u201d she said.\n\nAD\n\nAfter the thieves made a second request, the director grew suspicious and called his boss directly. Then the thieves called back, unraveling the ruse: The fake \u201c \u2018Johannes\u2019 was demanding to speak to me whilst I was still on the phone to the real Johannes!\u201d the director wrote in an email the insurer shared with The Post.\n\nFake-porn videos are being weaponized to harass and humiliate women: \u2018Everybody is a potential target\u2019\n\nThe money, totaling 220,000 euros, was funneled through accounts in Hungary and Mexico before being scattered elsewhere, Euler Hermes representatives said. No suspects have been named, the insurer said, and the money has disappeared.\n\nAD\n\nAI developers are working to build systems that can detect and combat fake audio, but the voice-mimicking technology is evolving rapidly. Google, for instance, has invested in research and has funded challenges to automatically recognize \u201cspoofed\u201d speech. But the company has also developed some of the world\u2019s most persuasive voice AI, including its Duplex service, which can call restaurants to book a table using a lifelike, computer-generated voice.\n\nAD\n\n\u201cThere\u2019s a tension in the commercial space between wanting to make the best product and considering the bad applications that product could have,\u201d said Charlotte Stanton, the director of the Silicon Valley office of the Carnegie Endowment for International Peace. \u201cResearchers need to be more cautious as they release technology as powerful as voice-synthesis technology, because clearly it\u2019s at a point where it can be misused.\"\n\nDig deeper: New Technology + Privacy\n\nAD\n\nWant to explore the impact of new technology on our privacy? Check out our curated list of stories below.\n\nUnderstanding how facial recognition software can affect law enforcement\n\nAn Oregon sheriff\u2019s department became the first law enforcement agency in the country to use Amazon\u2019s facial-recognition software, running 1,000 searches in a year to help solve crimes. But experts fear it could increase wrongful arrests.\n\nAD\n\nHow businesses market surveillance software to schools\n\nThere is no proof that facial-recognition software can prevent school shootings, yet companies are building sales pitches to schools around the promise of keeping children safe from school shooters.\n\nGet smart about your browser\u2019s privacy issues\n\nOur tech reviewer found more than 11,000 requests in a week for trackers from websites in Google Chrome. The browser even welcomed trackers from websites you would think were private, like Aetna and the Federal Student Aid website.", "description": "Once the realm of science fiction, voice-mimicking software is now \"well within the range of any lay criminal who's got creativity to spare,\u201d one cybersecurity expert said.", "authors": ["Drew Harwell", "Reporter Covering Artificial Intelligence"], "top_image": "https://www.washingtonpost.com/resizer/XM2LUqYFwE3bMyNjLtVImrwX2lk=/1440x0/smart/arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/GGEVGZT5WAI6RJR7PNOSVOT2YU.jpg"}