{"pub": "theverge", "url": "https://theverge.com/2018/6/22/17487764/adobe-photoshopped-fakes-edit-spotted-using-machine-learning-ai", "downloaded_at": "2019-10-05 14:51:38.727328+00:00", "title": "Adobe is using machine learning to make it easier to spot Photoshopped images", "language": "en", "text": "Experts around the world are getting increasingly worried about new AI tools that make it easier than ever to edit images and videos \u2014 especially with social media\u2019s power to share shocking content quickly and without fact-checking. Some of those tools are being developed by Adobe, but the company is also working on an antidote of sorts by researching how machine learning can be used to automatically spot edited pictures.\n\nThe company\u2019s latest work, showcased this month at the CVPR computer vision conference, demonstrates how digital forensics done by humans can be automated by machines in much less time. The research paper does not represent a breakthrough in the field, and it\u2019s not yet available as a commercial product, but it\u2019s interesting to see Adobe \u2014 a name synonymous with image editing \u2014 take an interest in this line of work.\n\nSpeaking to The Verge, a spokesperson for the company said that this was an \u201cearly-stage research project,\u201d but in the future, the company wants to play a role in \u201cdeveloping technology that helps monitor and verify authenticity of digital media.\u201d Exactly what this might mean isn\u2019t clear, since Adobe has never before released software designed to spot fake images. But, the company points to its work with law enforcement (using digital forensics to help find missing children, for example) as evidence of its responsible attitude toward its technology.\n\nThe new research paper shows how machine learning can be used to identify three common types of image manipulation: splicing, where two parts of different images are combined; cloning, where objects within an image are copy and pasted; and removal, when an object is edited out altogether.\n\nTo spot this sort of tampering, digital forensics experts typically look for clues in hidden layers of the image. When these sorts of edits are made, they leave behind digital artifacts, like inconsistencies in the random variations in color and brightness created by image sensors (also known as image noise). When you splice together two different images, for example, or copy and paste an object from one part of an image to another, this background noise doesn\u2019t match, like a stain on a wall covered with a slightly different paint color.\n\nAs with many other machine learning systems, Adobe\u2019s was taught using a large dataset of edited images. From this, it learned to spot the common patterns that indicate tampering. It scored higher in some tests than similar systems built by other teams, but not dramatically so. However, the research has no direct application in spotting deepfakes, a new breed of edited videos created using artificial intelligence.\n\n\u201cThe benefit of these new ML approaches is that they hold the potential to discover artifacts that are not obvious and not previously known,\u201d digital forensics expert Hany Farid told The Verge. \u201cThe drawback of these approaches is that they are only as good as the training data fed into the networks, and are, for now at least, less likely to learn higher-level artifacts like inconsistencies in the geometry of shadows and reflections.\u201d\n\nThese caveats aside, it\u2019s good to see more research being done that can help us spot digital fakes. If those sounding the alarm are right and we\u2019re headed to some sort of post-truth world, we\u2019re going to need all the tools we can get to sort fact from fiction. AI can hurt, but it can help as well.", "description": "Experts are worried that AI is making it easier than ever to edit images and videos. But can machine learning help spot fakes too? New research from Photoshop-creator Adobe suggests this is the case.", "authors": ["James Vincent", "Jun"], "top_image": "https://cdn.vox-cdn.com/thumbor/sMN-ba_XRrHFLPLg-BdmYBK9Cys=/0x117:2404x1376/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/11581897/photoshopped_iran_missile_launch.jpg", "published_at": "2018-06-22"}