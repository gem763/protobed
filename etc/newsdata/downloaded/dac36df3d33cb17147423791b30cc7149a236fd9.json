{"pub": "vice", "url": "https://vice.com/en_us/article/vb5ny9/deepminds-starcraft-ii-ai-is-now-better-than-9998-of-human-players", "downloaded_at": "2019-10-30 23:21:08.294288+00:00", "title": "DeepMind's 'Starcraft II' AI Is Now Better Than 99.98% of Human Players", "language": "en", "text": "DeepMind has trained an AI agent that plays StarCraft II at the Grandmaster level\u2014better than 99.98 percent of human players, the machine-learning-focused Google spinoff announced in a new paper\n\nAlphaStar, the AI in question, achieved its Grandmaster status the old fashioned way: grinding through dozens of matches against human opponents, the paper, published on Wednesday in Nature, explains.\n\nThis isn\u2019t DeepMind\u2019s first foray into designing AI to play StarCraft II. AlphaStar took on human opponents in a series of high profile games in January. AlphaStar crushed its human competition, but the AI was still operating with some restrictions\u2014it only knew how to play Protoss, one of Starcraft II\u2019s three factions, and could only play against Protoss. But now those restrictions are gone. AlphaStar can handle Zerg, Protoss, and Terran.\n\nAlphaStar worked its way up the European StarCraft II ladder on Battle.net, Blizzard\u2019s online gaming network. In a July blog post, Blizzard informed players competing in Europe that they may encounter the bot, but that it would remain anonymous during games, and allowed players to opt out of competing against AlphaStart. \u201cThe majority of players opted in,\u201d researchers noted in their article.\n\nThe AI system was designed to match the physical limitations of a human opponent. AlphaStar viewed each match through what researchers called a \u201ccamera-like interface\u201d similar to how humans see the game\u2019s playing field, meaning that the AI didn\u2019t have perfect, omnipresent knowledge of the game and had to \u201cchoose\u201d where to focus its attention.\n\nIts actions per minute (APM) were also restricted, meaning it could only perform a set amount of tasks every second. AlphStar could only complete 22 non-duplicate actions in a five second window, putting it in league with human players. DeepMind also added a 110 millisecond delay between observing a frame and executing an action, which accounted for human latency.\n\nHuman pros who played against the AI approved of this approach. \u201cWhile AlphaStar has excellent and precise control, it doesn\u2019t feel superhuman\u2014certainly not on a level that a human couldn\u2019t theoretically achieve,\u201d Dario \u2018TLO\u2019 W\u00fcnsch, a Team Liquid Starcraft II pro, said in a statement. \u201cOverall, it feels very fair\u2014like it is playing a \u2018real\u2019 game of StarCraft.\u201d\n\nDeepMind spokespeople weren\u2019t immediately available to comment.\n\nAlphaStar is based on a deep learning architecture that \u201clearns\u201d to complete tasks\u2014in this case, play Starcraft II well\u2014after hoovering up a ton of data.\n\nDeepMind trained AlphaStar in phases, the researchers explain in the paper. It started by making the AI \u201cwatch\u201d 971,000 StarCraft II replays. Each replay involved players with a high Match Making Ranking (MMR)\u2014the number Blizzard assigns to a player based on their skill level. Because of this, AlphaStar was watching replays from the top 22% of StarCraft II players. After AlphStar watched those replays, DeepMind added 16,000 more replays from games with players at even higher MMRs.\n\nThen, DeepMind created a league full of AI challengers and pit AlphaStar against itself to get even better at the game. To create a diverse opponent base, the team froze instances of AlphaStar at various points in its training and entered them into the game as new opponents.\n\nThroughout this process, DeepMind peeled off instances of AlphaStar and send them to Battle.net for evaluation using anonymous accounts. The first AlphaStar entered Battle.net after watching replays, but before participating in an AI league, and played 30 games. A more developed AlphaStar version was pulled out of competition after 50 games because, the paper notes, its cover was blown.\n\nThe last iteration\u2014AlphaStar Final\u2014used several fake accounts to help keep the AIs anonymous. It was this AI that achieved Grandmaster level, the highest ranking available in StarCraft II.\n\nAccording to StarCraft II pros, more exciting than the ranking are the ways AlphaStar Final innovated on existing tactics and strategy.\n\n\u201cIt was also exciting to see the agent develop its own strategies differently from the human players\u2014like the way AlphaStar builds more workers than its base can support early in the game in preparation for later expansion,\u201d Team Liquid player Grzegorz \u201cMaNa\u201d Komincz said in a statement. \u201cThe caps on the actions it can take and the camera view restrictions now make for compelling games\u2014even though, as a pro, I can still spot some of the system\u2019s weaknesses.\"\n\nDeepMind\u2019s researchers believe StarCraft II is a stepping stone to greater and more complex problems. AlphaStar\u2019s ability to handle a game as complicated as StarCraft II is a sign that artificial intelligence may be able to manage complex problems, such as navigating America\u2019s roads in a self-driving car.\n\n\u201cThe game\u2019s complexity is much greater than chess, because players control hundreds of units; more complex than Go, because there are 10^26 possible choices for every move; and players have less information about their opponents than in poker,\u201dDavid Silver, principal research scientist at DeepMind, said in a statement.", "description": "AlphaStar achieved Grandmaster status the old fashioned way: grinding through matches with human opponents to move up the leaderboard.", "authors": [], "top_image": "https://video-images.vice.com/articles/5db9ceb28a4620008dd4eb11/lede/1572458380739-sdfsdfsd.jpeg?crop=0.9332xw:0.9988xh;0.022xw,0xh&resize=1200:*", "published_at": "2019-10-30"}