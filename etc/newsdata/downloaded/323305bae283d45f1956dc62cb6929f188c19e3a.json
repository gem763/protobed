{"pub": "news24", "url": "https://fin24.com/Companies/ICT/amazon-workers-may-be-watching-your-cloud-cam-home-footage-20191010", "downloaded_at": "2019-10-10 15:00:45.357756+00:00", "title": "Amazon workers may be watching your cloud cam home footage", "language": "en", "text": "In a promotional video, Amazon.com says its Cloud Cam home security camera provides \u201ceverything you need to monitor your home, day or night.\u201d In fact, the artificially intelligent device requires help from a squad of invisible employees.\n\nDozens of Amazon workers based in India and Romania review select clips captured by Cloud Cam, according to five people who have worked on the program or have direct knowledge of it. Those video snippets are then used to train the AI algorithms to do a better job distinguishing between a real threat (a home invader) and a false alarm (the cat jumping on the sofa).\n\nAn Amazon team also transcribes and annotates commands recorded in customers\u2019 homes by the company\u2019s Alexa digital assistant, Bloomberg reported in April.\n\nAI has made it possible to talk to your phone. It\u2019s helping investors predict shifts in market sentiment. But the technology is far from infallible. Cloud Cam sends out alerts when it\u2019s just paper rustling in a breeze. Apple\u2019s Siri and Amazon\u2019s Alexa still occasionally mishear commands. One day, engineers may overcome these shortfalls, but for now AI needs human assistance. Lots of it.\n\nAt one point, on a typical day, some Amazon auditors were each annotating about 150 video recordings, which were typically 20 to 30 seconds long, according to the people, who requested anonymity to talk about an internal program.\n\nThe clips sent for review come from employee testers, an Amazon spokesperson said, as well as Cloud Cam owners who submit clips to troubleshoot such issues as inaccurate notifications and video quality. \u201cWe take privacy seriously and put Cloud Cam customers in control of their video clips,\u201d she said, adding that unless the clips are submitted for troubleshooting purposes, \u201conly customers can view their clips.\u201d\n\nNowhere in the Cloud Cam user terms and conditions does Amazon explicitly tell customers that human beings are training the algorithms behind their motion detection software.\n\nAnd despite Amazon\u2019s insistence that all the clips are provided voluntarily, according to two of the people, the teams have picked up activity homeowners are unlikely to want shared, including rare instances of people having sex.\n\nClips containing inappropriate content are flagged as such, then discarded so they aren\u2019t accidentally used to train the AI, the people said. Amazon's spokeswoman said such clips are scrapped to improve the experience of the company's human reviewers, but she didn't say why unsuitable activity would appear in voluntarily submitted video clips.\n\nThe workers said Amazon has imposed tight security on the Cloud Cam annotation operation. In India, dozens of reviewers work on a restricted floor, where employees aren\u2019t allowed to use their mobile phones, according to two of the people. But that hasn\u2019t stopped other employees from passing footage to non-team members, another person said.\n\nThe Cloud Cam debuted in 2017 and, along with the Alexa-powered line of Echo speakers, is one of several gadgets Amazon hopes will give it an edge in the emerging smart-home market.\n\nThe $120 (R1800) device detects and alerts people to activity going on in their homes and offers them free access to the footage for 24 hours. Users willing to pay about $7 to $20 (R100 - R300) for a monthly subscription can extend that access for as long as one month and receive tailored alerts-for a crying baby, say, or a smoke alarm. Amazon doesn\u2019t reveal how many Cloud Cams it sells, but the device is just one of many home security cams on the market, from Google\u2019s Nest to Amazon-owned Ring.\n\nWhile AI algorithms are getting better at teaching themselves, Amazon-like many companies-deploys human trainers across its businesses; they help Alexa understand voice commands, teach the company\u2019s automated Amazon Go convenience stores to distinguish one shopper from another and are even working on experimental voice software designed to detect human emotions.\n\nUsing humans to train the artificial intelligence inside consumer products is controversial among privacy advocates because of concerns its use can expose personal information. The revelation that an Amazon team listens to Alexa voice commands and subsequent disclosures about similar review programs at Google and Apple prompted attention from European and American regulators and lawmakers. The uproar even spurred some Echo owners to unplug their devices.\n\nAmid the backlash, both Apple and Google paused their own human review programs. For its part, Amazon began letting Alexa users exclude their voice recordings from manual review and changed its privacy policies to include an explanation that humans may listen to their recordings.\n\nReports by the Information and the Intercept technology websites in the last year examined the human role in training the software behind security cameras built by Ring. The sites reported that employees used clips customers had shared through a Ring app to train computer vision algorithms, and, in some cases, shared unencrypted customer videos with each other.\n\nAmazon doesn\u2019t tell customers much about its troubleshooting process for Cloud Cam. In its terms and conditions, the company reserves the right to process images, audio and video captured by devices to improve its products and services.\n\nIn a Q&A about Cloud Cam on its website, Amazon says \u201conly you or people you have shared your account information with can view your clips, unless you choose to submit a clip to us directly for troubleshooting. Customers can also choose to share clips via email or social media.\u201d\n\nThe Cloud Cam teams in India and Romania don\u2019t know how the company selects clips to be annotated, according to three of the people, but they said there were no obvious technical glitches in the footage that would require submitting it for troubleshooting purposes.\n\nAt an industry event this week, David Limp, who runs Amazon\u2019s Alexa and hardware teams, acknowledged that the company could have been more forthcoming about using people to audit AI. \u201cIf I could go back in time, that would be the thing I would do better,\u201d he said. \u201cI would have been more transparent about why and when we are using human annotation.\u201d", "description": "In a promotional video, Amazon.com says its Cloud Cam home security camera provides \u201ceverything you need to monitor your home, day or night.\u201d In fact, the artificially intelligent device requires help from a squad of invisible employees.", "authors": ["Natalia Drozdiak", "Giles Turner", "Matt Day"], "top_image": "http://cdn.24.co.za/files/Cms/General/d/9220/b49b36995a084e0ea6e3fa188dec7fa5.jpg", "published_at": "2019-10-10"}