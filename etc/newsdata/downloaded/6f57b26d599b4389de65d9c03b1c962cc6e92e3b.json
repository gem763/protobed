{"pub": "zdnet", "url": "https://www.zdnet.com/article/deepfakes-for-now-women-are-the-main-victim-not-democracy", "downloaded_at": "2019-10-07 20:01:03.153395+00:00", "title": "Deepfakes: For now women are the main victim, not democracy", "language": "en", "text": "Facebook offers $10 million in research grants for tech to detect deepfake videos Facebook will create its own deepfake videos to help build a system that can detect them.\n\nWhile the 2020 US presidential elections have lawmakers on edge over AI-generated fake videos, a new study by Netherlands-based deepfake-detection outfit Deeptrace shows that the main victims today are women.\n\nReddit, the site where the term deepfake was coined, in early 2018 banned deepfake porn or 'involuntary porn', which largely relies on generative adversarial networks (GANs) to insert the face of a woman into existing pornographic material.\n\nDespite Reddit's influence on internet culture the ban hasn't stopped the emergence of deepfake porn. New apps like DeepNude \u2013 an app that quickly undressed a woman in an image \u2013 have since popped up as techies experiment with GANs. The problem is that the apps can be used to harass and intimidate women.\n\nAlthough there's the obvious threat that deepfakes pose to democratic processes, the tech is also being applied in unexpected ways, such as CEO fraud using synthesized voice \u2013 a hugely costly type of fraud that has traditionally played out over email.\n\nAccording to Deeptrace, deepfake videos have exploded in the past year, rising from 8,000 in December 2018 to 14,678 today. And not surprisingly for the internet, nearly all of the material is pornography, which accounts for 96% of the deepfake videos it's found online. The fake videos have been viewed 134 million times.\n\nThe numbers suggest deepfake porn is still niche but also growing quickly. Additionally, 90% of the fake content depicted women from the US, UK, and Canada, while 2% represented women from South Korea and 2% depicted women from Taiwan.\n\n\"Deepfake pornography is a phenomenon that exclusively targets and harms women,\" the company notes.\n\nThat small number of non-pornographic deepfake videos it analyzed on YouTube mostly contained (61%) synthesized male subjects.\n\nAccording to Henry Ajder, a researcher at Deeptrace, currently most of the deepfake porn involves famous women. But he reckons the threat to all women is likely to increase as it becomes less computationally expensive to create deepfakes.\n\n\"As the generative technologies that support deepfakes become increasingly commodified, it is highly likely more private individuals will be targeted,\" Ajder told ZDNet.\n\n\"This commodification process will make the technology significantly more accessible to bad actors and almost certainly increase the quantity of deepfakes being produced.\"\n\nAs for the political threat, there actually aren't that many cases where deepfakes have changed a political outcome.\n\nThe only two cited in the report happened in Gabon and Malaysia. The case in Malaysia generated a sex video involving a cabinet minister, while the incident affecting Gabon involved a video released by the government of its president Ali Bongo Ondimba after he'd suffered a stroke.\n\nAjder thinks the political threat is currently in the \"near future\" but argues that the idea of a deepfake is already destabilizing political processes.\n\n\"I'd say deepfakes, cybersecurity, and political applications pose very serious near-term risks that we need to prepare for now, even if they aren't causing utter havoc right now in the way some people may think,\" he said.\n\nMore on deepfakes and security\n\nThe lurking danger of deepfakes TechRepublic\n\nThese deepfakes of Bill Hader are absolutely terrifying CNET", "description": "Deepfakes pose a serious threat to democracy in the long run but women are likely to suffer first, a new study says.", "authors": ["Liam Tung"], "top_image": "https://zdnet4.cbsistatic.com/hub/i/r/2019/10/07/3267b84f-65ca-4f79-955f-4cfbe000b2cc/thumbnail/770x578/9490d78047ba01d9b10d511d11cfc524/womanlaptopistocka-1158269371.jpg", "published_at": "2019-10-07"}