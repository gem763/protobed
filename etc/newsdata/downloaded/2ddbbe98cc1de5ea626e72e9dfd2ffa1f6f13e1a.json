{"pub": "dailymail", "url": "https://dailymail.co.uk/sciencetech/article-7602397/Activists-warn-dangers-using-AI-make-life-death-decision-battlefield.html", "downloaded_at": "2019-10-23 09:10:46.381046+00:00", "title": "Activists warn UN about dangers of using AI to make life-and-death decision on the battlefield", "language": "en", "text": "A Nobel Peace prize winner has warned against robots making life-and-death decision on the battlefield, as it is 'unethical and immoral' and can never be undone.\n\nJody Williams made the statement at the United Nations in New York City after the US military announced its project the uses AI to make decisions on what human soldiers should target and destroy.\n\nWilliams also pointed out the difficulty of holding those involved accountable for certain war crimes, as there will be a programmer, manufacturer, commander and the machine itself involved in the act.\n\nScroll down for videos\n\nJody Williams (right) has warned against robots making life-and-death decision on the battlefield, as it is 'unethical and immoral' and 'can never be undone'. She was accompanied with fellow activists Liz O'Sullivan (left) and Mary Wareham (center)\n\nWilliams won the prestigious accolade in 1997 after leading efforts to ban landmines and is now an advocate with the 'Campaign To Stop Killer Robots'.\n\n'Drones started out, you know, as surveillance equipment, and then suddenly they stuck on some Hellfire missiles, and they were, you know, killer,' she said during a panel discussion at the United Nations in New York City yesterday.\n\n'We're hoping, and really expecting that the larger community would not find out about the research and development of killer robots.'\n\n'We need to step back and think about how artificial intelligence robotic weapons systems would affect this planet and the people living on it.'\n\nThe activists against killer robots have also pleaded with officials to draft regulations for any craft heading into battle, whether by land, sea or land, without human intervention. The MQ-9 Reaper is set to incorporate AI for making decisions in the battlefield\n\nWilliams is referring to the US military's new initiative, Project Quarterback, which is using AI to make split-second decisions on how to carry out attacks in the field.\n\nThe group was formed in October 2012 with the goal to ban fully autonomous weapons and thereby retain meaningful human control over the use of force.\n\nThe activists against killer robots have also pleaded with officials to draft regulations for any craft heading into battle, whether by land, sea or land, without human intervention.\n\nWILL ROBOTS ONE DAY GET AWAY WITH WAR CRIMES? If a robot unlawfully kills someone in the heat of battle, who is liable for the death? In a report by the Human Rights Watch in 2017, they highlighted the rather disturbing answer: no one. The organisation says that something must be done about this lack of accountability - and it is calling for a ban on the development and use of 'killer robots'. Called 'Mind the Gap: The Lack of Accountability for Killer Robots,' their report details the hurdles of allowing robots to kill without being controlled by humans. 'No accountability means no deterrence of future crimes, no retribution for victims, no social condemnation of the responsible party,' said Bonnie Docherty, senior Arms Division researcher at the HRW and the report's lead author.\n\nLiz O'Sullivan, of the International Committee for Robot Arms Control, said, 'if we allow autonomous weapons to deploy and selectively engage with their own targets, we will see disproportionate false fatalities and error rates with people of color, people with disabilities, anybody who has been excluded from the training sets by virtue of the builders own inherent bias.'\n\nMary Wareham, another activist, pointed out that during meetings at the UN in Geneva in August, 'Russia and the United States were the key problems' as they 'did not want to see any result' towards the drafting of a ban treaty.\n\nShe said, 'other countries that are investing heavily into ever increasingly autonomous weapon systems include China, South Korea, Israel, the United Kingdom to some extent; perhaps Turkey, perhaps Iran.'\n\nAnother dangerous factor that comes into play with killer robots is who or what will be held accountable for war crimes?\n\n'It's unclear who, if anyone, could be held responsible for unlawful acts caused by a fully autonomous weapon: the programmer, manufacturer, commander, [or the] machine itself,' said Williams.\n\n'This accountability gap would make it is difficult to ensure justice, especially for victims.'", "description": "A Nobel Peace prize winner has warned against robots making life-and-death decision on the battlefield, as it is 'unethical and immoral' and 'can never be undone'.", "authors": ["Stacy Liberatore For Dailymail.Com"], "top_image": "https://i.dailymail.co.uk/1s/2019/10/22/22/20057054-0-image-a-45_1571780611728.jpg", "published_at": "2019-10-22"}