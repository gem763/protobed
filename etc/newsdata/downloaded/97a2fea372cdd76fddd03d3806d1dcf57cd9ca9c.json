{"pub": "theverge", "url": "https://theverge.com/2019/9/30/20887614/youtube-moderation-lgbtq-demonetization-terms-words-nerd-city-investigation", "downloaded_at": "2019-10-05 14:36:52.251071+00:00", "title": "YouTube moderation bots punish videos tagged as \u2018gay\u2019 or \u2018lesbian,\u2019 study finds", "language": "en", "text": "A new investigation from a coalition of YouTube creators and researchers is accusing YouTube of relying on a system of \u201cbigoted bots\u201d to determine whether certain content should be demonetized, specifically LGBTQ videos.\n\nThe investigation was conducted by three people: Sealow, the CEO of research firm Ocelot AI; YouTube creator Andrew who operates the YouTube Analyzed channel; and Een of popular YouTube commentary and investigative channel Nerd City.\n\nThe investigation was spurred by an interest to see what words were automatically demonetized by YouTube\u2019s machine learning bots, as concerns over transparency between executives and YouTubers within the creator community grew. Andrew manually tested 15,300 words between June 2nd and July 5th, 2019, using the most common terms in Webster\u2019s Dictionary, UrbanDictionary, and Google search results. The second round of experiment ran between July 6th and July 21st, and it included 14,000 words that were automated using YouTube\u2019s data API by Sealow. Een collaborated with his own sources and helped produce the main video.\n\nAndrew, Sealow, and Een each released their individual videos about the findings, alongside an Excel sheet listing all of the words they used and a white paper analysis of their findings. These words were used to test what YouTube\u2019s bots deem automatically inappropriate for monetization. The team found that if words like \u201cgay\u201d and \u201clesbian\u201d changed to random words like \u201chappy,\u201d the \u201cstatus of the video changed to advertiser friendly\u201d every time, Een says in his video.\n\nReached by The Verge, a YouTube spokesperson denied that there is a list of LGBTQ words that trigger demonetization, despite the investigation\u2019s findings. The spokesperson added that the company is \u201cconstantly evaluating our systems to help ensure that they are reflecting our policies without unfair bias.\u201d\n\n\u201cWe\u2019re proud of the incredible LGBTQ+ voices on our platform and take concerns like these very seriously,\u201d the spokesperson said. \u201cWe use machine learning to evaluate content against our advertiser guidelines. Sometimes our systems get it wrong, which is why we\u2019ve encouraged creators to appeal. Successful appeals ensure that our systems are updated to get better and better.\u201d\n\n\u201cStraight and heterosexual are green words.\u201d\n\nYouTube\u2019s systems for automated demonetization are based on many signals, but there is no specific list that\u2019s built into the company\u2019s machine learning system, according to the company. The company confirmed that it tests samples of videos from LGBTQ creators whenever new monetization classifiers are introduced to ensure that LGBTQ videos aren\u2019t more likely to get demonetized. But the company claims that the current reviews system in place, which is used by human moderators who oversee appeals, properly reflects the company\u2019s policies surrounding LGBTQ terms.\n\nBut the researchers\u2019 findings suggest that there\u2019s significant bias at work before the human moderators get involved. Their research led them to conclude that YouTube\u2019s machine learning bots that are specifically used to examine whether a video is available to monetize use a \u201chidden confidence level ranging from 0 to 1.\u201d Those closer to zero are approved for monetization, while others closer to one are demonetized. Effectively, if a video is deemed being above YouTube\u2019s threshold, it\u2019s immediately demonetized and has to undergo manual review.\n\n\u201cYoutube\u2019s classifiers have been trained to try and predict how likely a video is to be demonetized based on the training data (based on prior manual review results),\u201d Sealow told The Verge. \u201cSo a score of 1 is 100 percent confident that it should be demonetized while 0.5 is 50 percent and so on. Youtube have had to set a certain acceptable threshold \u2014 let\u2019s say \u201835 percent confidence\u2019 where any video that is over the 0.35 score will be demonetized and will require a manual review before being approved for monetization.\u201d\n\nThe company tests samples of videos from LGBTQ creators whenever new monetization classifiers are introduced\n\nIn the analysis of their findings, Sealow states that the \u201clist is best interpreted as a list of negatively charged keywords as certain words are deemed to be more severe than others.\u201d\n\nEvery video uploaded for testing purposes ran between one and two seconds and \u201cfeatured no visual or audio content that could trigger demonetization,\u201d the report reads. The waiting period for monetization approval or denial was around two hours. Words associated with the LGBTQ community or terms used in commentary such as \u201cdemocrat\u201d or \u201cliberal\u201d are \u201clikely negatively charged due to their use in political commentary that is often deemed to be non advertiser friendly,\u201d the report reads.\n\n\u201cThe exact same videos are monetized without the LGBTQ terminology,\u201d Sealow says in his video. \u201cThis is not a matter of LGBTQ personalities being demonetized for something that everyone else would also be demonetized for, such as sex or tragedy. This is LGBTQ terminology like \u2018gay\u2019 and \u2018lesbian\u2019 being the sole reason a video is demonetized despite the context.\u201d\n\nAllegations made in the video aren\u2019t new, but the study is the most extensive. YouTube executives, including CEO Susan Wojcicki and chief product officer Neal Mohan, have spoken about concerns that certain keywords in metadata and titles lead to automatic demonetization. It\u2019s an especially prevalent concern within the LGBTQ community. YouTube has categorically denied that there are policies \u201cthat say \u2018If you put certain words in a title that will be demonetized,\u2019\u201d as Wojcicki told YouTuber Alfie Deyes in a lengthy interview back in August.\n\n\u201cThis is LGBTQ terminology like \u2018gay\u2019 and \u2018lesbian\u2019 being the sole reason a video is demonetized despite the context.\u201d\n\n\u201cWe work incredibly hard to make sure that when our machines learn something \u2014 because a lot of our decisions are made algorithmically \u2014 that our machines are fair,\u201d Wojcicki added. \u201cThere shouldn\u2019t be [any automatic demonetization].\u201d\n\nThat hasn\u2019t stopped creators from using secret language in their videos and including Google Documents in their comments section to communicate with viewers. YouTuber Petty Paige will flash the infamous yellow dollar sign image \u2014 a sign that both creators and audiences know means that a video is demonetized \u2014 meaning that her fans should read the document linked below to understand why she\u2019s using specific words. She theorized, like many other LGBTQ personalities, that using words like \u201clesbian\u201d or \u201ctransgender\u201d could result in demonetization. Swapping out those terms for other random words seemingly didn\u2019t.\n\n\u201cIt\u2019s just as discriminatory if you never say this, and even more exploitive if you do,\u201d Een said.\n\nEarlier this summer, a number of LGBTQ creators filed a lawsuit against YouTube for alleged discriminatory practices, including unfairly demonetizing content that included LGBTQ-friendly terms. The lawsuit also alleges that YouTube actively hurts their channels\u2019 viewership numbers by placing videos in restricted mode, which the company has previously apologized for, and therefore limiting their ability to earn money. The lawsuit claims that \u201cYouTube is engaged in discriminatory, anticompetitive, and unlawful conduct that harms a protected class of persons under California law.\u201d\n\n\u201cWe\u2019re tired of being placated with clear lies and hollow promises that they\u2019ve either fixed it or they\u2019re going to fix it,\u201d Chris Knight, who co-hosts an LGBTQ YouTube news show, GNews!, told The Verge at the time. \u201cIt\u2019s clearly broken. There\u2019s clearly a bias with their AI, their policies. What we really want is for them to change.\u201d\n\nSealow and Een state that they don\u2019t believe that YouTube or Wojcicki are homophobic or purposely employ alleged homophobic practices. They specifically add this isn\u2019t because of specific YouTube policies or \u201ca lack of programs in place to mitigate algorithmic discrimination.\u201d\n\n\u201cIt\u2019s simply the result of the probabilistic nature of the machine learning classifiers used by the demonetization bot,\u201d Sealow\u2019s report adds.", "description": "A new investigation from a coalition of YouTube creators and researchers is accusing YouTube of relying on a system of \"bigoted bots\" to determine whether certain content should be demonetized, specifically LGBTQ videos. YouTube has denied the findings in a statement to The Verge.", "authors": ["Julia Alexander", "Sep"], "top_image": "https://cdn.vox-cdn.com/thumbor/nr_Bm6Wx6aXsNtwL_flPvpIijZ4=/19x0:709x361/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/19246368/Screen_Shot_2019_09_30_at_1.01.16_PM.png", "published_at": "2019-09-30"}