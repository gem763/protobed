{"pub": "dailymail", "url": "https://dailymail.co.uk/news/article-7607525/Met-Police-release-footage-work-detect-live-streamed-terror-attacks.html", "downloaded_at": "2019-10-24 16:18:15.741941+00:00", "title": "Met Police release video of armed officer pretending to be school terrorist shooter", "language": "en", "text": "Police today released dramatic footage of firearms officer training as they work with Facebook to improve detection of live-streamed Christchurch-style terrorist attacks.\n\nThe Metropolitan Police hopes the videos will help Facebook develop technology that can identify terrorist live streams so they can tip police off about attacks early on and prevent them being broadcast.\n\nThe tech giant provided officers at the Met's firearms training centres with body cameras and the footage will be shared to help its artificial intelligence more accurately and rapidly identify videos of real-life first person gunman incidents.\n\nThe video shows a plain clothes police officer storming through a 'school' as terrified children scream in the background.\n\nThe officer fires a large weapon with a camera attached to the top before he is hunted down by heavily armed anti-terror police.\n\nFacebook came under fire for the spread of a live stream video showing the New Zealand mosque shootings in March, which left 51 dead.\n\nThe video was viewed fewer than 200 times during the live broadcast and was watched about 4,000 times in total before being removed.\n\nHowever, the footage was downloaded by users and shared widely online in the aftermath of the far-right attack.\n\nFacebook largely relies on AI to spot terrorist content and remove it as quickly as possible, but in the case of the Christchurch terrorist attack, the company claims it did not have enough first-person footage of violent events for the system to analyse.\n\nThe video shows an officer in plain clothes making his way through a 'school' with a gun and live-stream camera\n\nThe police hope that the technology could help the company notify security services more quickly of an unfolding attack, as well as flagging potentially violent and extremist content for removal.\n\nCommander Richard Smith, head of the Met's Counter Terrorism Command, said: 'Facebook reached out to the Met as we have worked with them on numerous occasions before to remove online terrorist propaganda.\n\n'The live-streaming of terrorist attacks is an incredibly distressing method of spreading toxic propaganda, so I am encouraged by Facebook's efforts to prevent such broadcasts.\n\n'Stopping this kind of material being published will potentially prevent the radicalisation of some vulnerable adults and children.\n\nOfficers are pictured storming a school in a drill to help detect Facebook live stream attacks\n\n'The footage we are capturing shows our highly-skilled firearms officers training to respond with the utmost expertise to a wide range of scenarios including the kind of attacks we want to stop terrorists broadcasting.'\n\nThe videos will also be shared with the Home Office so that they can be passed on to other tech firms to help them develop similar technology.\n\nOfficers now routinely attach camera's to their equipment, allowing for a unique 'shooter' perspective.\n\nThe Met's firearms team carry out filmed training exercises that simulate terrorist incidents and hostage situations in different scenarios such as public transport and on waterways.\n\nArmed officers pretend to hunt the attacker as he makes his way through the 'school' in a New Zealand style attack\n\nMachine learning technology, or artificial intelligence, requires a large amount of different imagery to help it learn to identify terrorist firearms footage.\n\nUK police have establish the world's first unit designed to work with online service providers to remove terrorist material online.\n\nThe Counter Terrorism Internet Referral Unit, which is based within the Met, supports hundreds of national counter terrorism investigations by probing suspects and their networks.\n\nEarlier this year in May, Facebook, along with Amazon, Google, Microsoft and Twitter, agreed on a nine-point action plan following a meeting with world leaders in Paris named the Christchurch Call To Action.\n\nShocking footage shows the officers heavily armed with multiple weapons\n\nFacebook says it has banned more than 200 white supremacist organisations from its platform, as well as removing more than 26 million pieces of content in the last two years related to global terrorist groups like so-called Isis and al Qaida.\n\nErin Saltman, counter terrorism policy manager, Facebook, said: 'Violent extremist and hate based content has no place on our platforms and in the last two years, we have removed 26 million pieces of content from global terrorist groups.\n\n'The footage from this partnership with the Met Police will improve our artificial intelligence technology, helping us more quickly identify and remove dangerous content.\n\n'Crucially, we will make this technology available to the wider tech industry so collectively, we can prevent the spread of harmful content.'", "description": "The Metropolitan Police hopes the videos will help Facebook develop technology that can identify terrorist live streams so the company can tip police off about attacks early on.", "authors": ["Mark Duell For Mailonline"], "top_image": "https://i.dailymail.co.uk/1s/2019/10/24/04/wire-20114460-1571888095-433_636x382.jpg", "published_at": "2019-10-24"}