{"pub": "axios", "url": "https://axios.com/deepfakes-evidence-law-f36e6538-f075-496d-bb56-64fcc29f21ef.html", "downloaded_at": "2019-10-12 17:04:41.383835+00:00", "title": "Deepfakes could weaken important evidence", "language": "en", "text": "What's happening: Elected officials, experts and the press have been warning about the potential fallout for business or elections from deepfakes. But apart from a few high-profile examples, the tech so far has been used almost exclusively for porn, according to a landmark new report from Deeptrace Labs.\n\nPlus, when President Trump and his supporters throw around accusations of \"fake news\" to discredit information that they don't like, it can deepen the atmosphere of distrust.\n\nAll this could lead jurors or attorneys to falsely assume that a real video is faked, says Riana Pfefferkorn, associate director of surveillance and cybersecurity at Stanford's Center for Internet and Society.\n\n\"This is dangerous in the courtroom context because the ultimate goal of the courts is to seek out truth,\" says Pfefferkorn, who recently wrote an article about deepfakes in the courtroom for the Washington State Bar magazine.\n\n\"My fear is that the cultural worry could be weaponized to discredit [videos] and lead jurors to discount evidence that is authentic,\" she tells Axios.\n\nIf a video's authenticity comes into question, the burden shifts to the side that introduced it to prove it's not fake \u2014 which can be expensive and take a long time.\n\nAlready, people accused of possessing child porn often claim that it's computer-generated, says Hany Farid, a digital forensics expert at UC Berkeley. \"I expect that in this and other realms, the rise of AI-synthesized content will increase the likelihood and efficacy of those claiming that real content is fake.\"", "description": "Exaggerated worries over deepfakes could discount key video or audio evidence.", "authors": [], "top_image": "https://images.axios.com/wJTc71Tfpg12z_2kS9JNUuuD5i0=/0x0:1920x1080/1920x1080/2019/10/11/1570835343656.gif", "published_at": "2019-10-12"}