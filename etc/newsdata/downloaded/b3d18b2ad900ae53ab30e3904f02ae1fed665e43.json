{"pub": "news24", "url": "https://fin24.com/Opinion/opinion-facial-analysis-ai-is-being-used-in-job-interviews-heres-why-that-will-reinforce-inequality-20191012-2", "downloaded_at": "2019-10-12 06:45:31.224114+00:00", "title": "OPINION: Facial analysis AI is being used in job interviews. Here's why that will reinforce inequality", "language": "en", "text": "Artificial intelligence and facial analysis software is becoming commonplace in job interviews. The technology, developed by US company HireVue, analyses the language and tone of a candidate\u2019s voice and records their facial expressions as they are videoed answering identical questions.\n\nIt was used in the UK for the first time in September but has been used around the world for several years. Some 700 companies, including Vodafone, Hilton and Urban Outfitters have tried it out.\n\nCertainly there are significant benefits to be had from this. HireVue says it speeds up the hiring process by 90% thanks to the speed of information processing. But there are important risks we should be wary of when outsourcing job interviews to AI.\n\nThe AI is built on algorithms that assess applicants against its database of about 25,000 pieces of facial and linguistic information. These are compiled from previous interviews of \u201csuccessful hires\u201d \u2013 those who have gone on to be good at the job. The 350 linguistic elements include criteria like a candidate\u2019s tone of voice, their use of passive or active words, sentence length and the speed they talk. The thousands of facial features analysed include brow furrowing, brow raising, the amount eyes widen or close, lip tightening, chin raising and smiling.\n\nThe fundamental issue with this, as is often pointed out by critics of AI, is that this technology is not born in a perfect society. It is created within our existing society, marked by a whole range of different kinds of biases, prejudices, inequalities and discrimination. The data on which algorithms \u201clearn\u201d to judge candidates contains these existing sets of beliefs.\n\nAs UCLA professor, Safya Noble, demonstrates in her book Algorithms of Oppression, a few simple Google searches shows this happening. For example, when you search the term \u201cprofessor style\u201d, Google Images returns exclusively middle-aged white men. You get similar results for a \u201csuccessful manager\u201d search. By contrast, a search for \u201chousekeeping\u201d returns pictures of women.\n\nThis reflects how algorithms have \u201clearnt\u201d that professors and managers are mostly white men, while those who do housekeeping are women. And by delivering these results algorithms necessarily contribute to the consolidation, perpetuation and potentially even amplification of existing beliefs and biases. For this very reason we should question the intelligence of AI. The solutions it provides are necessarily conservative, leaving little room for innovation and social progress.\n\n\u2018Symbolic capital\u2019\n\nAs French sociologist Pierre Bourdieu emphasised in his work on the way that inequalities are reproduced, we all have very different economic and cultural capital. The environment in which we grow up, the quality of the teaching we had, the presence or absence of extra-curricular activities and a range of other factors, have a decisive impact on our intellectual abilities and strengths. This also has a big impact on the way we perceive ourselves \u2013 our levels of self-confidence, the objectives we set for ourselves, and our chances in life.\n\nAnother famous sociologist, Erving Goffman, called it a \u201csense of one\u2019s place\u201d. It is this ingrained sense of how we should act that leads people with less cultural capital (generally from less privileged backgrounds) to keep to their \u201cordinary\u201d place. This is also reflected in our body language and the way we speak. So there are those who, from an early age, have a stronger confidence in their abilities and knowledge. And there are many others who have not been exposed to the same teachings and cultural practices, and may be more timid and reserved. They may even suffer from an inferiority complex.\n\nAll of this will come across in job interviews. Ease, confidence, self-assurance and linguistic skills become what Bourdieu called \u201csymbolic capital\u201d. Those who possess it will be more successful \u2013 whether or not those qualities are actually best, or bring something new to the job.\n\nMore of the same\n\nOf course, this is something that has always been the case in society. But artificial intelligence will only reinforce it \u2013 particularly when AI is fed data of the candidates who were successful in the past. This means companies are likely to hire the same types of people that they have always hired.\n\nThe big risk here is that those people are all from the same set of backgrounds. Algorithms leave little room for subjective appreciation, for risk-taking or for acting upon a feeling that a person should be given a chance.\n\nIn addition, this technology may lead to the rejection of talented and innovative people who simply do not fit the profile of those who smile at the right moment or have the required tone of voice. And this may actually be bad for businesses in the long run as they risk missing out on talent that comes in unconventional forms.\n\nMore concerning is that this technology may also inadvertently exclude people from diverse backgrounds and give more chances to those who come from privileged ones. As a rule, they possess greater economic and social capital, which allows them to obtain the skills that become symbolic capital in an interview setting.\n\nWhat we see here is another manifestation of the more general issues with AI. Technology that is developed using data from our existing society, with its various inequalities and biases, is likely to reproduce them in the solutions and decisions that it proposes.\n\nIvan Manokha, Departmental Lecturer in International Political Economy, University of Oxford. Views expressed are his own. This article is republished from The Conversation under a Creative Commons license. Read the original article.", "description": "Artificial intelligence and facial analysis software is becoming commonplace in job interviews. The technology, developed by US company HireVue, analyses the language and tone of a candidate\u2019s voice and records their facial expressions as they are videoed answering identical questions.", "authors": ["Ivan Manokha"], "top_image": "http://cdn.24.co.za/files/Cms/General/d/7506/f2c970de5b3c4c719cb00eef2356dbf4.jpg", "published_at": "2019-10-12"}