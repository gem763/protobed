{"pub": "afr", "url": "https://afr.com/technology/is-ai-it-just-a-giant-waste-of-money-20191028-p534uc", "downloaded_at": "2019-10-29 23:59:01.608733+00:00", "title": "Is AI it just a giant waste of money?", "language": "en", "text": "The lab did the equivalent of 10,000 years of training on the robot hand, Dactyl, and used 30,000 CPU cores, but still ducked one difficult part of the challenge - identifying the state of the jumbled up cube - by packing the puzzle with Bluetooth sensors.\n\nEven then, the results were poor.\n\nAt best the robot failed 80 per cent of the time. When the sensors were turned off, it reported a 0 per cent success rate.\n\nOpenAI stands by the demo, saying it is early days, and pointed to a 60 per cent success rate over 15 moves, but its critics are unrepentant. \"A fiasco,\" says Marcus.\n\nThis wasn't the first time OpenAI's claims have been critically scrutinised.\n\nMusk quit OpenAI's board 18 months ago. AP\n\nIn 2017, Elon Musk had boasted that OpenAI had surpassed humans at playing the popular multiplayer action game Dota, in another attention-grabbing demo. Yet it was quickly discovered that OpenAI had rigged its AI player to have a reaction time of zero, something of an unfair advantage in combat.\n\nIts shots never missed, either. Still, within 20 minutes human players had ganged up to defeat it.\n\nAdvertisement\n\nMuch derision also met OpenAI's announcement earlier this year that it wouldn't disclose any specifics of a text-generating robot because it was \"too dangerous\" to release to the public.\n\nSimilar scepticism has been directed from some computer scientists towards Google's British AI arm DeepMind, which captivates audiences by claiming its AI is creative, or demonstrates intuition.\n\n\"They take advantage of the general public's desire for something magical,\" says Melanie Mitchell of Portland State University, author of a new book explaining AI's limitations. Sceptics call these \"It's alive!\" moments, in reference to the crazed Young Frankenstein played by Gene Wilder.\n\nClowns and a circus\n\nThe harshest criticism is reserved for OpenAI, however.\n\n\"In the Bay Area, in the universities and at Google, OpenAI are regarded as clowns,\" says a scathing Filip Piekniewski, a leading robotics scientist and entrepreneur, who wrote a viral post predicting the collapse of the current AI boom two years ago.\n\n\"If you step back and look at this company, what is their product? Their product is PR stunts that cost millions. That's it. It's a magician and a circus.\"\n\nAdvertisement\n\nMusk himself quit OpenAI's board 18 months ago, citing potential conflicts of interest with his Tesla car company.\n\nThe lab has also abandoned non-profit status to pursue a more commercial model. It still has some dedicated followers. Microsoft invested $US1 billion ($1.46 billion) earlier this year.\n\nYet a tide of scepticism is now spilling out from the corners of the internet, where techies engage in furious esoteric squabbles.\n\nFor critics of progress in AI, including many practitioners themselves, supposedly impressive demonstrations only draw attention to glaring shortcomings in the state of the art.\n\nFor investors and governments - who have banked on breakthroughs in a relatively recent technique called \"deep learning\" as the cornerstone of their strategies for a \"fourth industrial revolution\", in which automation on a massive scale will transform service economies - this is bad news.\n\n\"The vision on which the investment thesis was formed and the reality have diverged,\" explains Piekniewski.\n\n\"This thing is done. It is still not causing panic - I think because the investment cycle is tied to the economic cycle - but people are asking, 'Where are the results?' Investors will not get their money back.\"\n\nOne experienced AI entrepreneur in London concurred.\n\nAdvertisement\n\n\"Investors have become incredibly cautious. It was far easier to pick up four or five investors two years ago when our platform was a concept than now, when the product is proven and works.\n\n\"But that's the nature of seed capital here - most VCs only really invest in consumer products they can understand.\"\n\nTop of the hype cycle\n\nMitchell adds: \"I would say we're probably at the top of the hype cycle and the public are starting to see the limitations that people in the know already know.\"\n\nMachine learning scientist Jeffrey Ng, head of AI the Founders Forum network in London, notes \"a little temperance investment\", but is confident that judicious use of deep learning techniques, in the right context, can increase productivity.\n\nHe cites customer service data mining and robotic process automation as examples. The global agrichemicals giant Monsanto may disagree; it hit a failure rate of 99 per cent over more than 50 deep learning projects.\n\nSuch gathering clouds are yet to be noticed by many behind the front lines of technology.\n\nBanks and IT service companies such as the German giant SAP are rushing to set up AI \"ethics committees\", and think-tanks and intellectuals are agonising over the alleged threat of imminent mass unemployment.\n\nAdvertisement\n\nMany of them may be wasting their time, thinks Marcus.\n\n\"Unfortunately, a lot of this talk feels to me like fairy tales,\" he says. \"I wish they'd engage in the realities of what the systems in the next five years are realistically able to do.\"\n\nThat is, say Marcus and the AI \"realists\", far less impressive than the chatterati have been led to believe.\n\nSelf-driving cars, once promised by 2020 are receding further into the future.\n\nSo what's going wrong with the Fourth Industrial Revolution?\n\nIn his new book, Marcus predicts, \"The bitter truth is that for now, the vast majority of dollars invested in AI are going toward solutions that are brittle, cryptic and too unreliable to be used in high-stakes problems.\"\n\nSince its inception, AI has always relied on showbiz sparkle to sell its visions of thinking machines, taking advantage of an audience's desire to see something that has a life of its own.\n\nAdvertisement\n\nAI rebrand\n\nThe term itself was coined by a feisty young American mathematician John McCarthy in the mid-Fifties.\n\nAfter struggling for years to find funding for his journal devoted to a new but obscure branch of mathematics, McCarthy conjured up the phrase \"artificial intelligence\". After the rebrand, money poured in.\n\nStrangely, the current revival of AI, the third wave since McCarthy, is the \"dumbest\" yet.\n\nIt relies on statistical brute force. With \"deep learning\", the computer doesn't \"know\" what it's doing. In DeepMind's much-lauded research, the AI didn't know what a paddle was after it \"learned\" how to play the classic Atari video game Breakout. If the paddle was moved up two pixels on the screen, it couldn't play any more.\n\n\"Correlation is not causation,\" explains Pomona University economics Professor Gary Smith, another AI critic and author of The AI Delusion. Without understanding what's in a picture, the AI easily makes false associations.\n\nA robot [that] could lift Grandpa into bed 80 per cent of the time, but drops him 20 per cent of the time would be a disaster. \u2014 Neuroscientist and author Gary Marcus\n\nThe word \"learning\" in deep learning is deceptive, Professor Mitchell points out, because success in one demo can rarely be usefully applied in another situation. It's a failing that should alarm investors.\n\nAdvertisement\n\n\"The holy grail of AI ever since it started is abstraction, and nobody has got closer. A lot of people in the field acknowledge we're missing some conceptual foundation and are trying to look at other ideas.\"\n\nFailure rates that are forgivable in Google Image Search - such as identifying a sheep as a cloud - can have catastrophic consequences in real life. \"A robot [that] could lift Grandpa into bed 80 per cent of the time, but drops him 20 per cent of the time would be a disaster,\" says Marcus.\n\nThe good news for industry is that practical robotics continues to become more affordable, as the costs of the components like sensors and actuators fall, leading to more affordable single-purpose factory robots.\n\nBut typically, this doesn't involve any of the new AI. Leading sceptics are calling for a new ground-up approach to solve problems deep learning technology can't address.\n\nYet governments continue to pour in cash. China has committed $US150 billion to global leadership in the field. The UK, despite record private investment of \u00a31 billion in 2018, is also keen to add more from the taxpayer.\n\nDoing so \"sends out a signal and tells the world the UK wants to be a global leader\", Stephen Metcalfe, the Conservative MP who convened the all-party parliamentary group on AI, says. \"It's as much about the signal as about the actual funding.\"\n\nThe biggest booster of AI is Masayoshi Son, boss of the Japanese investment giant Softbank, which has made huge bets on AI start-ups. Son told an audience two years ago he thinks a computer will have an IQ of 30,000 within 30 years.\n\nThat doesn't look so likely today, and with Softbank's continuing woes with relatively low-tech businesses such as Uber and WeWork, it appears to have plenty of its own learning to do.\n\nAndrew Orlowski is the founder of the research network Think of X. He gave oral evidence to the House of Lords inquiry into artificial intelligence in 2017.\n\nThe Telegraph London", "description": "As investors and governments sink billions of dollars into the development of AI,an increasing number of sceptics are starting to question whether it is all just hype and PR stunts.", "authors": [], "top_image": "https://static.ffx.io/images/$zoom_0.9888%2C$multiply_0.7554%2C$ratio_1.777778%2C$width_1059%2C$x_263%2C$y_0/t_crop_custom/e_sharpen:25%2Cq_85%2Cf_auto/37db3e7e1fbb4f2bb41814d7422f742b14b9fa03", "published_at": "2019-10-28"}