{"pub": "bbc", "title": "King's Cross: 'Facial recognition last used in 2018'", "url": "https://bbc.com/news/technology-49551880", "language": "en", "published_at": "2019-09-02", "downloaded_at": "2019-09-03 00:12:55.518732+00:00", "text": "Image copyright Getty Images Image caption Part of the King's Cross complex\n\nFacial-recognition technology has not been used at London's King's Cross Central development since March 2018, according to the 67-acre (0.3-sq-km) site's developer.\n\nWhen the use of the technology was initially reported, by the Financial Times in August, a spokeswoman said it was to \"ensure public safety\".\n\nThe partnership now says only two on-site cameras used facial recognition.\n\nThey had been in one location and had been used to help the police, it added.\n\nAccording to a statement on its website, the two cameras were operational between May 2016 and March 2018 and the data gathered was \"regularly deleted\".\n\nThe King's Cross partnership also denied any data had been shared commercially.\n\nIt had used it to help the Metropolitan and British Transport Police \"prevent and detect crime in the neighbourhood\", it said.\n\nBut both forces told BBC News they were unaware of any police involvement.\n\nIt said it had since shelved further work on the technology and \"has no plans to reintroduce any form of FRT [facial-recognition technology] at the King's Cross estate\".\n\nHowever, as recently as last month, a security company was advertising for a CCTV operator for the area.\n\nThe duties of the role included: \"To oversee and monitor the health, safety and welfare of all officers across the King's Cross estate using CCTV, Facewatch and surveillance tactics.\"\n\nThe advert was later amended to remove this detail, after BBC News raised the issue.\n\nFollowing the FT's report, the Information Commissioner's Office (ICO) launched an investigation into how the facial-recognition data gathered was being stored.\n\nThe Mayor of London, Sadiq Khan, also wrote to the King's Cross Central development group asking for reassurance its use of facial-recognition technology was legal.\n\nThe latest statement was posted online on the eve of technology giant Samsung opening an event space on the site, with a launch event planned for Tuesday evening, 3 September.\n\nThe FT reporter who broke the original story described the statement as \"strange\".\n\nOne critic of facial-recognition technology, Dr Stephanie Hare, said many questions remained about what had been going on in the area, which, while privately owned, is open to the public and contains a number of bars, restaurants and family spaces.\n\n\"It does not change the fundamentals of the story in terms of the implications for people's privacy and civil liberties, or the need for the ICO to investigate - they deployed this technology secretly for nearly two years,\" she said.\n\n\"Even if they deleted data, I would want to know, 'Did they do anything with it beforehand, analyse it, link it to other data about the people being identified? Did they build their own watch-list? Did they share this data with anyone else? Did they use it to create algorithms that have been shared with anyone else? And most of all, were they comparing the faces of people they gathered to a police watch-list?'\"\n\nDr Hare also said it was unclear why the partnership had stopped using it.\n\n\"Was it not accurate? Ultimately unhelpful? Or did they get what they needed from this 22-month experiment?\" she said.", "description": "The London site's developer says only two on-site cameras, in one location, used facial recognition.", "authors": ["Zoe Kleinman", "Technology Reporter", "Bbc News"], "top_image": "https://ichef.bbci.co.uk/news/1024/branded_news/4A86/production/_108287091_gettyimages-1139393155.jpg"}