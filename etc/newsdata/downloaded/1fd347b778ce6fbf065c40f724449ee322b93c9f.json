{"pub": "thenextweb", "url": "https://thenextweb.com/tech/2019/10/11/pinterest-says-ai-reduced-self-harm-content-on-its-platform-by-88", "downloaded_at": "2019-10-11 12:40:02.492894+00:00", "title": "Pinterest says AI reduced self-harm content on its platform by 88%", "language": "en", "text": "Although mental health is by no means a new phenomenon, research proves that anxiety and depression are at an all time high. Multiple studies show that technology, specifically social media, is detrimental to people\u2019s mental wellbeing. However, tech is taking on some of the responsibility to help those struggling with their mental health.\n\nYesterday, on international World Mental Health Day, Pinterest announced in a blogpost that for the past year, it\u2019s been using machine learning techniques to identify and automatically hide content that displays, rationalizes, or encourages self-injury. Using this technology, the social networking company says it has achieved an 88 percent reduction in reports of self-harm content by users, and it\u2019s now able to remove harmful content three times faster than ever before.\n\nIn addition to this, Pinterest is cleaning up its platform by removing over 4,600 search terms and phrases related to self-harm. Now, if someone searches for one of these removed terms, links to free and confidential support from expert resources are prominently displayed \u2014 on their boards and homepage. The approach was created with guidance from external, leading emotional health experts including National Suicide Prevention Lifeline, Vibrant Emotional Health, and Samaritans.\n\nEarlier this year, Pinterest introduced a collection of emotional well-being activities to its iOS app in the US. Before, these activities that aimed to help those struggling with their mental health, only appeared when someone searched for something that indicated they were feeling down, like \u201cstress relief\u201d or \u201csad quotes.\u201d Pinterest said how it didn\u2019t want people to have to search for something sad to get these resources, so now all users have to search is #pinterestwellbeing to find exercised to improve their mood.\n\nSome of these resources that aim to make people feel better include exercises like \u201cRefocus your attention,\u201d Take a breath, and \u201cFeel compassion for others.\u201d\n\nA study by the National Centre for Social Research found that over the past 14 years, the number of girls and young women self-harming has tripled. Because of these worrying findings, social media companies were placed under a new statutory duty of care, and can now face fines, prosecution, and risk being removed from operation in the UK if they fail to protect their users from online harm.\n\n\n\nLast month, Facebook tightened its policies on self-harm content by no longer allowing graphic images with the aim to avoid \u201cunintentional promoting or triggering self-harm, even when someone is seeking support or expressing themselves to aid their recovery.\u201d\n\nAlongside this, Instagram made it harder to search for harmful content and prevented content like self-harm from being recommended in its \u2018Explore\u2019 page.\n\nEarlier this year, the tech companies released a tool that automatically hides potentially harmful and offensive content with its \u201cSensitivity Screen.\u201d But researchers raised concerns over how effective these trigger warnings actually are. While some advocates of the feature argued that sensitivity screens are easy acts of consideration that could prevent trauma, others argued that they offer little help, and may even harm people\u2019s mental health by feelings of anxiety.\n\nWhile technology has been to blame for having a detrimental effect on people\u2019s mental health \u2014 from feeling loneliness and isolation \u2014 it\u2019s promising to see some of these platforms take responsibility and recognize its ability to make change on a wider scale.\n\nRead next: Google releases voice guidance in Maps for visually impaired people", "description": "Pinterest announced that for the past year, it\u2019s been using machine learning to identify and hide content that displays or encourages self-injury.", "authors": ["Cara Curtis"], "top_image": "https://img-cdn.tnwcdn.com/image/tnw?filter_last=1&fit=1280%2C640&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2019%2F10%2F200-calories-1-6.png&signature=9669f629fe68d325450fc92b304ff77f", "published_at": "2019-10-11"}