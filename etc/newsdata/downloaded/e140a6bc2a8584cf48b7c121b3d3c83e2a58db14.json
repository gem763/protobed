{"pub": "thenextweb", "url": "https://thenextweb.com/syndication/2019/10/16/the-rate-of-the-universes-expansion-is-in-dispute-but-a-new-kind-of-measurement-offers-hope", "downloaded_at": "2019-10-16 13:40:18.592404+00:00", "title": "The rate of the universe\u2019s expansion is in dispute \u2013 but a new kind of measurement offers hope", "language": "en", "text": "Advances in astronomical observation over the past century have allowed scientists to construct a remarkably successful model of how the cosmos works. It makes sense \u2013 the better we can measure something, the more we learn. But when it comes to the question of how fast our universe is expanding, some new cosmological measurements are making us ever more confused.\n\nSince the 1920s we\u2019ve known that the universe is expanding \u2013 the more distant a galaxy is, the faster it is moving away from us. In fact, in the 1990s, the rate of expansion was found to be accelerating. The current expansion rate is described by something called \u201cHubble\u2019s Constant\u201d \u2013 a fundamental cosmological parameter.\n\nUntil recently, it seemed we were converging on an accepted value for Hubble\u2019s Constant. But a mysterious discrepancy has emerged between values measured using different techniques. Now a new study, published in Science, presents a method that may help to solve the mystery.\n\nThe problem with precision\n\nHubble\u2019s Constant can be estimated by combining measurements of the distances to other galaxies with the speed they are moving away from us. By the turn of the century, scientists agreed that the value was about 70 kilometers per second per megaparsec \u2013 one megaparsec is just over 3m light-years. But in the last few years, new measurements have shown that this might not be a final answer.\n\nIf we estimate Hubble\u2019s Constant using observations of the local, present-day universe, we get a value of 73. But we can also use observations of the afterglow of the Big Bang \u2013 the \u201ccosmic microwave background\u201d \u2013 to estimate Hubble\u2019s Constant. But this \u201cearly\u201d universe measurement gives a lower value of around 67.\n\nWorryingly, both of the measurements are reported to be precise enough that there must be some sort of problem. Astronomers euphemistically refer to this as \u201ctension\u201d in the exact value of Hubble\u2019s Constant.\n\nIf you\u2019re the worrying kind, then the tension points to some unknown systematic problem with one or both of the measurements. If you\u2019re the excitable kind, then the discrepancy might be a clue about some new physics that we didn\u2019t know about before. Although it has been very successful so far, perhaps our cosmological model is wrong, or at least incomplete.\n\nDistant versus local\n\nTo get to the bottom of the discrepancy, we need a better linking of the distance scale between the very local and very distant universe.\n\nThe new paper presents a neat approach to this challenge. Many estimates of the expansion rate rely on the accurate measurement of distances to objects. But this is really hard to do: we can\u2019t just run a tape measure across the universe.\n\nOne common approach is to use \u201cType 1a\u201d supernovas (exploding stars). These are incredibly bright, so we can see them at a great distance. As we know how luminous they should be, we can calculate their distance by comparing their apparent brightness with their known luminosity.\n\nTo derive Hubble\u2019s Constant from the supernova observations, they must be calibrated against an absolute distance scale because there is still a rather large uncertainty in their total brightness. Currently, these \u201canchors\u201d are very nearby (and so very accurate) distance markers, such as Cepheid Variable stars, which brighten and dim periodically.\n\nIf we had absolute distance anchors further out in the cosmos, then the supernova distances could be calibrated more accurately over a wider cosmic range.\n\nFar-flung anchors\n\nThe new work has dropped a couple of new anchors by exploiting a phenomenon called gravitational lensing. By looking at how light from a background source (like a galaxy) bends due to the gravity of a massive object in front of it, we can work out the properties of that foreground object.\n\nA large cluster galaxy (center of the box) has split the light from an exploding background supernova into four yellow images/dots. NASA/Hubble The team has studied two galaxies that are lensing the light from two other background galaxies. The distortion is so strong that multiple images of each background galaxy are projected around the foreground deflectors (such as in the image above). The components of light making up each of those images will have traveled slightly different distances on their journey to Earth as the light bends around the foreground deflector. This causes a delay in the arrival time of light across the lensed image.\n\nIf the background source has a fairly constant brightness, we don\u2019t notice that time delay. But when the background source itself varies in brightness, we can measure the difference in light arrival time. This work does exactly that.\n\nThe time delay across the lensed image is related to the mass of the foreground galaxy deflecting the light, and its physical size. So when we combine the measured time delay with the mass of the deflecting galaxy (which we know) we get an accurate measure of its physical size.\n\nLike a penny held at arms length, we can then compare the apparent size of the galaxy to the physical size to determine the distance, because an object of fixed size will appear smaller when it is far away. The authors present absolute distances of 810 and 1230 megaparsecs for the two deflecting galaxies, with about a 10-20% margin of error.\n\nTreating these measurements as absolute distance anchors, the authors go on to reanalyze the distance calibration of 740 supernovas from a well-established data set used to determine Hubble\u2019s Constant. The answer they got was just over 82 kilometers per second per megaparsec.\n\nThis is quite high compared to the numbers mentioned above. But the key point is that with only two distance anchors the uncertainty in this value is still quite large. Importantly, though, it is statistically consistent with the value measured from the local universe. The uncertainty will be reduced by hunting for \u2013 and measuring \u2013 distances to other strongly lensed and time-varying galaxies. They are rare, but upcoming projects like the Large Synoptic Survey Telescope should be capable of detecting many such systems, raising hopes of reliable values.\n\nThe result provides another piece of the puzzle. But more work is needed: it still doesn\u2019t explain why the value derived from the cosmic microwave background is so low. So the mystery remains, but hopefully not for too long.\n\nThis article is republished from The Conversation by James Geach, Professor of Astrophysics and Royal Society University Research Fellow, University of Hertfordshire under a Creative Commons license. Read the original article.\n\nRead next: CHEAP: Stop living under a rock, get the maxed out Surface Laptop for just $1,049", "description": "", "authors": ["The Conversation"], "top_image": "https://img-cdn.tnwcdn.com/image/tnw?filter_last=1&fit=1280%2C640&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2019%2F10%2Fpic.png&signature=d2c36365d97a83dd579fc20af92b2baa", "published_at": "2019-10-16"}