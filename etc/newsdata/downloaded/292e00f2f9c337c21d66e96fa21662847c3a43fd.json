{"pub": "yahoo", "url": "https://sg.style.yahoo.com/human-compatible-stuart-russell-review-063102300.html", "downloaded_at": "2019-10-24 06:58:45.933255+00:00", "title": "Human Compatible by Stuart Russell review \u2013 AI and our future", "language": "en", "text": "Creating machines smarter than us could be the biggest event in human history \u2013 and the last. Here\u2019s a question scientists might ask more often: what if we succeed? That is, how will the world change if we achieve what we\u2019re striving for? Tucked away in offices and labs, researchers can develop tunnel vision, the rosiest of outlooks for their creations. The unintended consequences and shoddy misuses become afterthoughts \u2013 messes for society to clean up later. Today those messes spread far and wide: global heating, air pollution, plastics in the oceans, nuclear waste and babies with badly rewritten DNA. All are products of neat technologies that solve old problems by creating new ones. In the inevitable race to be first to invent, the downsides are dismissed, unexplored or glossed over. In 1995, Stuart Russell wrote the book on AI. Co-authored with Peter Norvig, Artificial Intelligence: A Modern Approach became one of the most popular course texts in the world (Norvig worked for Nasa; in 2001, he joined Google). In the final pages of the last chapter, the authors posed the question themselves: what if we succeed? Their answer was hardly a ringing endorsement. \u201cThe trends seem not to be too terribly negative,\u201d they offered. A lot has happened since: \u2013 Google and Facebook for starters. In Human Compatible, Russell returns to the question and this time does not hold back. The result is surely the most important book on AI this year. Perhaps, as Richard Brautigan\u2019s poem has it, life is good when we are all watched over by machines of loving grace. But Russell, a professor at the University of California, Berkeley, sees darker eventualities. Creating machines that surpass our intelligence would be the biggest event in human history. It may also be the last, he warns. Here he makes the convincing case that how we choose to control AI is \u201cpossibly the most important question facing humanity\u201d. Russell has picked his moment well. Tens of thousands of the world\u2019s brightest minds are now building AIs. Most work on one-trick ponies \u2013 the \u201cnarrow\u201d AIs that process speech, translate languages, spot people in crowds, diagnose diseases, or whip people at games from Go to Starcraft II. But these are a far cry from the field\u2019s ultimate goal: general purpose AIs that match, or surpass, the broad-based brainpower of humans. Its is not a ludicrous ambition. From the start, DeepMind, the AI group owned by Alphabet, Google\u2019s parent company, set out to \u201csolve intelligence\u201d and then use that to solve everything else. In July, Microsoft signed a $1bn contract with OpenAI, a US outfit, to build an AI that mimics the human brain. It is a high stakes race. As Vladimir Putin said: whoever becomes the leader in AI \u201cwill become the ruler of the world\u201d. Russell doesn\u2019t claim we are nearly there. In one section he sets out the formidable problems computer engineers face in creating human-level AI. Machines must know how to turn words into coherent, reliable knowledge; they must learn how to discover new actions and order them appropriately (boil the kettle, grab a mug, toss in a teabag). And like us, they must manage their cognitive resources so they can reach good decisions fast. These are not the only hurdles, but they give a flavour of the task ahead. Russell suspects it will keep researchers busy for another 80 years, but stresses the timing is impossible to predict. Even with apocalypse camped on the horizon, this is a wry and witty tour of intelligence and where it may take us. And where exactly is that? A machine that masters all the above would be a \u201cformidable decision maker in the real world\u201d, Russell says. It would absorb vast amounts of information from the internet, TV, radio, satellites and CCTV and with it gain a more sophisticated understanding of the world and its inhabitants than any human could ever hope for. What could possibly go right? In education, AI tutors would maximise the potential of every child. They would master the vast complexity of the human body, letting us banish disease. As digital personal assistants they would put Siri and Alexa to shame: \u201cYou would, in effect, have a high-powered lawyer, accountant, and political advisor on call at any time.\u201d And what of the downsides? Without serious progress on AI safety and regulation, Russell foresees messes aplenty and his chapter on misuses of AI is grim reading. Advanced AI would hand governments such extraordinary powers of surveillance, persuasion and control that \u201cthe Stasi will look like amateurs\u201d. And while Terminator-style killer robots are not about to eradicate humanity, drones that select and kill individuals based on their faceprints, skin colour or uniforms are entirely feasible. As for jobs, we may no longer make a living by providing physical or mental labour, but we can still supply our humanity. Russell notes: \u201cWe will need to become good at being human.\u201d What\u2019s worse than a society-destroying AI? A society-destroying AI that won\u2019t switch off. It\u2019s a terrifying, seemingly absurd prospect that Russell devotes much time to. The idea is that smart machines will suss out, as per HAL in 2001: A Space Odyssey, that goals are hard to achieve if someone pulls the plug. Give a superintelligent AI a clear task \u2013 to make the coffee, say \u2013 and its first move will be to disable its off switch. The answer, Russell argues, lies in a radical new approach where AIs have some doubt about their goals, and so will never object to being shut down. He moves on to advocate \u201cprovably beneficial\u201d AI, whose algorithms are mathematically proven to benefit their human users. Suffice to say this is a work in progress. How will my AI deal with yours? Let\u2019s be clear: there are plenty of AI researchers who ridicule such fears. After the philosopher Nick Bostrom highlighted potential dangers of general purpose AI in Superintelligence (2014), a US thinktank, the Information Technology and Innovation Foundation, gave its Luddism award to \u201calarmists touting an artificial intelligence apocalypse\u201d. This was indicative of the dismal debate around AI safety, which is on the brink of descending into tribalism. The danger that comes across here is less an abrupt destruction of the species, more an inexorable enfeeblement: a loss of striving and understanding, which erodes the foundations of civilisation and leaves us \u201cpassengers in a cruise ship run by machines, on a cruise that goes on forever\u201d. . Human Compatible is published by Allen Lane (\u00a325). To order a copy go to guardianbookshop.com or call 020-3176 3837. Free UK p&p over \u00a315, online orders only. Phone orders min p&p of \u00a31.99.\n\nHere\u2019s a question scientists might ask more often: what if we succeed? That is, how will the world change if we achieve what we\u2019re striving for? Tucked away in offices and labs, researchers can develop tunnel vision, the rosiest of outlooks for their creations. The unintended consequences and shoddy misuses become afterthoughts \u2013 messes for society to clean up later.\n\nToday those messes spread far and wide: global heating, air pollution, plastics in the oceans, nuclear waste and babies with badly rewritten DNA. All are products of neat technologies that solve old problems by creating new ones. In the inevitable race to be first to invent, the downsides are dismissed, unexplored or glossed over.\n\nIn 1995, Stuart Russell wrote the book on AI. Co-authored with Peter Norvig, Artificial Intelligence: A Modern Approach became one of the most popular course texts in the world (Norvig worked for Nasa; in 2001, he joined Google). In the final pages of the last chapter, the authors posed the question themselves: what if we succeed? Their answer was hardly a ringing endorsement. \u201cThe trends seem not to be too terribly negative,\u201d they offered. A lot has happened since: \u2013 Google and Facebook for starters.\n\nIn Human Compatible, Russell returns to the question and this time does not hold back. The result is surely the most important book on AI this year. Perhaps, as Richard Brautigan\u2019s poem has it, life is good when we are all watched over by machines of loving grace. But Russell, a professor at the University of California, Berkeley, sees darker eventualities. Creating machines that surpass our intelligence would be the biggest event in human history. It may also be the last, he warns. Here he makes the convincing case that how we choose to control AI is \u201cpossibly the most important question facing humanity\u201d.\n\nRussell has picked his moment well. Tens of thousands of the world\u2019s brightest minds are now building AIs. Most work on one-trick ponies \u2013 the \u201cnarrow\u201d AIs that process speech, translate languages, spot people in crowds, diagnose diseases, or whip people at games from Go to Starcraft II. But these are a far cry from the field\u2019s ultimate goal: general purpose AIs that match, or surpass, the broad-based brainpower of humans.\n\nIts is not a ludicrous ambition. From the start, DeepMind, the AI group owned by Alphabet, Google\u2019s parent company, set out to \u201csolve intelligence\u201d and then use that to solve everything else. In July, Microsoft signed a $1bn contract with OpenAI, a US outfit, to build an AI that mimics the human brain. It is a high stakes race. As Vladimir Putin said: whoever becomes the leader in AI \u201cwill become the ruler of the world\u201d.\n\nRussell doesn\u2019t claim we are nearly there. In one section he sets out the formidable problems computer engineers face in creating human-level AI. Machines must know how to turn words into coherent, reliable knowledge; they must learn how to discover new actions and order them appropriately (boil the kettle, grab a mug, toss in a teabag). And like us, they must manage their cognitive resources so they can reach good decisions fast. These are not the only hurdles, but they give a flavour of the task ahead. Russell suspects it will keep researchers busy for another 80 years, but stresses the timing is impossible to predict.\n\nEven with apocalypse camped on the horizon, this is a wry and witty tour of intelligence and where it may take us. And where exactly is that? A machine that masters all the above would be a \u201cformidable decision maker in the real world\u201d, Russell says. It would absorb vast amounts of information from the internet, TV, radio, satellites and CCTV and with it gain a more sophisticated understanding of the world and its inhabitants than any human could ever hope for.\n\nWhat could possibly go right? In education, AI tutors would maximise the potential of every child. They would master the vast complexity of the human body, letting us banish disease. As digital personal assistants they would put Siri and Alexa to shame: \u201cYou would, in effect, have a high-powered lawyer, accountant, and political advisor on call at any time.\u201d\n\nAnd what of the downsides? Without serious progress on AI safety and regulation, Russell foresees messes aplenty and his chapter on misuses of AI is grim reading. Advanced AI would hand governments such extraordinary powers of surveillance, persuasion and control that \u201cthe Stasi will look like amateurs\u201d. And while Terminator-style killer robots are not about to eradicate humanity, drones that select and kill individuals based on their faceprints, skin colour or uniforms are entirely feasible. As for jobs, we may no longer make a living by providing physical or mental labour, but we can still supply our humanity. Russell notes: \u201cWe will need to become good at being human.\u201d\n\nStory continues", "description": "Creating machines smarter than us could be the biggest event in human history \u2013 and the last. Here\u2019s a question scientists might ask more often: what if we succeed? That is, how will the world change if we achieve what we\u2019re striving for? Tucked away in offices and labs, researchers can develop tunnel", "authors": ["Ian Sample"], "top_image": "https://s.yimg.com/uu/api/res/1.2/EgU6boE4LALK6XjgO7GNIg--~B/aD0zMDA7dz01MDA7c209MTthcHBpZD15dGFjaHlvbg--/http://media.zenfs.com/en-GB/homerun/theguardian_763/029a61ca93befbbf105f22749f534388", "published_at": "2019-10-24"}