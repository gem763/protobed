{"pub": "washingtonpost", "url": "https://washingtonpost.com/technology/2019/09/06/deepfakes-deep-pockets-facebook-spends-million-contest-detecting-constantly-evolving-videos", "downloaded_at": "2019-09-07 02:19:59.971259+00:00", "title": "\u2018Deepfakes,\u2019 deep pockets: Facebook spends $10 million on contest for detecting \u2018constantly evolving\u2019 videos", "language": "en", "text": "Facebook is spearheading a competition to find new ways to identify computer-altered videos known as \u201cdeepfakes.\u201d But some artificial-intelligence specialists say the strategy might backfire.\n\nThose experts say the contest will probably hasten the already accelerating arms race between the malicious actors using AI to create increasingly realistic faked videos, and the technology companies racing to detect them.\n\n\u201cAny algorithm used to identify deepfakes could also be used to make deepfakes better,\" says Rachel Thomas, a co-founder of machine-learning lab Fast.ai.\n\n[Top AI researchers race to detect \u2018deepfake\u2019 videos: \u2018We are outgunned\u2019]\n\nAlready, top artificial-intelligence researchers across the country have been racing to defuse the computer-generated fake videos as fears grow that they could undermine candidates and mislead voters in the lead-up to the 2020 presidential election. Many fear these videos could be deployed in a similar manner to the way fake news stories and deceptive Facebook groups were used to influence the 2016 election.\n\nWhile people have altered videos for as long as the technology has existed, AI software developed by Google has increased the accessibility and sophistication of deepfakes. And the tools keep advancing and growing in popularity. Last week, a Chinese app called Zao became the most popular download in China, allowing users to virtually graft their faces onto videos of actors from scenes in movies and television shows.\n\nDetecting deepfakes is becoming significantly more difficult as the technology improves. Detection often comes down to gestures as subtle as a chin movement or a blink of an eye.\n\nFacebook\u2019s competition, called the Deepfake Detection Challenge, is a partnership between Facebook, the technology industry consortium Partnership on AI, Microsoft and experts from seven academic institutions. Events will begin in October and run until March. Facebook said that it has dedicated $10 million to fund the competition, which will include a not-yet-announced number of grants and awards.\n\n[Viral Chinese app Zao puts your face in place of Leonardo DiCaprio\u2019s in \u2018deepfake\u2019 videos]\n\nFacebook said it will release the data set for the challenge later this year. The company is commissioning a \u201crealistic data set\u201d made up of videos using paid actors, as well as altered versions of those videos. Competitors will use those data sets to develop detection codes. Facebook will enter the challenge, too, but will not accept any monetary prizes.\n\nChief technology officer Mike Schroepfer said in a blog post that Facebook\u2019s hope is that the competition will help the company accelerate its progress and create more open-source tools as it battles a \u201cconstantly evolving problem.\u201d\n\nUsing a data set made up of videos of actors might not adequately train algorithms to detect deepfakes that depict humans in real situations, Thomas warned.\n\nIn another potential impact to the outcome of the competition, some were critical of the lack of diversity among the panel of academics who consulted with Facebook on the project. As noted by Vice, all seven of the professors quoted in the announcement are men. None is a professor of social sciences, a collection of fields that have scrutinized the human impact and possible consequences of AI technology.\n\n[Facebook wouldn\u2019t delete an altered video of Nancy Pelosi. What about one of Mark Zuckerberg?]\n\nStill, the Deepfake Detection Challenge received praise from Capitol Hill, where politicians have urged social media companies to enhance their efforts to ward off that type of disinformation before the election season.\n\nRep. Adam B. Schiff (D-Calif.), chairman of the House Intelligence Committee, said in a statement that the competition is \u201ca promising step\u201d by the technology community in the battle against deepfakes. With voting in the first 2020 primaries less than six months away, Schiff said social media platforms \u201cmust urgently prepare for increasingly sophisticated disinformation campaigns.\u201d\n\nManipulated videos have already targeted some politicians. House Speaker Nancy Pelosi (D-Calif.) was the subject of a video earlier this year that was subtly changed to make it sound as though she were drunkenly slurring her words. Though the alterations to the video were relatively low-tech, the situation and the speed with which the content went viral online demonstrated how even minor changes to a video could be used to shape public perceptions.\n\nWhen Facebook said it would not remove the Pelosi video, stating that it did not violate any of its policies, two artists countered with a more sophisticated deepfake featuring Facebook chief executive Mark Zuckerberg bragging about misusing \u201cstolen data\u201d from users. That video also remained on the platform.", "description": "Artificial-intelligence specialists say the competition will likely hasten the arms race between the malicious actors using AI to create increasingly realistic videos and the technology companies struggling to detect them.", "authors": ["Marie C. Baca", "Breaking News Technology", "Business Reporter", "September At Pm", "Marie C. Baca Is The Washington Post'S Breaking News Technology", "Business Reporter In San Francisco."], "top_image": "https://www.washingtonpost.com/resizer/9Krs4tCmn-qk8w2iV5kKBVw9dpU=/1484x0/d1i4t8bqe7zgj6.cloudfront.net/06-12-2019/t_fe4f086cd86b4cbb980a732fd17feac9_name_deepfakes.jpg", "published_at": "2019-09-06"}