{"pub": "washingtonpost", "url": "https://washingtonpost.com/news/powerpost/paloma/the-technology-202/2019/09/03/the-technology-202-new-nyu-report-says-urges-social-media-companies-to-take-down-provably-false-information/5d6d58f388e0fa7bb93a88d8", "downloaded_at": "2019-09-03 23:40:32.267267+00:00", "title": "The Technology 202: New NYU report urges social media companies to take down 'provably' false information", "language": "en", "published_at": "2019-09-03", "text": "Ctrl + N\n\nFacebook COO Sheryl Sandberg, left, accompanied byTwitter CEO Jack Dorsey arrive to the Senate Intelligence Committee hearing on 'Foreign Influence Operations and Their Use of Social Media Platforms' on Capitol Hill. (AP Photo/Jose Luis Magana)\n\nDisinformation on social media isn\u2019t going away \u2014 it\u2019s evolving as the 2020 election approaches. A New York University report published today is calling on tech companies to prepare by taking a more active role in removing \u201cprovably\u201d false content from their sites.\n\nSuch a move would be a major shift for the technology companies who have been hesitant to play the role of arbiters when it comes to policing content on their sites. Companies like Facebook have been investing heavily in fact-checking partnerships with news organizations and new technology aimed at limiting the spread of false information. But the companies don't automatically remove content from their sites just because it's provably false, as highlighted earlier this year when Facebook decided to leave up a doctored video that made House Speaker Nancy Pelosi appear drunk.\n\nPaul M. Barrett, the NYU professor who wrote the report, tells me those policies need to change to prepare for escalating disinformation threats ahead of the next election. He says the companies have to do everything they've been doing and more to prepare for the ever-changing threat.\n\n\u201cThey have to take responsibility for the way their sites are misused,\u201d Barrett, deputy director of the NYU Stern Center for Business and Human Rights, tells me in an interview.\n\nThe report lays out sobering predictions about how a host of bad actors could build on the playbook that Russians executed to stoke political divisions ahead of the 2016 election. Since then, a new cast of actors \u2014 including Iran, China and even domestic players \u2014 have shown they\u2019re also capable of exploiting social media for political gain, and it\u2019s likely they\u2019ll use different techniques, like \u201cdeepfakes\u201d or videos and images altered with artificial intelligence.\n\nFacebook spokesman Andy Stone said in a statement that the company knows its adversaries are \"always changing their techniques.\"\n\n\"We\u2019ve developed smarter tools, greater transparency, and stronger partnerships to better identify emerging threats, stop bad actors, and reduce the spread of misinformation,\" Stone said. \"We also know that security is never finished and we can\u2019t do this alone, so we are working with policymakers and outside experts to make sure we continue to improve.\u201d\n\nHere are Barret's nine recommendations for how the companies should get ready for disinformation in 2020:\n\n1. Invest in detecting and removing deepfake videos \u2014 before regulators step in and require companies to do so.\n\nDeepfake technology has rapidly advanced since the last election, and Barrett predicts videos will be unleashed depicting 2020 candidates doing or saying things they never did. He says it's time for companies to invest more significantly in developing technology and hiring people to detect and remove these videos. Earlier this year, Google announced a project to invest in research on fake audio detection, and Barrett says other companies should follow.\n\n2. Take down content that can \u201cdefinitively be shown to be untrue.\u201d\n\nIn his boldest proposal, Barrett argues companies are increasingly taking down other types of problematic content, like hate speech and posts deemed to be aimed at voter suppression. He argues that disinformation should be added to the list of content the companies eliminate when it's clear the information is false. For example, he says the companies should take down an article that could be headlined, \u201cThe Sandy Hook Massacre Was Staged,\u201d that is definitively false. But stories that are misleading but not provably false like, for example, \u201cJournalists Really Are the Enemy of the People,\u201d should remain online.\n\n\u201cWe urge the companies to prioritize false content related to democratic institutions, starting with elections,\u201d he said. \u201cAnd we suggest that they retain clearly marked copies of removed material in a publicly accessible, searchable archive, where false content can be studied by scholars and others, but not shared or retweeted.\u201d\n\n3. Hire a \u201ccontent overseer\u201d reporting directly to the chief executive and chief operating officer.\n\nBarrett says right now, responsibility for content decisions tends to be \u201cscattered\u201d across many different teams at the tech companies. He says it's time to centralize these decisions under one executive at a company who has significant clout to better streamline important decisions.\n\n4. Increase defenses against misinformation at Instagram.\n\n\u201cInstagram has been a problem all along, but for whatever reason we don\u2019t pay as much attention to it,' Barrett tells me in an interview. As my colleague Tonya Riley recently detailed in the Technology 202, Instagram has recently rolled out a new fact-checking tool, but experts are concerned it might have limited impact on disinformation. Barrett says it's time for Instagram and its parent company Facebook to come up with a clearer strategy for approaching disinformation, especially as he predicts phony memes could be a key tool bad actors deploy in 2020.\n\n5. Restrict message forwarding even more at WhatsApp.\n\nEarlier this year, Facebook instituted a five-time limit on message forwarding to WhatsApp groups to ensure rumors and fake news don't fly rampant. Barrett thinks this is a good first step, but he recommends the company go farther and only allow users to forward a message to a group chat once.\n\n6. Pay more attention to the growing threat of for-profit disinformation campaigns.\n\nFor-profit disinformation services have gone global and are becoming more sophisticated, Barrett warns. There are signs some for-profit groups have used similar tactics as the Russian trolls in 2016, but their goal is to turn a profit rather than influence ideologies. Barrett says companies need to be more vigilant in this area.\n\n7. Support legislation to increase political ad transparency on social media.\n\nBarrett thinks it's time for the tech industry to throw its \u201cconsiderable lobbying clout\u201d behind bills like the Honest Ads Act, which would require tech companies to be more transparent about who is paying for political ads on their platforms. Companies like Facebook have taken voluntary steps to address this issue in the absence of regulation, and Facebook and Twitter have endorsed the legislation. But Barrett is calling on the companies to make this one of their top political priorities.\n\n8. Collaborate more.\n\nThe companies should create a permanent intercompany task force focused on disinformation, Barrett argues. The companies have been working together more often to identify inauthentic behavior on their websites, but Barrett thinks they could do more if they had a more formal body to address disinformation. The companies already have such partnerships to address other harmful things, like terrorist content.\n\n9. Make social media literacy a prominent and permanent feature on their websites.\n\nBarrett tells me that social media companies have made positive strides in supporting digital literacy programs that educate the public about disinformation, like supporting classes at school for children and teens. But he says the companies could post a reminder to their users about the threat of disinformation every time they log in. \u201cThe more often users are reminded of this fact \u2014 and are taught how to distinguish real from fake \u2014 the less influence false content will wield,\u201d he writes in the report. \u201cConcise, incisive instruction, possibly presented in FAQs format, should be just one click away for all users of all of the platforms, all of the time.\u201d\n\nYou are reading The Technology 202, our guide to the intersection of technology and politics. Not a regular subscriber?\n\nBITS, NIBBLES AND BYTES\n\nThe thumbs-up Like logo on a sign at Facebook headquarters in Menlo Park, Calif. (Jeff Chiu/AP)\n\nBITS: Facebook may no longer show the number of \"Likes\" a post receives in your news feed, the company confirmed to TechCrunch's Josh Constine yesterday. Although it wouldn't say when or if it will begin testing the feature, potential plans to do so could indicate Facebook is taking criticism of the addictive nature of its products more seriously in light of increased scrutiny from government regulators.\n\nBased on code found in Facebook's Android app by researcher Jane Manchun Wong, the test would experiment by showing some users just a few reaction emojis but not a full count of who liked the status. Instagram, which is owned by Facebook, already began experimenting with removing like counts earlier this year to some positive results. (Facebook did not release internal findings about its Instagram experiment and has argued in the past the feature isn't entirely bad for users.)\n\nAn expansion of the test across Facebook's products could be a way to placate growing criticism from regulators about the addictive nature of the platform. Sen. Josh Hawley (R-Mo.) introduced legislation in July that would give the Federal Trade Commission the authority to ban practices designed to exploit users and keep them on a platform. Facebook recently reached a settlement with the FTC following the agency's broad investigation into its privacy practices, and Facebook says the FTC has opened an antitrust investigation.\n\nA staff member walks past the YouTube logo displayed on a wall at Google's YouTube Space production facility in Tokyo. (Kiyoshi Ota/Bloomberg News)\n\nNIBBLES: YouTube will now require channel owners to approve community-provided translations after trolls exploited the tool to harass users and spread offensive content, the Verge's Russell Brandom reports. Although YouTube has always encouraged channel owners to review contributions made by users, the new system shows the company is taking a more proactive step against harassment on its platform.\n\nThe change comes after a YouTube user named JT flagged the high level of offensive materials in translations for the popular YouTuber creator PewdiePie and pointed out how the harassing content crowded out legitimate translations. The video resulted in a harassment campaign against JT in retaliation, Russell reports. JT brought the issue to the attention of YouTube on Twitter, but was originally instructed to just report the offending translations.\n\nYouTube then changed its policies a few days later:\n\nThanks for your patience - Based on the feedback we\u2019ve heard, we are introducing some changes to Community Contributions. Moving forward, creators that have turned on this feature will need to manually review their Community Contributions and check for spam before publishing. \u2014 TeamYouTube (@TeamYouTube) August 30, 2019\n\nYouTube has grappled with how to address hate speech on its platform amid increasing scrutiny this summer, particularly with regard to guidelines for its content creators.\n\nAn iPhone user. (Ryan Anson / AFP/Getty Images)\n\nBYTES: A new Chinese face-swapping app climbed the top of China's iOS App Store over the weekend, but critics are already sounding the alarm about the app maker's privacy practices Bloomberg's Colum Murphy and Zheping Huang report.\n\nThe app, Zao, allows users to upload a photo of themselves and swap it onto the faces of actors in scenes from popular movies and television shows. But much like FaceApp, the Russia-based app that attracted scrutiny earlier this summer, Zao came under fire for having \u201cfree, irrevocable, permanent, transferable, and relicense-able\u201d rights to all this user-generated content. The company changed its policy to seek permission from users for any new uses of their images.\n\nBut the ease with which the app allows users to create \"deepfakes,\" an increasingly catch-all term for the use of artificial intelligence to make it appear someone did or said something that never happened, underscores how little regulation exists for the use of artificial intelligence in doctoring videos.\n\nPUBLIC CLOUD\n\n\u2014 News from the public sector:\n\nGovernments Shut Down the Internet to Stifle Critics. Citizens Pay the Price. Internet shutdowns have become one of the defining tools of government repression in the 21st century \u2014 but citizens bear the cost at work and at home. The New York Times\n\nU.S. and Poland urge tougher checks on foreign influence over 5G The United States and Poland believe suppliers of 5G network equipment should be rigorously evaluated for foreign government control, a joint declaration signed Monday said, as Washington pressures allies to exclude China from 5G networks. Reuters\n\nMeet the former labor organizer emerging as a huge threat to Uber and Lyft A heated debate over a proposed California measure that would force employers such as Uber and Lyft to treat app-based workers as employees has sparked a million-dollar lobbying battle in the heart of the gig economy, a fight that could spill over to the ballot box next year. The Hill\n\nPRIVATE CLOUD\n\n\u2014 News from the private sector:\n\nTwitter and Facebook under fire for removing the word 'vagina' from ads for gynecology book Twitter removed advertisements for a book on gynecology because they used the word \"vagina,\" a prominent medical practitioner has claimed. CNN\n\nVenture-Capital Stalwart Battles Washington\u2019s Crypto Crackdown Andreessen Horowitz, a venture-capital firm known for early investments in companies including Facebook, is putting up a fight against Washington\u2019s cryptocurrency crackdown. Wall Street Journal\n\nWhat the Jetflicks and iStreamItAll Takedowns Mean for Piracy In a sweeping indictment, the feds came down hard on two unauthorized streaming services that allegedly crossed a very important line. Wired\n\n#TRENDING\n\n\u2014 Tech news generating buzz around the Web:\n\nDating Apps Are Making Marriages Stronger Couples who meet online tend to communicate better and have longer, happier relationships. Wall Street Journal", "description": "That isn't an automatic at the moment.", "authors": ["Cat Zakrzewski", "Technology Policy Reporter", "September At Am"], "top_image": "https://www.washingtonpost.com/pbox.php?url=https://palomaimages.washingtonpost.com/pr2/0662c65790ba11801264d94ee74d228f-4398-3102-70-8-ICJA2AVREMI6RC2TKAIWO2HETE.jpg&w=1484&op=resize&opt=1&filter=antialias&t=20170517"}