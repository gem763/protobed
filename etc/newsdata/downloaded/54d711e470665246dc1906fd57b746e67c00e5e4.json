{"pub": "guardian", "url": "https://theguardian.com/technology/2019/sep/24/ai-equal-with-human-experts-in-medical-diagnosis-study-finds", "downloaded_at": "2019-09-25 04:35:05.024054+00:00", "title": "AI equal with human experts in medical diagnosis, study finds", "language": "en", "text": "Artificial intelligence is on a par with human experts when it comes to making medical diagnoses based on images, a review has found.\n\nThe potential for artificial intelligence in healthcare has caused excitement, with advocates saying it will ease the strain on resources, free up time for doctor-patient interactions and even aid the development of tailored treatment. Last month the government announced \u00a3250m of funding for a new NHS artificial intelligence laboratory.\n\nHowever, experts have warned the latest findings are based on a small number of studies, since the field is littered with poor-quality research.\n\nOne burgeoning application is the use of AI in interpreting medical images \u2013 a field that relies on deep learning, a sophisticated form of machine learning in which a series of labelled images are fed into algorithms that pick out features within them and learn how to classify similar images. This approach has shown promise in diagnosis of diseases from cancers to eye conditions.\n\nHowever questions remain about how such deep learning systems measure up to human skills. Now researchers say they have conducted the first comprehensive review of published studies on the issue, and found humans and machines are on a par.\n\nProf Alastair Denniston, at the University Hospitals Birmingham NHS foundation trust and a co-author of the study, said the results were encouraging but the study was a reality check for some of the hype about AI.\n\nDr Xiaoxuan Liu, the lead author of the study and from the same NHS trust, agreed. \u201cThere are a lot of headlines about AI outperforming humans, but our message is that it can at best be equivalent,\u201d she said.\n\nWriting in the Lancet Digital Health, Denniston, Liu and colleagues reported how they focused on research papers published since 2012 \u2013 a pivotal year for deep learning.\n\nAn initial search turned up more than 20,000 relevant studies. However, only 14 studies \u2013 all based on human disease \u2013 reported good quality data, tested the deep learning system with images from a separate dataset to the one used to train it, and showed the same images to human experts.\n\nThe team pooled the most promising results from within each of the 14 studies to reveal that deep learning systems correctly detected a disease state 87% of the time \u2013 compared with 86% for healthcare professionals \u2013 and correctly gave the all-clear 93% of the time, compared with 91% for human experts.\n\n'It's going to create a revolution': how AI is transforming the NHS Read more\n\nHowever, the healthcare professionals in these scenarios were not given additional patient information they would have in the real world which could steer their diagnosis.\n\nProf David Spiegelhalter, the chair of the Winton centre for risk and evidence communication at the University of Cambridge, said the field was awash with poor research.\n\n\u201cThis excellent review demonstrates that the massive hype over AI in medicine obscures the lamentable quality of almost all evaluation studies,\u201d he said. \u201cDeep learning can be a powerful and impressive technique, but clinicians and commissioners should be asking the crucial question: what does it actually add to clinical practice?\u201d\n\nHowever, Denniston remained optimistic about the potential of AI in healthcare, saying such deep learning systems could act as a diagnostic tool and help tackle the backlog of scans and images. What\u2019s more, said Liu, they could prove useful in places which lack experts to interpret images.\n\nLiu said it would be important to use deep learning systems in clinical trials to assess whether patient outcomes improved compared with current practices.\n\nDr Raj Jena, an oncologist at Addenbrooke\u2019s hospital in Cambridge who was not involved in the study, said deep learning systems would be important in the future, but stressed they needed robust real-world testing. He also said it was important to understand why such systems sometimes make the wrong assessment.\n\n\u201cIf you are a deep learning algorithm, when you fail you can often fail in a very unpredictable and spectacular way,\u201d he said.", "description": "Research suggests AI able to interpret medical images using deep learning algorithm", "authors": ["Nicola Davis"], "top_image": "https://i.guim.co.uk/img/media/6043e9d71800085fb1f3b7a1eee3e8df863e5ee5/120_0_3600_2160/master/3600.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=f925812ad75dab3720beb3a8397e3309", "published_at": "2019-09-24"}