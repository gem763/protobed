{"pub": "guardian", "url": "https://theguardian.com/technology/2019/sep/15/ex-google-worker-fears-killer-robots-cause-mass-atrocities", "downloaded_at": "2019-09-15 15:13:54.240294+00:00", "title": "Ex-Google worker fears 'killer robots' could cause mass atrocities", "language": "en", "text": "A new generation of autonomous weapons or \u201ckiller robots\u201d could accidentally start a war or cause mass atrocities, a former top Google software engineer has warned.\n\nLaura Nolan, who resigned from Google last year in protest at being sent to work on a project to dramatically enhance US military drone technology, has called for all AI killing machines not operated by humans to be banned.\n\nNolan said killer robots not guided by human remote control should be outlawed by the same type of international treaty that bans chemical weapons.\n\nUnlike drones, which are controlled by military teams often thousands of miles away from where the flying weapon is being deployed, Nolan said killer robots have the potential to do \u201ccalamitous things that they were not originally programmed for\u201d.\n\nNolan, who has joined the Campaign to Stop Killer Robots and has briefed UN diplomats in New York and Geneva over the dangers posed by autonomous weapons, said: \u201cThe likelihood of a disaster is in proportion to how many of these machines will be in a particular area at once. What you are looking at are possible atrocities and unlawful killings even under laws of warfare, especially if hundreds or thousands of these machines are deployed.\n\n\u201cThere could be large-scale accidents because these things will start to behave in unexpected ways. Which is why any advanced weapons systems should be subject to meaningful human control, otherwise they have to be banned because they are far too unpredictable and dangerous.\u201d\n\nGoogle recruited Nolan, a computer science graduate from Trinity College Dublin, to work on Project Maven in 2017 after she had been employed by the tech giant for four years, becoming one of its top software engineers in Ireland.\n\nShe said she became \u201cincreasingly ethically concerned\u201d over her role in the Maven programme, which was devised to help the US Department of Defense drastically speed up drone video recognition technology.\n\nInstead of using large numbers of military operatives to spool through hours and hours of drone video footage of potential enemy targets, Nolan and others were asked to build a system where AI machines could differentiate people and objects at an infinitely faster rate.\n\n\u201cAs a site reliability engineer my expertise at Google was to ensure that our systems and infrastructures were kept running, and this is what I was supposed to help Maven with. Although I was not directly involved in speeding up the video footage recognition I realised that I was still part of the kill chain; that this would ultimately lead to more people being targeted and killed by the US military in places like Afghanistan.\u201d\n\nAlthough she resigned over Project Maven, Nolan has predicted that autonomous weapons currently being developed pose a far greater risk to the human race than remote-controlled drones.\n\nShe outlined how external forces ranging from changing weather systems to machines being unable to work out complex human behaviour might throw killer robots off course, with possibly fatal consequences.\n\n\u201cYou could have a scenario where autonomous weapons that have been sent out to do a job confront unexpected radar signals in an area they are searching; there could be weather that was not factored into its software or they come across a group of armed men who appear to be insurgent enemies but in fact are out with guns hunting for food. The machine doesn\u2019t have the discernment or common sense that the human touch has.\n\n\u201cThe other scary thing about these autonomous war systems is that you can only really test them by deploying them in a real combat zone. Maybe that\u2019s happening with the Russians at present in Syria, who knows? What we do know is that at the UN Russia has opposed any treaty let alone ban on these weapons by the way.\n\n\u201cIf you are testing a machine that is making its own decisions about the world around it then it has to be in real time. Besides, how do you train a system that runs solely on software how to detect subtle human behaviour or discern the difference between hunters and insurgents? How does the killing machine out there on its own flying about distinguish between the 18-year-old combatant and the 18-year-old who is hunting for rabbits?\u201d\n\nThe ability to convert military drones, for instance into autonomous non-human guided weapons, \u201cis just a software problem these days and one that can be relatively easily solved\u201d, said Nolan.\n\nShe said she wanted the Irish government to take a more robust line in supporting a ban on such weapons.\n\n\u201cI am not saying that missile-guided systems or anti-missile defence systems should be banned. They are after all under full human control and someone is ultimately accountable. These autonomous weapons however are an ethical as well as a technological step change in warfare. Very few people are talking about this but if we are not careful one or more of these weapons, these killer robots, could accidentally start a flash war, destroy a nuclear power station and cause mass atrocities.\u201d\n\nAutonomous threat?\n\nSome of the autonomous weapons being developed by military powers around the world include:\n\nThe US navy\u2019s AN-2 Anaconda gunboat, which is being developed as a \u201ccompletely autonomous watercraft equipped with artificial intelligence capabilities\u201d and can \u201cloiter in an area for long periods of time without human intervention\u201d.\n\nRussia\u2019s T-14 Armata tank, which is being worked on to make it completely unmanned and autonomous. It is being designed to respond to incoming fire independent of any tank crew inside.", "description": "Engineer who quit over military drone project warns AI might also accidentally start a war", "authors": ["Henry Mcdonald", "John Naughton"], "top_image": "https://i.guim.co.uk/img/media/6d6e90b98d5437f673d6a26eacb2cf2fb5814025/124_242_3316_1990/master/3316.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=2fc36aeeec49e48ceb10eed56011d684", "published_at": "2019-09-15"}