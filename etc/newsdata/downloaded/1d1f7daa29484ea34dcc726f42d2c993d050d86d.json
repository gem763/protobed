{"pub": "guardian", "title": "Could language be the key to detecting fake news? | David Shariatmadari", "url": "https://theguardian.com/commentisfree/2019/sep/02/language-fake-news-linguistic-research", "language": "en", "published_at": "2019-09-02", "downloaded_at": "2019-09-02 09:03:32.020433+00:00", "text": "The internet represents the biggest explosion of data in human history. There\u2019s more out there, and more access to it than ever before. The information ecosystem is a bit like a tropical rainforest: luxuriant, dense and fiercely competitive. As such, it contains its fair share of predators and poisonous plants.\n\nDeliberately misleading articles, websites and social media posts can come about for lots of different reasons: they might be trying to influence elections or policies; they might represent a form of cyberwarfare between states; they might be aimed at raising someone\u2019s profile and influence, or discrediting their opponents. Or they might simply be about making money, relying on the attention-grabbing nature of outrageous lies to generate ad revenue, as in the case of the \u201cdigital gold rush\u201d that saw a small Macedonian town register more than 150 pro-Trump websites during the 2016 presidential race.\n\nWe may have to rely on AI to do the heavy lifting for us \u2013 and tell us whether telltale linguistic patterns are present\n\nOne thing they may have in common, however, is the language they use.\n\nHaving a reliable way of identifying fake news is important. The whole reason it\u2019s a problem is that it mimics reliable reporting \u2013 and people can\u2019t always tell the difference. That\u2019s why, for the past few years, researchers have been trying to work out what the linguistic characteristics of fake news are. Computers that are fed material already classified as misleading are able to identify patterns in the language used. They\u2019re then able to apply that knowledge to new material, and flag it as potentially dubious.\n\nOne such project, led by Fatemeh Torabi Asr at Simon Fraser University in Canada, recently found that \u201con average, fake news articles use more \u2026 words related to sex, death and anxiety\u201d. \u201cOverly emotional\u201d language is often deployed. In contrast, \u201cGenuine news \u2026 contains a larger proportion of words related to work (business) and money (economy).\u201d\n\nAnother group of researchers analysed the relationship of various grammatical categories to fake news. They concluded that words which can be used to exaggerate are all found more often in deliberately misleading sources. These included superlatives, like \u201cmost\u201d and \u201cworst\u201d, and so-called subjectives, like \u201cbrilliant\u201d and \u201cterrible\u201d. They noted that propaganda tends to use abstract generalities like \u201ctruth\u201d and \u201cfreedom\u201d, and intriguingly showed that use of the second-person pronoun \u201cyou\u201d was closely linked to fake news.\n\nSome of these approaches have their problems. Jack Grieve, at the University of Birmingham, cautions that scholars don\u2019t always control for genre \u2013 so the differences in language seen above might just come down to the difference between a more formal news article, and a more casual Facebook post.\n\nTo get around this problem, Grieve\u2019s team has compared 40 retracted and 41 non-retracted articles by Jayson Blair, who resigned from the New York Times in disgrace in 2003. These were produced in a single genre \u2013 national newspaper writing \u2013 but they still displayed subtle, probably unconscious differences in register, related, according to Grieve, to the different communicative purposes they served (on the one hand to inform, on the other to deceive). Even though he was trying to pass his work off as factual, there were subtle tells that only become evident when the data is crunched. For example, there were more emphatics like \u201creally\u201d and \u201cmost\u201d in Blair\u2019s retracted articles. He used shorter words and his language was less \u201cinformationally dense\u201d. The present tense cropped up more often and he relied on the third person pronouns \u201che\u201d and \u201cshe\u201d rather than full names \u2013 something that\u2019s typical of fiction.\n\nImmigration panic: how the west fell for manufactured rage Read more\n\nSo what does all this tell us? Clearly, we don\u2019t have a foolproof means of telling fact from fake yet, but there are certain features that should put us on our guard. Is the writing more informal than you\u2019d expect? Does it contain lots of superlatives and emphatic language? Does it make subjective judgments or read more like narrative than reportage? Ultimately, we may have to rely on artificial intelligence to do the heavy lifting for us \u2013 and it should be able to tell us whether those telltale linguistic patterns seen in large datasets of fake news, invisible to the \u201cnaked eye\u201d, are present.\n\nFor me there\u2019s an interesting correspondence with certain kinds of political rhetoric here. The language of fakery, with its powerful subjective statements and focus on anxiety, has something in common with that used by populist leaders. Their style, which often involves \u201cadversarial, emotional, patriotic and abrasive speech\u201d should put us on our guard too. Cooler heads make for a more boring read, but they might get you a little closer to the truth.\n\n\u2022 David Shariatmadari is a Guardian editor and writer, and author of Don\u2019t Believe A Word: The Surprising Truth About Language", "description": "Purveyors of disinformation can be caught out by the particular words they use, says Guardian writer and editor David Shariatmadari", "authors": ["David Shariatmadari"], "top_image": "https://i.guim.co.uk/img/media/08f2531db01acd8d4fe77b4cd3a3c97cbe319caf/0_132_3600_2160/master/3600.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctb3BpbmlvbnMucG5n&enable=upscale&s=8a8f7981c49c0591607b2a45d4391a57"}