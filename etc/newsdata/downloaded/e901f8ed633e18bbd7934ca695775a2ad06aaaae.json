{"pub": "guardian", "url": "https://theguardian.com/commentisfree/2019/sep/20/polls-public-opinion-polling-industry", "downloaded_at": "2019-09-20 08:16:18.561910+00:00", "title": "The polling industry doesn\u2019t measure public opinion \u2013 it produces it | Richard Seymour", "language": "en", "text": "The polls keep coming, one after another. But the polls are all over the place. For example, they can\u2019t agree on where the competing parties stand. One gives the Tories a 10-point lead, another gives Labour a 2% lead. Polling has never been an exact science, but political volatility, the growth of new polling firms and the extraordinary ubiquity of conflicting polls, has put it under new strains and new scrutiny.\n\nPolling was once a specialised sector of market research. Now it is a niche area of the much bigger data industry, using the same Bayesian techniques of probabilistic analysis that stock markets employ in financial forecasting. Its customers include huge financial firms that can extract commercial advantage from the slightest margin of predictive accuracy.\n\nWhen it comes to prediction, the neoliberal economist Frank Knight made an important distinction between \u201crisk\u201d and \u201cuncertainty\u201d. The data revolution has helped capitalism manage risk, but it manages uncertainty far less effectively. One byproduct of this is that, although we have more data than ever before, political outcomes are no easier to predict: hence, the current crisis of polling.\n\nWe can no more dispense with political polling than capitalism can give up on data\n\nFor pollsters, the risk of a \u201cwrong\u201d prediction is managed in their selection of who to interview, and how to weight the results. If young and poor voters didn\u2019t turn out last time, they probably won\u2019t this time. But in conditions of political uncertainty, these assumptions start to look like what they are: guesswork and ideology.\n\nBy relying on past outcomes to guide their assumptions, pollsters made no room for political upsets. Since poll numbers are often used as a kind of democratic currency \u2013 a measure of \u201celectability\u201d \u2013 the effect of these methodological assumptions was to ratify the status quo. They reinforced the message: \u201cThere is no alternative.\u201d Now that there are alternatives, polling firms are scrabbling to update their models.\n\nYet, what do polls actually measure? In 1947, as modern polling was becoming a major industry, researchers canvassed American public opinion on something called the \u201cMetallic Metals Act\u201d. No such act existed, metallic metals being akin to ironic irony, or tautologous tautology. But 70% of respondents took a firm view for or against. They weren\u2019t stupid: they were just acting as most of us do in an interview situation, under pressure to have definite views about something of which we may be uncertain, conflicted or even ignorant.\n\nThese researchers weren\u2019t measuring opinion. They were producing it. This is what the polling industry does: that\u2019s why it is an industry.\n\nThe artifice of the phone interview, or online survey, resembles no real-life circumstance in which opinions are formed. It is an assembly line designed to produce quantifiable opinions: that is, to express sentiments, preferences. This may make sense in the context of market research to measure consumer preferences. But formulating a preference, or even purchasing an item, is quite unlike casting a vote. The latter is closer to a major life decision \u2013 often rooted in collective experiences like class and race \u2013 than to a brand choice.\n\nThe methodology of polling implies that there exists a general will on any given issue \u2013 the sum of a quantity of individual opinions of roughly equal weight. These can be totalled up into a magic percentage. But one reason voting intention polls must weight their results is that not all opinions are equally informed, committed or even meaningful. Most of us have ambivalent or downright contradictory views on some subjects, which is why small adjustments in polling questions can produce such varying results.\n\nSo while polling, in conditions of political stability, can often accurately predict voting outcomes, its findings are less meaningful as a guide to \u201cpublic opinion\u201d on more complex issues. \u201cNothing is more inadequate,\u201d wrote the sociologist Pierre Bourdieu, \u201cfor representing the state of opinion than a percentage.\u201d \u201cPublic opinion\u201d is a mirage.\n\nThere is, nonetheless, something authoritative about a round figure, which appears to brook no argument. Yet, the only test of polling is its predictive power. And predictions failed in 2015, 2016 and 2017. When this happens, there is a tendency in the media to explain by reference to misleading respondents: \u201cshy Tories\u201d, for example.\n\nPerhaps some people deliberately obscure their real intentions. But consider what happened in the 2010 general election, with \u201cCleggmania\u201d. For weeks, the Liberal Democrats surged, sometimes to first place, gaining strongly among young voters. In the end, they lost five seats.\n\nWhy did the polls not predict this outcome correctly? Most of us, if asked about an issue we aren\u2019t sure of, or haven\u2019t thought about, will cast our minds back to the news. Pollsters are measuring, as much as anything, the effects of recent news cycles. The media publishing them are reporting on the effects of their own coverage. They are short-term, however, and can recede by election day, by which time other assets such as street campaigning can make a significant difference. Cleggmania was precisely such a media phenomenon. The Lib Dems were not offering more to young voters in 2010 than in 2005: arguably, they offered less. But a surge of attention following Nick Clegg\u2019s debate performances drove the party up the polls, only for most of the surge to burn out by election day.\n\nYet, most of us believe in public opinion. If we didn\u2019t, the polling industry wouldn\u2019t have a market. Polling is clearly useful for capturing trends in party support, or aspects of emerging moods, however partial. But political professionals working behind closed doors rarely make the mistake of treating polls, whether on voting intentions or issues, as democratic verdicts. Rather, the data is raw material to be worked on and shaped \u2013 used to guide publicity or election campaigns.\n\nBecause we believe in it, though, polling tends to become a self-fulfilling prophecy, particularly on social media \u2013 where each new poll is eagerly shared by supporters of whichever party appears to be surging this week. Like older forms of divination, the numbers give form to our desires and fears. They authorise our beliefs, legitimise our candidates and generate little waves of excitement. They allow us to blow attention bubbles around issues or parties, boosting the ratings further, and spawning yet another squee of excitement and feverish sharing of numbers. In moments of crisis, this can even allow small parties to game the system and generate attention and support as if from nowhere. If it weren\u2019t for this, it is difficult to see how the Brexit party, a corporation with no members and a relatively small budget, could have won the European elections in May.\n\nHow do you know whether you can trust poll results? Here\u2019s what to watch out for | Rob Vance Read more\n\nAt its worst, polling can subvert democratic debate. Even a slight polling plurality is enough for politicians and newspapers to assert that \u201cthe people\u201d want whatever they\u2019re selling, producing the illusion of a non-existent consensus in favour of policies that have little real support.\n\nWe can no more dispense with political polling than capitalism can give up on data. For all its limits, the data usually \u201cworks\u201d in the narrow sense that it quantifies an intention or sentiment, however fleeting or partial. The problem is the way the industry is supported by a belief in public opinion. If we can let go of that superstition, the numbers will have less power over us.\n\n\u2022 Richard Seymour is a political activist and author; his latest book is The Twittering Machine", "description": "There is something authoritative and reassuring about a round number. But we shouldn\u2019t pretend that a percentage can meaningfully represent the views of the public, says political activist and author Richard Seymour", "authors": ["Richard Seymour"], "top_image": "https://i.guim.co.uk/img/media/e012ecd4ed6d90775815f04c292b13d0d1fafe6d/0_192_3000_1800/master/3000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctb3BpbmlvbnMucG5n&enable=upscale&s=ae2d338b965274bf64ac7a42b57d5ef8", "published_at": "2019-09-20"}