{"pub": "guardian", "url": "https://theguardian.com/technology/2019/sep/17/imagenet-roulette-asian-racist-slur-selfie", "downloaded_at": "2019-09-18 07:24:57.676688+00:00", "title": "The viral selfie app ImageNet Roulette seemed fun \u2013 until it called me a racist slur", "language": "en", "text": "How are you supposed to react when a robot calls you a \u201cgook\u201d?\n\nAt first glance, ImageNet Roulette seems like just another viral selfie app \u2013 those irresistible 21st-century magic mirrors that offer a simulacrum of insight in exchange for a photograph of your face. Want to know what you will look like in 30 years? There\u2019s an app for that. If you were a dog what breed would you be? That one went viral in 2016. What great work of art features your doppelganger? Google\u2019s Arts & Culture app dominated social media feeds in 2018 when it gave us a chance to bemoan being more Picasso than Botticelli, or vice versa.\n\nThe enduring popularity of these apps, dubious origins and privacy policies be damned, speaks to our basic insecurity. They cater to the part of us that, aware of how much time we spend looking at screens, starts to wonder what the screens see back \u2013 a shortcut to selfie-awareness.\n\nBut ImageNet Roulette, a project developed by the artificial intelligence researcher Kate Crawford and the artist Trevor Paglen, flips this basic formula on its head. Built in concert with their new exhibition, Training Humans, at the Fondazione Prada in Milan, the site\u2019s goal is not to use technology to help us see ourselves, but to use ourselves to see technology for what it actually is.\n\nRise of the racist robots \u2013 how AI is learning all our worst impulses Read more\n\nThe site\u2019s algorithm was trained on photos of humans contained in ImageNet, a dataset described by Crawford as \u201cone of the most significant training sets in the history of AI\u201d. Created in 2007 by researchers at Stanford and Princeton, ImageNet includes more than 14m photographs, mostly of objects but also of humans, that have been classified and labeled by legions of workers on Amazon\u2019s crowdsourcing labor site, Mechanical Turk.\n\nIf you upload your photo, ImageNet Roulette will use AI to identify any faces, then label them with one of the 2,833 subcategories of people that exist within ImageNet\u2019s taxonomy. For many people, the exercise is fun. For me, it was disconcerting.\n\nAs a technology reporter, I\u2019m regularly tasked with writing those scolding articles about why you should be careful which apps you trust, so I usually eschew viral face apps. But after a day of watching my fellow journalists upload their ImageNet Roulette selfies to Twitter with varying degrees of humor and chagrin about their labels (\u201cweatherman\u201d, \u201cwidower\u201d, \u201cpilot\u201d, \u201cadult male\u201d), I decided to give it a whirl. That most of my fellow tech reporters are white didn\u2019t strike me as relevant until later.\n\nI don\u2019t know exactly what I was expecting the machine to tell me about myself, but I wasn\u2019t expecting what I got: a new version of my official Guardian headshot, labeled in neon green print: \u201cgook, slant-eye\u201d. Below the photo, my label was helpfully defined as \u201ca disparaging term for an Asian person (especially for North Vietnamese soldiers in the Vietnam War)\u201d.\n\nFacebook Twitter Pinterest How artificial intelligence classified Julia Carrie Wong\u2019s headshot. Photograph: ImageNet Roulette\n\nOn the one hand, this is exactly the outcome that Crawford and Paglen were aiming for. ImageNet Roulette is not based on a magical intelligence that shows us who we are; it\u2019s based on a severely flawed dataset labeled by fallible and underpaid humans that shows us its limitations.\n\n\u201cWe want to shed light on what happens when technical systems are trained on problematic training data,\u201d they wrote. \u201cAI classifications of people are rarely made visible to the people being classified. ImageNet Roulette provides a glimpse into that process \u2013 and to show the ways things can go wrong.\u201d\n\nBut my experience with ImageNet Roulette also occurred during a strange week for people of Asian descent in America, when the public was engaged in a fraught debate over whether or not it is funny to call Chinese people \u201cchinks\u201d and Asian Americans were grappling with the novel experience of having a national political \u201crepresentative\u201d who does not necessarily represent our views.\n\nI found myself both oddly upset and oddly relieved to be labeled a gook. As a biracial \u201cJew chink\u201d (yes, Shane Gillis, we actually exist outside your pathetic punchlines) with brownish skin and a bony nose, people usually assume that I\u2019m any ethnicity but Chinese. Having a piece of technology affirm my identity with a racist and dehumanizing slur is strange.\n\nStill, isn\u2019t that what we\u2019re all looking for when we look into these magic mirrors? We want to know how the world sees us. I got my answer.", "description": "During a strange week for Asian Americans, the app \u2013 which is part of an art project \u2013 achieved its aim by underscoring exactly what\u2019s wrong with artificial intelligence", "authors": ["Julia Carrie Wong"], "top_image": "https://i.guim.co.uk/img/media/703a81fa39bea016f38d071b4ca7e180062cd33a/0_154_6000_3600/master/6000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctb3BpbmlvbnMucG5n&enable=upscale&s=d0171da5af3304bbd895ddbe5a99b481", "published_at": "2019-09-17"}