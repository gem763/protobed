{"pub": "atlantic", "url": "https://theatlantic.com/technology/archive/2019/10/google-allegedly-used-homeless-train-pixel-phone/599668", "downloaded_at": "2019-10-09 12:43:29.587159+00:00", "title": "How the Homeless Became Raw Materials for Big Tech", "language": "en", "text": "Managers reportedly encouraged contractors to mischaracterize the data collection as a \u201cselfie game,\u201d akin to Snapchat filters such as Face Swap. College students who agreed to the scans later told the Daily News that they didn\u2019t recall ever hearing the name \u201cGoogle,\u201d and were simply told to play with the phone in exchange for a gift card. To entice homeless users in LA to consent, contractors were allegedly instructed to mention a California law that allows the gift cards to be exchanged for cash. The whole episode is, in a bleak way, an apparent attempt to diversify AI training data while paying people for their information. But the result is completely dystopian.\n\nRead: FaceApp is everyone\u2019s problem\n\nAccording to The New York Times, Google temporarily suspended the data collection pending an internal investigation. In an emailed statement to The Atlantic, a Google spokeswoman said, \u201cWe\u2019re taking these claims seriously and investigating them. The allegations regarding truthfulness and consent are in violation of our requirements for volunteer research studies and the training that we provided.\u201d\n\nIt\u2019s baffling that this purported scheme, which the Daily News\u2019 reporting suggests commodified black and homeless Americans, was intended to reduce racial bias. But as the Harvard technologist Shoshanna Zuboff has argued, people have always been the \u201craw materials\u201d for Big Tech. Products like the Pixel or iPhone, and services like Google and Facebook, collect our data as we use them, companies refine that data and, with each new generation, sell us more advanced products that collect more useful data. In this framework, our habits, our choices, our likes, and our dislikes are not unlike soybeans or petroleum or iron ore: Natural resources that are extracted and processed by huge firms, for massive profit.\n\nSometimes this looks like a smart thermostat getting better at predicting how cool you like your home, and sometimes it looks like a $1 trillion company allegedly offering $5 gift cards to homeless black people to better sell a $1,200 phone.\n\nAs the techlash continues, some lawmakers are seeking to empower their constituents to demand that companies like Google pay users for their data. California and Alaska have debated legislation to charge companies for using people\u2019s personal data. Andrew Yang, the 2020 Democratic presidential candidate, has advocated treating data as a \u201cproperty right.\u201d Facebook co-founder Chris Hughes suggests a \u201cdata dividend,\u201d a revenue tax on companies monetizing enormous amounts of public data, paid out to users across the country like Universal Basic Income.\n\nRead: What Amazon thinks you\u2019re worth\n\nBut following that line of thinking makes it clear that we still have no ethical or economic framework for valuing data collected from people across different social contexts. Should tech companies pay more for dark-skinned subjects because they\u2019re underrepresented in training data? If our bodies are commodities, what\u2019s a fair price, and who should set it? The data ownership is, fundamentally, limited: Even if we manage, with the help of Hughes or Yang or state legislatures, to negotiate a high price for our data, we\u2019re still for sale.\n\nIn a backwards way, movements to pay users for the data that tech companies take from them only corroborate the process by which Silicon Valley turns our faces into commodities. Imagine an unregulated race-to-the-bottom market where companies target the most vulnerable for their data, restrained only by the alarmingly low bar for consent to improve their products. It would look a lot like paying homeless people $5 for a face scan.\n\nWe want to hear what you think about this article. Submit a letter to the editor or write to letters@theatlantic.com.", "description": "Google allegedly scanned volunteers with dark skin tones in order to perfect the Pixel phone\u2019s face-unlock technology.", "authors": ["Sidney Fussell"], "top_image": "https://cdn.theatlantic.com/assets/media/img/mt/2019/10/AP_19205729770783/facebook.jpg?1570565808", "published_at": "2019-10-09"}