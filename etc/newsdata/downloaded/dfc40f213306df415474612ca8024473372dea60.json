{"pub": "axios", "url": "https://axios.com/the-coming-deepfakes-threat-to-businesses-308432e8-f1d8-465e-b628-07498a7c1e2a.html", "downloaded_at": "2019-10-12 17:04:18.185093+00:00", "title": "The coming deepfakes threat to businesses", "language": "en", "text": "What's happening: For all the talk about fake videos, it's deepfake audio that has emerged as the first real threat to the private sector.\n\nSymantec, a major cybersecurity company, says it has seen three successful audio attacks on private companies. In each, a company's \"CEO\" called a senior financial officer to request an urgent money transfer.\n\nScammers were mimicking the CEOs' voices with an AI program that had been trained on hours of their speech \u2014 culled from earnings calls, YouTube videos, TED talks and the like.\n\nMillions of dollars were stolen from each company, whose names were not revealed. The attacks were first reported in the BBC.\n\nAnd in March, a Twitter account falsely claiming to belong to a Bloomberg journalist reportedly tried to coax personal information from Tesla short-sellers. Amateur sleuths said the account's profile photo had the hallmarks of an AI-generated image.\n\nBig picture: This threat is just beginning to emerge. Video and audio deepfakes are improving at a frightening pace and are increasingly easy to make.\n\nThere's been an uptick in sophisticated audio attacks over the past year, says Vijay Balasubramaniyan, CEO of Pindrop, a company that protects call centers from scammers.\n\nin sophisticated audio attacks over the past year, says Vijay Balasubramaniyan, CEO of Pindrop, a company that protects call centers from scammers. But businesses aren't ready, experts tell Axios. \"I don\u2019t think corporate infrastructure is prepared for a world where you can\u2019t trust the voice or video of your colleague anymore,\" says Henry Ajder of Deeptrace, a deepfakes-detection startup.\n\nEven if companies were clamoring for defenses, few tools exist to keep harmful deepfakes at bay, says Symantec's Saurabh Shintre. The challenge of automatically spotting a deepfake is almost insurmountable, and there are hurdles still ahead for a promising alternative: creating a digital breadcrumb trail for unaltered media.\n\nPindrop monitors for audio attacks like altered voices on customer service lines.\n\nSymantec and ZeroFOX, another cybersecurity company, say they are developing technology to detect audio fakes.\n\nWhat's out there already isn't cheap.\n\nNew Knowledge, a firm that defends companies from disinformation, says its services can run from $50,000 to \"a couple million\" a year.\n\na firm that defends companies from disinformation, says its services can run from $50,000 to \"a couple million\" a year. Just monitoring the internet for potential fakes comes at \"a substantial cost,\" says Matt Price of ZeroFOX. \"And that's not even talking about the detection piece, which will probably be fairly expensive.\"\n\nAs a result, businesses are largely defenseless for now, leaving an opening for a well-timed deepfake to drop like a bomb.\n\n\"If you're waiting for it to happen, you're already too late,\" New Knowledge COO Ryan Fox tells Axios.\n\nGo deeper: Companies take the battle to online mobs", "description": "Audio and video generated by AI can impersonate CEOs.", "authors": [], "top_image": "https://images.axios.com/992Lw5FLvK4j5oDlIGGze_JciR8=/0x0:1920x1080/1920x1080/2019/07/18/1563477066850.gif", "published_at": "2019-07-19"}