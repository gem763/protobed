{"pub": "techcrunch", "url": "https://techcrunch.com/2019/10/28/instagram-expands-ban-on-suicide-content-to-cover-cartoons-and-memes", "downloaded_at": "2019-10-28 13:18:02.328302+00:00", "title": "Instagram expands ban on suicide content to cover cartoons and memes \u2013 TechCrunch", "language": "en", "text": "Instagram has expanded a ban on graphical self-harm imagery to include a broader range of content depicting suicide, including fictional illustrations of self-harm and suicide methods such as drawings, cartoons and memes.\n\n\u201cThis past month, we further expanded our policies to prohibit more types of self-harm and suicide content. We will no longer allow fictional depictions of self-harm or suicide on Instagram, such as drawings or memes or content from films or comics that use graphic imagery,\u201d writes Instagram boss, Adam Mosseri, explaining the latest policy shift. \u201cWe will also remove other imagery that may not show self-harm or suicide, but does include associated materials or methods.\u201d\n\nEarlier this year Mosseri, met with the UK\u2019s health secretary to discuss the platform\u2019s policy towards self-harm content. The company has faced high level pressure in the country following a public outcry after the family of Molly Russell, a 14-year-old UK schoolgirl who killed herself after viewing suicide content on Instagram, went public with the tragedy by talking to the BBC.\n\nIn February the Facebook-owned social media platform announced that it would prohibit graphic images of self-harm, such as cutting, and restrict access to non-graphic self-harm content, such as images of healed scars \u2014 by not recommending it in searches.\n\nAt the time it also suggested it was toying with the idea of using sensitive screens to blur non-graphical suicide content, saying it was consulting with experts. In the event it appears to have decided to go further \u2014 by now saying it will also remove fictional content related to self-harm, as well as anything that depicts methods of suicide or self-harm.\n\nInstagram says it\u2019s doubled the amount of self-harm content it has acted on following the earlier policy change \u2014 with Mosseri writing that in the three months following the ban on graphic images of cutting it \u201cremoved, reduced the visibility of, or added sensitivity screens to more than 834,000 pieces of content\u201d.\n\nWhile more than 77% of this content was identified by the platform prior to it being reported, he adds.\n\nA spokesperson for Instagram confirmed to us that the latest policy shift is in effect.\n\nAlthough it\u2019s not clear how long it could take for it to be effectively enforced. Mosseri told BBC News: \u201cIt will take time to fully implement,\u201d adding that: \u201cIt\u2019s not going to be the last step we take.\u201d\n\nIn his blog post about the policy change, the Instagram boss writes that the new policy is \u201cbased on expert advice from academics and mental health organisations like the Samaritans in the UK and National Suicide Prevention Line in the US\u201d, saying: \u201cWe aim to strike the difficult balance between allowing people to share their mental health experiences while also protecting others from being exposed to potentially harmful content.\u201d\n\n\u201cAccounts sharing this type of content will also not be recommended in search or in our discovery surfaces, like Explore. And we\u2019ll send more people more resources with localized helplines like the Samaritans and PAPYRUS in the UK or the National Suicide Prevention Lifeline and The Trevor Project in the United States,\u201d he adds.\n\nHe goes on to argue that the issues involved are complex and \u201cno single company or set of policies and practices alone can solve\u201d, while defending continuing to allow some suicide and self-harm content on Instagram by saying \u201cexperts tell us that giving people a chance to share their most difficult moments and their stories of recovery can be a vital means of support\u201d and that \u201cpreventing people from sharing this type of content could not only stigmatize these types of mental health issues, but might hinder loved ones from identifying and responding to a cry for help\u201d.\n\n\u201cBut getting our approach right requires more than a single change to our policies or a one-time update to our technology. Our work here is never done. Our policies and technology have to evolve as new trends emerge and behaviors change,\u201d he adds.", "description": "Instagram has expanded a ban on graphical self-harm imagery to include a broader range of content depicting suicide, including fictional illustrations of self-harm and suicide methods such as drawings, cartoons and memes. \u201cThis past month, we further expanded our policies to prohibit more types of self-harm and suicide content. We will no longer allow fictional [\u2026]", "authors": [], "top_image": "https://techcrunch.com/wp-content/uploads/2016/09/disrupt_sf16_adam_mosseri-4017.jpg?w=600", "published_at": "2019-10-28"}