{"pub": "townhall", "url": "https://townhall.com/columnists/bobbarr/2019/10/23/artificial-intelligence-produces-artificial-justice-n2555195", "downloaded_at": "2019-10-23 09:42:24.989736+00:00", "title": "Artificial Intelligence Produces Artificial Justice", "language": "en", "text": "The opinions expressed by columnists are their own and do not represent the views of Townhall.com.\n\nThanks to today\u2019s \u201cInternet of Things\u201d (IoT), there is an \u201cautomation\u201d for almost every aspect of our lives. From such mundane if not downright silly things as kitchen faucets that activate on voice command, to the impressive -- massive shipping warehouses run by robotics -- many aspects of life today go beyond that imagined decades ago in science fiction. While we still are waiting for flying cars depicted in the Jetsons television show of the 1960s, or space hotels as portrayed in the sci-fi epic 2001, the array of technologically driven devices available to the average citizen is indeed impressive.\n\nYet, while automation and artificial intelligence simplifies or altogether eliminates many of the activities of day-to-day life, the technology complicates others. For example, how do you program a self-driving car in an emergency situation to choose between the life of a pedestrian or that of its \u201cdriver?\u201d Even more complex are questions now being asked in the context of judicial systems; decisions cutting to the heart of individual liberty. As a Forbes article propositioned, what does justice look like if, or rather when, many aspects of judicial procedures, such as sentencing, are left to computer algorithms?\n\nOn the surface, injecting AI into certain legal procedures may appear to make sense for the same reasons it is used across other sectors of industry and professions. In many arenas, artificial intelligence can process information far faster than humans, even while incorporating astronomically more data; and doing so without \u201chuman error.\u201d\n\nLeaving aside for the moment the question of whether all human \u201cerror\u201d should be eliminated from decision-making, advocates for such technology would ask why wouldn\u2019t we want to use AI in a judicial system that constantly is being blamed for mis-judgments in determining guilt and then in sentencing decisions?\n\nAlready algorithms are used in the judicial system in areas such as risk-assessment and \u201cpredictive policing,\u201d in which AI processes crime data to identify trends that can help improve patrol decisions and police staffing needs.\n\nClearly, there are positive and negative aspects to these AI-developments. For example, risk-assessments can help eliminate prejudice in assigning bail. On the other hand, we have seen the disastrous consequences of innocent people sucked into legal nightmares when predictive AI mistakes perfectly benign activities (like a science teacher\u2019s shopping trip) as criminal conduct if certain boxes are checked.\n\nAs with any computer-driven action, the output of algorithms and AI is only as good as what is input; and, just as more important, who is doing the inputting and why.\n\nWhat might a sentence look like from the perspective of an algorithm designed by the so-called law-and-order types, in which any infraction of a law, no matter the circumstances, warrants the full weight of the law in response? Or, what about the \u201czero-tolerance\u201d gun control zealots who suspend children from school for making finger guns? Just look at the type of \u201cjustice\u201d Democrats demand for President Trump, and imagine such a powerful tool as algorithmic sentencing guidelines crafted by them.\n\nCan \u201cjustice,\u201d especially in the context of criminal law, which by its very nature balances individual liberty against government power, ever be reduced to a technologic formula? Should it be thus degraded?\n\nIn a fundamental sense, determining whether all aspects of a crime exist in order to pursue prosecution and then doling out punishment should the defendant be found guilty, are merely aspects of the judicial process; they are not justice in and of itself. In its truest sense, \u201cjustice\u201d is a principle that ensures -- to the greatest human degree possible -- the right guilty party is brought before the courts, and that the resultant punishment is commensurate and reflective of the individual situation at hand.\n\nJustice reduced to algorithm is a two-dimensional reflection of a multi-dimensional condition. No matter how sophisticated or expansive the data, AI cannot possibly factor in such relevant circumstances as motive, mens rea (that is, a guilty state of mind), or even the fairness of the law itself.\n\nExperience following the adoption of federal Sentencing Guidelines in the late 1980s is highly relevant to any consideration of imposing AI on judicial proceedings. These guidelines were the culmination of a multi-year process to standardize and streamline sentencing for defendants in federal trial court proceedings, but have required numerous and extensive revisions ever since. They ultimately were deemed by the U.S. Supreme Court to be unconstitutional as mandatory \u201cguidelines.\u201d This example alone should cause efforts to \u201cstandardize\u201d fundamental aspects of our legal system via \u201cartificial intelligence\u201d to be viewed with extreme caution; and, in my view, ultimately discarded.", "description": "Thanks to today\u2019s \u201cInternet of Things\u201d (IoT), there is an .10/23/2019 5:38:36AM EST.", "authors": ["Bob Barr", "Matt Vespa", "Timothy Meads", "Julio Rosas"], "top_image": "https://media.townhall.com/townhall/reu/s1280x720/2018/296/ba4dd22d-8547-4a19-867c-e91c40070025.jpg", "published_at": "2019-10-23"}