{"pub": "thehill", "url": "https://thehill.com/opinion/cybersecurity/464217-in-the-ai-era-privacy-and-democracy-are-in-peril", "downloaded_at": "2019-10-05 13:20:00.587434+00:00", "title": "In the AI era, privacy and democracy are in peril", "language": "en", "text": "Lawmakers should not let the impeachment inquiry distract them from addressing an equally pressing issue that threatens U.S. democracy. The unchecked use of Artificial Intelligence (AI) by the major internet platforms is invading our privacy, putting our democracy at risk.\n\nGoogle reads everyone\u2019s email, analyzes our searches, where we surf, where we go in the physical world, who our friends are, who we have spoken to and much more. The internet giants have appropriated public and private data to create \u201cprediction products\u201d that can forecast individual behavior and manipulate them without their awareness (or consent). Pure profit maximization has led to a capitalistic form of surveillance that is arguably even worse than the Chinese model, which is ostensibly about maximizing the benefits to all of society. These two extreme objective functions \u2013 unconstrained profit maximization and state control \u2013 lead to the same result: The ceding of free will to AI algorithms that control us overtly or covertly. What does democracy mean if there is no free will?\n\nI recommend regulating the use of personal data for prediction products. I also propose classifying certain platforms as \u201cdigital utilities\u201d that aim to maximize public benefit and spur economic growth, much like the interstate highway system and the \u201cInformation superhighway\u201d have done for physical and electronic commerce.\n\nADVERTISEMENT\n\nU.S. regulators should look to Europe and India\u2019s models as two low-risk approaches to data protection. In a Washington Post article in September 2018, I showed that four major models of data use have emerged globally, with the U.S. and Chinese models at extreme ends, and the European and Indian models emphasizing individual data protection.\n\nEurope\u2019s General Data Protection Regulation (GDPR) model requires \u201ca data controller to hold and process only the data that is absolutely necessary for the transaction.\u201d Such a move would limit the considerable \u201cbehavioral surplus\u201d that such companies use for their prediction products, and better protect individuals from explicit manipulation.\n\nBut we can and should go further by considering two strengths of the Indian approach. The first is individual empowerment through \u201cdata fiduciaries,\u201d who are similar to financial fiduciaries in that their primary allegiance is to the individual and require explicit consent for sharing personal data.\n\nSecond, India views certain types of infrastructure as \u201cdigital utilities,\u201d on top of which other utility or commercial platforms can operate. For example, the Aadhar platform, the world\u2019s largest biometric identification system, provides real-time authentication, confirming, \u201cAre you who you say you are?\u201d Payment platforms are also a utility, and make use of Aadhar\u2019s real-time authentication capability. Platforms form a \u201cstack , \u201d with upper layers making use of the high-volume, low-cost utility layers at the bottom.\n\nIn an effort to create \u201cdigital utilities,\u201d U.S. regulators need to consider two properties of internet platforms. First, these platforms do not conform to standard industry boundaries, making antitrust regulation difficult. Which sector does Amazon belong to? Google? Facebook?\n\nADVERTISEMENT\n\nSecond, internet platforms exhibit a \u201cwinner take all\u201d outcome due to scale and network effects, which makes it difficult to create competition artificially. There is little room for another search engine, another social media platform, another online retailer or another micro-blogging platform. If we accept the dominant nature of such monopolies, we might regulate them accordingly, in the same way we regulate water and electricity. A federal agency that regulates \u201cdigital utilities\u201d must be oriented to the digital future, which will include digital sensor networks to support driverless cars and other future innovations.\n\nIn 2017 I recommended that social media platforms be regulated to curb the misuse of Facebook that was fast becoming apparent. I proposed Know Your Customer (KYC) regulation, similar to its use in the financial arena, to ensure that the platforms know who is paying them. Verifying identity would go a long way to reducing fraud, such as enticing senior citizens to make precious metals investments using fake entities with names like \u201cFox News Insider Reports\u201d and \u201cUS Retirement Bureau.\u201d\n\nBut KYC does not address the unconstrained manner in which the internet giants are gathering, linking and selling public and private data to create products that can predict individual desires and behavior. Although it is not possible to prove conclusively that nefarious parties influenced the 2016 U.S. presidential election outcome , it would be a mistake to wait for irrefutable proof of harm to act. If machines can predict how to alter consumer behavior in a specific way, they are in charge, meaning their owners are in charge.\n\nIn a September 2014 op-ed piece in Britain\u2019s Independent newspaper, the famed theoretical physicist Stephen Hawking provided a stark warning on the future of Artificial Intelligence, noting, \u201cWhereas the short-term impact of AI depends on who controls it, the long-term impact depends on whether it can be controlled at all.\u201d He warned that dismissing hyper-intelligent machines \u201cas mere science fiction would be a mistake, and potentially our worst mistake ever.\u201d\n\nWe are at a crossroads, where humans risk losing complete control of their liberty to AI. We can protect our privacy and our democracy through judicious data protection policy, but we must not delay.\n\nVasant Dhar is a professor at New York University\u2019s Stern School of Business and the director of the PhD program at the Center for Data Science.", "description": "We are at a crossroads, where humans risk losing complete control of their liberty to AI. We can protect our privacy and our democracy through judicious data protection policy, but we must not delay.", "authors": [], "top_image": "https://thehill.com/sites/default/files/fallpolicy_technology_083018hillillustration.jpg", "published_at": "2019-10-03"}