{"pub": "thenextweb", "url": "https://thenextweb.com/artificial-intelligence/2019/10/09/uk-passport-program-uses-ai-to-create-a-virtual-speed-line-for-white-people", "downloaded_at": "2019-10-09 18:30:30.076520+00:00", "title": "UK passport program uses AI to create a virtual speed-line for white people", "language": "en", "text": "The lighter your skin, the better AI-powered facial recognition systems work for you. The UK Home Office knows this, because the government\u2018s been briefed several times on the problem. And a recent report shows that it knew it was developing a passport program built on biased, racist AI. It just doesn\u2019t care.\n\nThe UK\u2019s passport program went live in 2016. It uses an AI-powered facial recognition feature to determine whether user-uploaded photos meet the requirements and standards for use as a passport photo. The system rejects photos that miss the mark.\n\nIn the time since its launch, many black users have reported numerous issues using the system that white people don\u2019t appear to have, including the system\u2019s failure to recognize that their eyes are open or their mouths are closed.\n\nUsers can override the AI\u2018s rejection and submit their images anyway, but they\u2019re also warned that their application could be delayed or denied if there\u2019s a problem with the photo \u2013 white users can rely on the AI to make sure they don\u2019t suffer these issues, others have to hope for the best.\n\nThis is the very definition of privilege-based racism. It\u2019s a government-sponsored virtual priority lane for white people. And, according to a freedom of information act request by advocate organization medConfidential, Home Office was well aware of this before the system was ever deployed.\n\nPer a report from New Scientist writer Adam Vaughn, Home Office responded to the documents by stating it was aware of the problem, but felt it was acceptable to use the system anyway:\n\nUser research was carried out with a wide range of ethnic groups and did identify that people with very light or very dark skin found it difficult to provide an acceptable passport photograph. However; the overall performance was judged sufficient to deploy.\n\nAI is incredibly good at being racist because racism is systemic: small, difficult to see groupings of seemingly diverse data correlate to create any racist system. Given nearly any problem that can be solved for the benefit of white people or to a detriment excluding white people, AI\u2019s going to reflect the exact same bias intrinsic in the data it\u2019s fed.\n\nThis may not always be the case, but in 2019 it holds as true as basic arithmetic. Google hasn\u2019t figured it out yet, despite exploiting homeless black people in an attempt to build a database for study. Amazon hasn\u2019t figured it out, despite selling law enforcement agencies around the US its biased Rekognition software. And you can be certain that the UK\u2019s government hasn\u2019t figured it out yet either.\n\nWhat the UK\u2019s government has figured out, however, is how to exploit AI\u2019s inherent bias to ensure that white people receive special privileges. The UK\u2019s letting the entire world know what its priorities are.\n\nRead next: Facial recognition company CEO explains why government surveillance is bad for privacy", "description": "", "authors": ["Tristan Greene"], "top_image": "https://img-cdn.tnwcdn.com/image/tnw?filter_last=1&fit=1280%2C640&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2017%2F09%2Fangryrobot.jpg&signature=83aa73881a65d5bcab4d757de35e6b37", "published_at": "2019-10-09"}