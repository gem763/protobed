{"pub": "washingtontimes", "url": "https://washingtontimes.com/news/2019/sep/18/facebook-auto-generating-pages-for-islamic-state-a", "downloaded_at": "2019-09-18 07:25:28.450150+00:00", "title": "Facebook auto-generating pages for Islamic State, al-Qaida", "language": "en", "text": "WASHINGTON (AP) - In the face of criticism that Facebook is not doing enough to combat extremist messaging, the company likes to say that its automated systems remove the vast majority of prohibited content glorifying the Islamic State group and al-Qaida before it\u2019s reported.\n\nBut a whistleblower\u2019s complaint shows that Facebook itself has inadvertently provided the two extremist groups with a networking and recruitment tool by producing dozens of pages in their names.\n\nThe social networking company appears to have made little progress on the issue in the four months since The Associated Press detailed how pages that Facebook auto-generates for businesses are aiding Middle East extremists and white supremacists in the United States.\n\nOn Wednesday, U.S. senators on the Committee on Commerce, Science, and Transportation will be questioning representatives from social media companies, including Monika Bickert, who heads Facebooks efforts to stem extremist messaging.\n\nThe new details come from an update of a complaint to the Securities and Exchange Commission that the National Whistleblower Center plans to file this week. The filing obtained by the AP identifies almost 200 auto-generated pages - some for businesses, others for schools or other categories - that directly reference the Islamic State group and dozens more representing al-Qaida and other known groups. One page listed as a \u201cpolitical ideology\u201d is titled \u201cI love Islamic state.\u201d It features an IS logo inside the outlines of Facebook\u2019s famous thumbs-up icon.\n\nIn response to a request for comment, a Facebook spokesperson told the AP: \u201cOur priority is detecting and removing content posted by people that violates our policy against dangerous individuals and organizations to stay ahead of bad actors. Auto-generated pages are not like normal Facebook pages as people can\u2019t comment or post on them and we remove any that violate our policies. While we cannot catch every one, we remain vigilant in this effort.\u201d\n\nFacebook has a number of functions that auto-generate pages from content posted by users. The updated complaint scrutinizes one function that is meant to help business networking. It scrapes employment information from users\u2019 pages to create pages for businesses. In this case, it may be helping the extremist groups because it allows users to like the pages, potentially providing a list of sympathizers for recruiters.\n\nThe new filing also found that users\u2019 pages promoting extremist groups remain easy to find with simple searches using their names. They uncovered one page for \u201cMohammed Atta\u201d with an iconic photo of one of the al-Qaida adherents, who was a hijacker in the Sept. 11 attacks. The page lists the user\u2019s work as \u201cAl Qaidah\u201d and education as \u201cUniversity Master Bin Laden\u201d and \u201cSchool Terrorist Afghanistan.\u201d\n\nFacebook has been working to limit the spread of extremist material on its service, so far with mixed success. In March, it expanded its definition of prohibited content to include U.S. white nationalist and white separatist material as well as that from international extremist groups. It says it has banned 200 white supremacist organizations and 26 million pieces of content related to global extremist groups like IS and al-Qaida.\n\nIt also expanded its definition of terrorism to include not just acts of violence attended to achieve a political or ideological aim, but also attempts at violence, especially when aimed at civilians with the intent to coerce and intimidate. It\u2019s unclear, though, how well enforcement works if the company is still having trouble ridding its platform of well-known extremist organizations\u2019 supporters.\n\nBut as the report shows, plenty of material gets through the cracks - and gets auto-generated.\n\nThe AP story in May highlighted the auto-generation problem, but the new content identified in the report suggests that Facebook has not solved it.\n\nThe report also says that researchers found that many of the pages referenced in the AP report were removed more than six weeks later on June 25, the day before Bickert was questioned for another congressional hearing.\n\nThe issue was flagged in the initial SEC complaint filed by the center\u2019s executive director, John Kostyack, that alleges the social media company has exaggerated its success combatting extremist messaging.\n\n\u201cFacebook would like us to believe that its magical algorithms are somehow scrubbing its website of extremist content,\u201d Kostyack said. \u201cYet those very same algorithms are auto-generating pages with titles like \u2018I Love Islamic State,\u2019 which are ideal for terrorists to use for networking and recruiting.\u201d\n\n___\n\nOrtutay reported from San Francisco.\n\nSign up for Daily Newsletters\n\nCopyright \u00a9 2019 The Washington Times, LLC.", "description": "In the face of criticism that Facebook is not doing enough to combat extremist messaging, the company likes to say that its automated systems remove the vast majority of prohibited content glorifying the Islamic State group and al-Qaida before it's reported.", "authors": ["The Washington Times Http", "Desmond Butler", "Barbara Ortutay"], "top_image": "https://twt-thumbs.washtimes.com/media/image/2019/09/18/facebook_extremism_57504_c0-167-3997-2497_s1770x1032.jpg?ff773f4ed7189d56bfc453859a2ccc9fbfa53ada", "published_at": "2019-09-18"}