{"pub": "washingtonpost", "url": "https://washingtonpost.com/health/2019/10/24/racial-bias-medical-algorithm-favors-white-patients-over-sicker-black-patients", "downloaded_at": "2019-10-24 23:54:19.471600+00:00", "title": "Racial bias in a medical algorithm favors white patients over sicker black patients", "language": "en", "text": "Correcting the bias would more than double the number of black patients flagged as at risk of complicated medical needs within the health system the researchers studied, and they are already working with Optum on a fix. When the company replicated the analysis on a national data set of 3.7 million patients, they found that black patients who were ranked by the algorithm as equally as in need of extra care as white patients were much sicker: They collectively suffered from 48,772 additional chronic diseases.\n\nAD\n\nAD\n\n\u201cIt\u2019s truly inconceivable to me that anyone else\u2019s algorithm doesn\u2019t suffer from this,\u201d said Sendhil Mullainathan, a professor of computation and behavioral science at the University of Chicago Booth School of Business, who oversaw the work. \u201cI\u2019m hopeful that this causes the entire industry to say, \u2018Oh, my, we\u2019ve got to fix this.\u2019 \u201d\n\nThe algorithm wasn\u2019t intentionally racist \u2014 in fact, it specifically excluded race. Instead, to identify patients who would benefit from more medical support, the algorithm used a seemingly race-blind metric: how much patients would cost the health-care system in the future. But cost isn\u2019t a race-neutral measure of health-care need. Black patients incurred about $1,800 less in medical costs per year than white patients with the same number of chronic conditions; thus the algorithm scored white patients as equally at risk of future health problems as black patients who had many more diseases.\n\nMachines increasingly make decisions that affect human life, and big organizations \u2014 particularly in health care \u2014 are trying to leverage massive data sets to improve how they operate. They utilize data that may not appear to be racist or biased but may have been heavily influenced by longstanding social, cultural and institutional biases \u2014 such as health-care costs. As computer systems determine which job candidates should be interviewed, who should receive a loan or how to triage sick people, the proprietary algorithms that power them run the risk of automating racism or other human biases.\n\nAD\n\nAD\n\nIn medicine, there is a long history of black patients facing barriers to accessing care and receiving less effective health care. Studies have found black patients are less likely to receive pain treatment, potentially lifesaving lung cancer surgery or cholesterol-lowering drugs, compared with white patients. Such disparities probably have complicated roots, including explicit racism, access problems, lack of insurance, mistrust of the medical system, cultural misunderstandings or unconscious biases that doctors may not even know they have.\n\nMullainathan and his collaborators discovered that the algorithm they studied, which was designed to help health systems target patients who would have the greatest future health-care needs, was predicting how likely people were to use a lot of health care and rack up high costs in the future. Since black patients generally use health care at lower rates, the algorithm was less likely to flag them as likely to use lots of health care in the future.\n\nThe algorithm would then deepen that disparity by flagging healthier white patients as in need of more intensive care management.\n\nAD\n\nAD\n\n\u201cPredictive algorithms that power these tools should be continually reviewed and refined, and supplemented by information such as socio-economic data, to help clinicians make the best-informed care decisions for each patient,\u201d Optum spokesman Tyler Mason said. \u201cAs we advise our customers, these tools should never be viewed as a substitute for a doctor\u2019s expertise and knowledge of their patients\u2019 individual needs.\u201d\n\nRuha Benjamin, an associate professor of African American studies at Princeton University, drew a parallel to the way Henrietta Lacks, a young African American mother with cervical cancer, was treated by the medical system. Lacks is well known now because her cancer cells, taken without her consent, are used throughout modern biomedical research. She was treated in the Negro wing of Johns Hopkins Hospital in an era when hospitals were segregated. Imagine if today, Benjamin wrote in an accompanying article, Lacks were \u201cdigitally triaged\u201d with an algorithm that didn\u2019t explicitly take into account her race but underestimated her sickness because it was using data that reflected historical bias to project her future needs. Such racism, though not driven by a hateful ideology, could have the same result as earlier segregation and substandard care.\n\n\u201cI am struck by how many people still think that racism always has to be intentional and fueled by malice. They don\u2019t want to admit the racist effects of technology unless they can pinpoint the bigoted boogeyman behind the screen,\u201d Benjamin said.\n\nAD\n\nAD\n\nThe software used to predict patients\u2019 need for more intensive medical support was an outgrowth of the Affordable Care Act, which created financial incentives for health systems to keep people well instead of waiting to treat them when they got sick. The idea was that it would be possible to simultaneously contain costs and keep people healthier by identifying those patients at greatest risk for becoming very sick and providing more resources to them. But because wealthy, white people tend to utilize more health care, such tools could also lead health systems to focus on them, missing an opportunity to help some of the sickest people.\n\nChristine Vogeli, director of evaluation and research at the Center for Population Health at Partners HealthCare, a nonprofit health system in Massachusetts, said when her team first tested the algorithm, they mapped the highest scores in their patient population and found them concentrated in some of the most affluent suburbs of Boston. That led them to use the tool in a limited way, supplementing it with other information, rather than using it off the shelf.\n\n\u201cYou\u2019re going to have to make sure people are savvy about it \u2026 or you\u2019re going to have an issue where you\u2019re only serving the richest and most wealthy folks,\u201d Vogeli said.\n\nAD\n\nAD\n\nSuch biases may seem obvious in hindsight, but algorithms are notoriously opaque because they are proprietary products that can cost hundreds of thousands of dollars. The researchers who conducted the new study had an unusual amount of access to the data that went into the algorithm and what it predicted.\n\nThey also found a relatively straightforward way to fix the problem. Instead of just predicting which patients would incur the highest costs and use the most health care in the future, they tweaked the algorithm to make predictions about their future health conditions.\n\nSuchi Saria, a machine learning and health-care expert at Johns Hopkins University, said the study was fascinating because it showed how, once a bias is detected, it can be corrected. Much of the scientific study of racial disparities in medicine provides evidence of inequity, but correcting those problems might require sweeping social and cultural changes, as well as individual behavior changes by thousands of providers. In contrast, once a flawed algorithm is identified, the bias can be removed.\n\nAD\n\nAD\n\n\u201cThe cool thing is we could easily measure the bias that has historically existed, switch out the algorithm and correct the bias,\u201d Saria said. The trickier part may be developing an oversight mechanism that will detect the biases in the first place.\n\nSaria said that one possibility is that data experts could potentially test companies\u2019 algorithms for bias, the same way security firms test whether a companies\u2019 cyber defenses are sufficient.\n\nRead More:\n\nAD", "description": "A widely used algorithm that flags patients for extra medical care is biased against black patients, a study found.", "authors": ["Carolyn Y. Johnson", "Science Reporter"], "top_image": "https://www.washingtonpost.com/resizer/J6g9nUFdN_nP-7Ro9eMMoHcz4fk=/1440x0/smart/arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/55D5DCXWOYI6TMWSD434TWBNXM.jpg", "published_at": "2019-10-24"}