{"pub": "theverge", "url": "https://theverge.com/2019/9/26/20885512/amazon-alexa-voice-assistant-privacy-features-trust", "downloaded_at": "2019-10-05 14:18:14.589017+00:00", "title": "To use Alexa, you have to trust Amazon", "language": "en", "text": "At Wednesday\u2019s hardware event, Amazon wanted to make sure you knew it valued your privacy. \u201cWe\u2019re investing in privacy across the board,\u201d hardware and services chief Dave Limp told the crowd. \u201cPrivacy cannot be an afterthought when it comes to the devices and services we offer our customers. It has to be foundational and built in from the beginning for every piece of hardware, software, and service that we create.\u201d\n\nTo prove the point, the company rolled out a new set of privacy features, each one giving users slightly more control. A new camera shutter will electronically disconnect the camera on the Echo Show 5. A separate feature lets you set \u201cprivacy zones,\u201d in which a particular part of the camera\u2019s view will be impossible to record or view live. Another setting, due in November, stops the Ring camera from recording while you\u2019re at home. A host of new Alexa skills will let you monitor recordings directly, and even set rolling deletion. It\u2019s a serious run of features, meant to convince you that Amazon is thinking hard about the privacy implications of its smart speakers and cameras.\n\n\u201cPrivacy cannot be an afterthought\u201d\n\nBut not everyone was convinced. At the same event, Amazon also gave us a flood of new ways to install networked microphones in nearly everything we own: our glasses, our alarm clocks, even our jewelry. It was an all-out push for more Alexa in more places \u2014 a troubling thought, if you\u2019re concerned about the invasive nature of always-on microphones.\n\nAfter months of mounting concerns over police partnerships with Amazon\u2019s Ring subsidiary, privacy advocates weren\u2019t shy about pointing out the contradiction. \u201cThis is what Amazon does,\u201d said Evan Greer, a deputy director at Fight for the Future. \u201cThey make empty statements to sell their products and then continue to build a for-profit, surveillance dragnet without oversight and accountability.\u201d\n\nOn the surface, it might just seem like bad timing. Amazon has been working on these products for a long time \u2014 and as it happens, the launch comes after months of escalating privacy scandals around the very idea of a voice-based personal assistant. Every single major provider has been forced to reckon with its use of contractors \u2014 actual human beings who listen to your voice assistant messages for verification purposes \u2014 and none have had good answers to the privacy concerns.\n\nApple has even been forced to change its entire data retention model, shifting to a default opt-out for Siri recordings \u2014 something Amazon chooses not to offer. Clearly, this was not the best time to launch a massive expansion of your voice assistant program.\n\nThe underlying transaction is the same as a Facebook login: data for convenience\n\nBut the problem goes much deeper than bad timing. Voice assistants (particularly hardware-agnostic ones like Alexa) offer customers a basic deal: accept the privacy cost of putting a microphone in your home, and you can have this array of voice-activated skills, all powered by a near-invisible network of cloud servers. This deal is familiar to anyone who\u2019s spent any time with Facebook or Google products. Alexa isn\u2019t something you buy with money. It\u2019s almost always bundled, for free, with products that have other more benign purposes, like speakers and screens. That may make the trade-offs more subtle than with a Facebook login or Gmail account, but the underlying transaction is the same: data for convenience.\n\nLike any good salesperson, Amazon has focused more on the benefits than the cost, which means the recent revelations have come as a surprise. On a technical level, it\u2019s not surprising that a voice assistant could not be fully automated, and that human beings might need to listen in to improve the system. But Amazon and other companies were never clear about that part of the bargain, so customers simply didn\u2019t know.\n\nMuch of yesterday\u2019s privacy push seems to be about convincing users Amazon is aware of these new concerns, and is responding to them. If you\u2019re freaked out by the idea that Alexa might mishear a wake word and start recording, they\u2019ll give you a command that lets you check for that. If you\u2019re worried about a growing catalog of voice recordings sitting on an Amazon server somewhere, they\u2019ll give you a way to delete them. In the move-fast-and-break-things school of tech ethics, this is how progress happens. You release a product, objections arise, and you fix the objections. It\u2019s a little messy, but as long as you address customer concerns, you should end in a good place \u2014 or so the thinking goes.\n\nBut privacy is more than just a set of features. Accepting Alexa into your home (or into your glasses) means believing that Amazon isn\u2019t somehow taking advantage of the data you\u2019re giving it. In short, you have to trust them. Every time Alexa expands into some new domain, more trust is required \u2014 and every time the service screws up, that trust gets harder to maintain. Seen from that perspective, the new privacy measures could be too little, too late.", "description": "Amazon talked a lot about privacy at its hardware event on September 25th \u2014 but will it be enough to sell consumers on the new Alexa devices?", "authors": ["Russell Brandom", "Sep"], "top_image": "https://cdn.vox-cdn.com/thumbor/loSNxgVV0WKyTFUnd0WWqDEQWz8=/0x146:2040x1214/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/10817631/acastro_180510_1777_alexa_0001.jpg", "published_at": "2019-09-26"}