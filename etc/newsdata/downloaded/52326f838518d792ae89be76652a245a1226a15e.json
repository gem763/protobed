{"pub": "axios", "url": "https://axios.com/the-impending-war-over-deepfakes-b3427757-2ed7-4fbc-9edb-45e461eb87ba.html", "downloaded_at": "2019-10-19 17:03:29.075358+00:00", "title": "The impending war over deepfakes", "language": "en", "text": "The big picture: Publicly available software makes it easy to create sophisticated fake videos without having to understand the machine learning that powers it. Most software swaps one person\u2019s face onto another\u2019s body, or makes it look like someone is saying something they didn\u2019t.\n\nThis has ignited an arms race between fakers and sleuths.\n\nIn one corner are academics developing face-swap tech that could be used for special-effects departments, plus myriad online pranksters and troublemakers. Doctored photos are a stock-in-trade of the internet, but as far as experts know, AI has not yet been used by state actors or political campaigns to produce deepfakes.\n\ndeveloping face-swap tech that could be used for special-effects departments, plus myriad online pranksters and troublemakers. Doctored photos are a stock-in-trade of the internet, but as far as experts know, AI has not yet been used by state actors or political campaigns to produce deepfakes. Arrayed against them are other academic researchers, plus private companies and government entities like DARPA and Los Alamos National Labs, all of whom have marshaled resources to try and head off deepfakes.\n\nFacing an uphill fight, the deepfake detectives have approached the problem from numerous angles.\n\nGfycat, a gif-hosting platform, banned deepfake porn and uses a pair of tools to take down offending clips. One compares the faces in each frame of a gif to detect anomalies that could give away a fake; the other checks whether a new gif has simply pasted a new face onto a previously uploaded clip.\n\na gif-hosting platform, banned deepfake porn and uses a pair of tools to take down offending clips. One compares the faces in each frame of a gif to detect anomalies that could give away a fake; the other checks whether a new gif has simply pasted a new face onto a previously uploaded clip. Researchers at SUNY Albany created a system that monitors video blinking patterns to determine whether it's genuine.\n\ncreated a system that monitors video blinking patterns to determine whether it's genuine. Hany Farid, a Dartmouth professor and member of DARPA's media forensics team, favors a physics-based approach that analyzes images for giveaway inconsistencies like incorrect lighting on an AI-generated face. He says non-AI, forensics-based reasoning is easier to explain to humans \u2014 like to, say, a jury.\n\nand member of DARPA's media forensics team, favors a physics-based approach that analyzes images for giveaway inconsistencies like incorrect lighting on an AI-generated face. He says non-AI, forensics-based reasoning is easier to explain to humans \u2014 like to, say, a jury. Los Alamos researchers are creating a neurologically inspired system that searches for invisible tells that photos are AI-generated. They are testing for compressibility, or how much information the image actually contains. Generated images are simpler than real photos, because they reuse visual elements. The repetition is subtle enough to trick the eye, but not a specially trained algorithm.\n\nAI might never catch 100% of fakes, said Juston Moore, a data scientist at Los Alamos. \"But even if it\u2019s a cat-and-mouse game,\" he said, \"I think it\u2019s one worth playing.\"\n\nWhat\u2019s next: We\u2019re years away from a comprehensive system to battle deepfakes, said Farid. It would require new technological advances as well as answers to thorny policy questions that have already proven extremely difficult to solve.\n\nAssuming the technology is worked out, here is how it could be implemented:\n\nAn independent website that verifies uploaded photos and videos. Verified content could be displayed in a gallery for reference.\n\nthat verifies uploaded photos and videos. Verified content could be displayed in a gallery for reference. A platform-wide verification system on social-media sites like Twitter, Facebook, and Reddit that checks every user-uploaded item before allowing it to post. A displayed badge could verify content.\n\non social-media sites like Twitter, Facebook, and Reddit that checks every user-uploaded item before allowing it to post. A displayed badge could verify content. A tracking system for the origin of a video, image, or audio clip. Blockchain could play a role, and a company called Truepic has raised money to use it for this purpose.\n\nof a video, image, or audio clip. Blockchain could play a role, and a company called Truepic has raised money to use it for this purpose. Watermarks could be placed on images verified as real or deepfakes. Farid said that one possibility is to add an invisible signature to images created with Google\u2019s TensorFlow technology, which powers the most popular currently available deepfake generator.\n\nThe big question: Will tech companies implement such protections if they might be seen as infringing on free speech, a similar conundrum faced by social networking companies policing extremist content?\n\nGo deeper:", "description": "A fake video of a world leader making an incendiary threat could set off a trade war.", "authors": [], "top_image": "https://images.axios.com/kdlJx2GrHSgCWpr2ynRhQBsqPXs=/0x0:1920x1080/1920x1080/2018/07/22/1532276124843.jpg", "published_at": "2018-07-22"}