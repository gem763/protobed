{"pub": "techcrunch", "url": "https://techcrunch.com/2019/10/06/an-interview-with-dr-stuart-russell-author-of-human-compatible-artificial-intelligence-and-the-problem-of-control", "downloaded_at": "2019-10-07 00:07:22.496347+00:00", "title": "An interview with Dr. Stuart Russell, author of \u201cHuman Compatible, Artificial Intelligence and the Problem of Control\u201d \u2013 TechCrunch", "language": "en", "text": "(UC Berkeley\u2019s Dr. Stuart Russell\u2019s new book, \u201cHuman Compatible: Artificial Intelligence and the Problem of Control, goes on sale Oct. 8. I\u2019ve written a review, \u201cHuman Compatible\u201d is a provocative prescription to re-think AI before it\u2019s too late,\u201d and the following in an interview I conducted with Dr. Russell in his UC Berkeley office on September 3, 2019.)\n\nNed Desmond: Why did you write Human Compatible?\n\nDr. Russell: I\u2019ve been thinking about this problem \u2013 what if we succeed with AI? \u2013 on and off since the early 90s. The more I thought about it, the more I saw that the path we were on doesn\u2019t end well.\n\n(AI Researchers) had mostly just doing toy stuff in the lab, or games, none of which represented any threat to anyone. It\u2019s a little like a physicist playing tiny bits of uranium. Nothing happens, right? So we\u2019ll just make more of it, and everything will be fine. But it just doesn\u2019t work that way. When you start crossing over to systems that are more intelligent, operating on a global scale, and having real-world impact, like trading algorithms, for example, or social media content selection, then all of a sudden, you are having a big impact on real-world, and it\u2019s hard to control. It\u2019s hard to undo. And that\u2019s just going to get worse and worse and worse.\n\nDesmond: Who should read Human Compatible?\n\nDr. Russell: I think everyone, because everyone is going to be affected by this. As progress occurs towards human level (AI), each big step is going to magnify the impact by another factor of 10, or another factor of 100. Everyone\u2019s life is going to be radically affected by this. People need to understand it. More specifically, it would be policymakers, the people who run the large companies like Google and Amazon, and people in AI, related disciplines, like control theory, cognitive science and so on.\n\nMy basic view was so much of this debate is going on without any understanding of what AI is. It\u2019s just this magic potion that will make things intelligent. And in these debates, people don\u2019t understand the building blocks, how it fits together, how it works, how you make an intelligent system. So chapter two (of Human Compatible was) sort of mammoth and some people said, \u201cOh, this is too much to get through and others said, \u201cNo, you absolutely have to keep it.\u201d So I compromised and put the pedagogical stuff in the appendices.\n\nDesmond: Why did computer scientists tend to overlook the issue of uncertainty in the objective function for AI systems?\n\nDr. Russell: Funnily enough, in AI, we took uncertainty (in the decision-making function) to heart starting in the 80s. Before that, most AI people said let\u2019s just work on cases where we have definite knowledge, and we can come up with guaranteed plans.", "description": "(UC Berkeley\u2019s Dr. Stuart Russell\u2019s new book, \u201cHuman Compatible: Artificial Intelligence and the Problem of Control, goes on sale Oct. 8. I\u2019ve written a review, \u201cHuman Compatible\u201d is a provocative prescription to re-think AI before it\u2019s too late,\u201d and the following in an interview I conducted with Dr. Russell in his UC Berkeley office on [\u2026]", "authors": [], "top_image": "https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-675412424-1-e1561576161717.jpg?w=473", "published_at": "2019-10-06"}