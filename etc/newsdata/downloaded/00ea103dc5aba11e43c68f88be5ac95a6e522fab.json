{"pub": "nytimes", "url": "https://nytimes.com/2019/10/15/technology/personaltech/google-pixel-photography.html", "downloaded_at": "2019-10-15 16:22:23.672112+00:00", "title": "When You Take a Great Photo, Thank the Algorithm in Your Phone", "language": "en", "text": "Not too long ago, tech giants like Apple and Samsung raved about the number of megapixels they were cramming into smartphone cameras to make photos look clearer. Nowadays, all the handset makers are shifting focus to the algorithms, artificial intelligence and special sensors that are working together to make our photos look more impressive.\n\nWhat that means: Our phones are working hard to make photos look good, with minimal effort required from the user.\n\nOn Tuesday, Google showed its latest attempt to make cameras smarter. It unveiled the Pixel 4 and Pixel 4 XL, new versions of its popular smartphone, which comes in two screen sizes. While the devices include new hardware features \u2014 like an extra camera lens and an infrared face scanner to unlock the phone \u2014 Google emphasized the phones\u2019 use of so-called computational photography, which automatically processes images to look more professional.\n\nAmong the Pixel 4\u2019s new features is a mode for shooting the night sky and capturing images of stars. And by adding the extra lens, Google augmented a software feature called Super Res Zoom, which allows users to zoom in more closely on images without losing much detail.", "description": "Google\u2019s Pixel 4 is the newest example of how computational photography is driving the future of cameras.", "authors": ["Brian X. Chen"], "top_image": "https://static01.nyt.com/images/2019/10/15/business/15Techfix-print/15Techfix-print-facebookJumbo.jpg", "published_at": "2019-10-15"}