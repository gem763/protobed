{"pub": "businessinsider", "url": "https://businessinsider.com/california-deepfake-laws-politics-porn-free-speech-privacy-experts-2019-10", "downloaded_at": "2019-10-10 18:35:40.677370+00:00", "title": "California's governor signed new deepfake laws for politics and porn, but experts say they threaten free speech", "language": "en", "text": "California has two new laws regulating deepfakes \u2014 videos or images manipulated with artificial intelligence to make it appear as if someone has said or done something that they haven't.\n\nThe first law makes it illegal to post deepfakes of political candidates in the 60 days ahead of an election. It was introduced after a Nancy Pelosi deepfake went viral.\n\nThe second law allows state residents to sue anyone who uses a deepfake to place them in pornographic material without consent. A recent study found that more than 90% of deepfakes are pornographic and target women.\n\nBut civil liberties and misinformation experts have criticized both laws, saying that they are misguided, vague, subjective, and threaten free speech.\n\nLast week, California Gov. Gavin Newsom signed two deepfake bills into state law.\n\nThe first is political, making it illegal to post manipulated videos and pictures that give a \"false impression of a political candidate's actions or words\" in the 60 days before an election.\n\nThe bill was introduced by Democratic Assemblyman Marc Berman after a deepfake of Nancy Pelosi went viral, in which her speech was altered in a video to make it sound like she was slurring her words.\n\n\"In the context of elections, the ability to attribute speech or conduct to a candidate that is false \u2014 that never happened \u2014 makes deepfake technology a powerful and dangerous new tool in the arsenal of those who want to wage misinformation campaigns to confuse voters,\" Berman said in a statement.\n\nThe law will take effect next year and it includes exemptions for news outlets, satire and parody, and manipulated videos that have clear disclaimers.\n\nBut most deepfakes aren't political. Deeptrace, a cybersecurity company, released a study of almost 15,000 deepfakes, and found that more than 90% were pornographic. All of these deepfakes targeted women, a horrifying and prevalent new form of online harassment and revenge porn.\n\nAccordingly, the second California deepfake law allows residents to sue anyone who uses deepfake technology to place them in pornographic material without consent. Both of these measures seem positive \u2014 but they may not have their intended effect, according to experts.\n\nExperts say California's deepfake legislation is misguided, and threatens free speech\n\nClaire Wardle is the executive director of First Draft, a nonprofit focused on addressing the online tactics that fuel misinformation and disinformation. As Wardle has seen deepfake worries increase, she isn't sure that our attention is in the right place.\n\n\"I have real concerns about new legislation that focuses on the technology or techniques used to create the manipulated content,\" Wardle told Business Insider. \"It's the impact \u2014 especially the harm that it has \u2014 that we should be focused on.\"\n\nThere are already laws that regulate the impact of pornographic deepfakes, including specific measures for revenge porn and digital harassment. Wardle argues that we should be using those existing laws to remedy the harm caused by deepfakes.\n\nDavid Greene, the Electronic Frontier Foundation's civil liberties director, is similarly skeptical of deepfake legislation.\n\nGreene added extortion, false light, and defamation to the list of laws that could already police deepfakes, depending on the creator's intent. Further, Greene says California's political deepfake law does not strike an appropriate balance between preventing harm and protecting free speech.\n\n\"The law is overbroad, vague, and subjective,\" Greene told Business Insider. \"It hinges on whether the deepfake leads to a fundamentally different impression of the candidate, which is not specific enough, and could suppress speech.\"\n\nBoth the EFF and the ACLU wrote letters to Gov. Newsom, warning that the political deepfake law would not solve the problem and may only lead to more confusion.\n\nWardle and Greene also expressed concern over how the exceptions for satire and parody would be determined.\n\nThe governor's office did not immediately respond to a request for comment regarding opposition to the law. Assemblyman Berman's office also did not respond to a request for similar comment.\n\n\"As people have become increasingly concerned about the impact of disinformation, we've learned the challenges of legislating around content,\" Wardle told Business Insider. \"It can have really worrying consequences on free speech.\"\n\nInstead, Wardle and Greene agree that we need to place more emphasis on understanding the intent behind creating deepfakes.\n\n\"There has been a consensus that we should focus on the sources,\" Wardle said. \"Who is creating the content? What are they aiming to achieve? Is it a coordinated campaign to manipulate? That's how we should think about these questions.\"", "description": "California has approved deepfake laws for politics and porn, but experts say the laws are misguided and threaten free speech. Here's why.", "authors": ["Will Fischer"], "top_image": "https://image.businessinsider.com/5d9e26a8122bd56e80695a76?width=1200&format=jpeg", "published_at": "2019-10-10"}