{"pub": "dailymail", "url": "https://popularmechanics.com/technology/gadgets/a20597/can-we-talk", "downloaded_at": "2019-10-05 07:20:05.332246+00:00", "title": "Can We Talk? The Deepening Conversation Between Humans and Computers", "language": "en", "text": "Getty Images\n\nNot long after Radiohead's 1997 masterpiece Ok Computer came out, I sat in the small upstairs office of my house and sang aloud to the album's least tuneful song, \"Fitter Happier,\" a track in which the lead vocalist is a monotone computer voice that reads aloud ways to become healthier and more productive. By \"sang along,\" I mean I made my computer sing along: I typed out the words and hit play at the exact right moment so the computerized voices (both Apple's Fred) fell in line with each other.\n\nI loved making machines talk. Some years before that, I typed words into a 90s program called Kid Works, which you could use to have a man's voice read aloud short bits of text. \"Rachel's dog 10\" I typed, a reference to a drawing I just did with a mouse. \"Rah-chel-S- dog-ten\" the computer read back to me, the deep, scratchy man's voice sounding tinny from the Macintosh IIsi built-in speaker.\n\nWhen I first learned to make a computer talk, I had to tell it exactly what to say. The only surprises came from the machine's curious mispronunciations. Nowadays I make my gadgets converse with me by rousing them with my voice and waiting to hear what they come up with in response. The difference is so stark I have to remind myself I'm chatting with a machine. When my phone's virtual assistant gets something wrong, I have to correct myself: She didn't get it wrong\u2014it got it wrong. (I actually have my Siri set to use a man's voice, so there's a double layer of wrong happening here.)\n\nThis distinction should be easy. Yet when things talk to us and when we talk to them, we have human expectations for them. The more natural our conversations are, the thinking goes, the more we'll talk. And the more we talk, the more our artificial assistants will be able to learn from us, become like us, and make conversation with us more naturally. Jim Glass, head of MIT's Spoken Language Systems Group, puts it this way: \"If you make the interaction more like human-human interaction, humans might not have to think as hard about how to express themselves, because the computer would be behaving in ways a human would.\"\n\nThat's the goal, at least, and that's why Apple, Amazon, Google, and others are pushing us to use our voices rather than our fingers to interact with their products. Talking is easier and faster than typing. Voice assistants like Siri have been on the market for years and are getting better all the time. So why do they still feel so weird to use? Why does it feel so uncanny to talk to an inanimate object and to expect it to talk back in your own language?\n\nI've long been resistant to using Siri. Very simply, I'm embarrassed. Talking to an object is embarrassing in a way that, say, talking to a stranger's dog on the street is not. Maybe it's the mundanity of what I'm saying, asking Siri boring questions about what the weather is like today. Or maybe it's that the mundanity touches something deeply personal\u2014the dictation of a text message saying \"I'm on my way,\" or the question to Google about what I should eat tonight. Talking to a voice assistant feels a bit like speaking a foreign language to a native speaker. \"For some people,\" Glass says, \"having the machine try to be like a human can be weird.\" Indeed.\n\nEventually, I gave in. It happened when I moved to a place where I drove after years of riding the subway. I'd often wonder what song was on the radio, and Siri could tell me. Or I'd think of something I needed to get at the grocery store, and I'd have Siri add it to my list. But it was when I started wearing an Apple Watch that I really gave in. It's just so convenient to raise my wrist to my mouth and tell Siri to remind me at 4 to call the cobbler.\n\nThere are now devices out there that let you control your whole smart home without lifting a finger. Tell your house to become 72 degrees, and it will. That's a nice hands-free trick, but that's what it is: a shortcut, not a conversation. Something else is now happening. Tell the speaker to play more music that sounds like the National, and it will. Not only will it do that, but it'll learn what you mean by \"play more music that sounds like the National\"\u2014that you mean this band but not that band. It'll recognize you as you. How is this even possible?\n\nThe way gadgets were meant to be controlled Getty Images\n\nNow that Siri and its ilk have been around for a few years, it's become easy to forget just how much it takes to make even this level of voice control happen. There are three huge steps working here.\n\nFirst, the device has to be able to hear you. It needs a decent microphone, one that can pick up your voice amidst a collection of other sounds. Next, it needs to be able to understand you\u2014that is, it needs an algorithm that can identify the sound coming from you as speech and translate that speech into text. Often, this step involves recognizing keywords, like \"what\" and \"weather\" and \"San Francisco.\" Good voice assistants can understand unconventional pronunciations; after you've said a word enough times, a voice assistant will understand you always say it that way. It doesn't matter if the pronunciation isn't standard, only that the pronunciation is consistent. Last comes the step that separates a computer assistant from a mere computer voice. It needs to understand what what you're asking for, and it must be able to beam and receive data from the cloud to give you the response you're asking for.\n\nThe Amazon Echo\n\nAll mainstream voice assistants are decent at these three tasks, but each has its strengths. Siri and Google Now both learn a user's voice and understand what the user wants fairly well. But they can have a hard time picking up a voice amidst the daily cacophony. It's no surprise that Amazon's Echo\u2014it's a speaker, after all\u2014picks up the slack there. But the Echo is limited by the apps it is connected to (it won't work with iCloud, for example) and by its size\u2014you won't take this thing to the bar and ask it about basketball scores. And even if you could, it might not be able to answer, as it seems to be designed for more home-related tasks, like ordering pizzas. Hound, SoundHound's voice-controlled search engine, actually does speech recognition and natural-language processing at the same time, in a process it calls \"speech-to-meaning.\" The app is currently the best at understanding complex requests, like \"Find me a coffee shop with Wi-Fi that serves beer within a mile of my house.\"\n\n\"If you make the interaction more like human-human interaction, humans might not have to think as hard about how to express themselves.\"\n\nWhichever voice assistant you use, you probably had to talk to it for awhile before it began understanding your requests on the first try. Some of us have gotten used to the idea of talking to our gadgets. But many of us still haven't gotten used to how we have to talk to our gadgets.\n\nWhether or not we think about it in such cold and rational terms, human language is a means of information retrieval. A conversation can be angry, witty, romantic, or tense, but talking to another human being is fundamentally about exchanging information. It's a collection of inputs and outputs, if you think about it as you would with a machine.\n\nYet the human voice may be the least intuitive input device for interaction with machines simply because it's the most intuitive input device for interacting with each other. We already know talking so well that it's a primarily unconscious endeavor. I've spent my whole life figuring out how to communicate with other people by talking, and most of my life figuring out how to communicate with machines using my hands. Now I'm supposed to sit back and command a speaker or phone to do my bidding, expecting a machine to deliver a mechanized (and, I hope, accurate) response behind the veneer of a human voice.\n\nAnd when I command that phone, I have to use the right phrases. I'm simultaneously supposed to talk to the device naturally\u2014since I'm using my voice\u2014and unnaturally, since I know its ability to understand me (and the realm of answers it can provide) remains limited. Countless memes and videos are dedicated to Siri easter eggs, the quirky canned responses Apple has programmed it to give when you ask the assistant a question it cannot answer.\n\nThings are getting better\u2014meaning voice assistants are getting a lot more human-sounding. \"The convenient thing to do is to mimic the human model so you're bringing along what you already know about communication,\" says Nuance CTO Vlad Sejnoha. But today, \"it's like interacting with five-year olds.\" That's partly due to the very means of communication\u2014language, which is wonderful, but ambiguous. So it can be hard both for voice assistants to understand what we're saying and for us to understand what they're saying back\u2014or at least why they're saying it. Why, for instance, does Siri default to a Bing search when I ask it \"What year was Iowa City founded?\"\n\nPart of the problem is a lack of \"introspection,\" Sejnoha says. AIs need to know what they don't know, and they need to be able to explain it. When they can do that, Siri still may default to a web search, but it'll at least tell you why it's doing that, just as a person might tell you why she doesn't understand your request.\n\nTalking to a voice assistant feels a bit like speaking a foreign language to a native speaker\n\nThe real question of the moment is whether Siri should be more human. On a practical level, sure. It'd be helpful if Apple's voice assistant were better at understanding what you were asking. For Silicon Valley prophets who foresee seamless interaction between human and gadget, that's probably a no-brainer. Yet we might grow too uncomfortable as our devices fall deeper and deeper into the uncanny valley (and my problem of referring to software as \"she\" is likely to get worse).\n\nFor another thing, teaching a machine to learn and \"think\" as a human does may hold it back. The magic of voice assistants is that they talk to us as if they were human, yet they have instant access to a vast reservoir of knowledge beyond the hope of a mere mortal. I can't tell you when the next train is coming, nor can I seem to remember how many tablespoons are in a quarter cup, but Siri can.\n\nThe ideal may be a voice assistant that understands us as a human would while responding as both a machine and human would. A machine we can talk to in a natural voice, without having to rephrase our thoughts in a way a computer would understand, but that has access to vast quantities of information and runs many tasks simultaneously. Something that is human, but not too human.\n\n\"In the future, we will have complex conversations with the things around us,\" says Keyvan Mohajer, founder and CEO of SoundHound. \"The more these things become humanlike, the more people will adopt them\u2014and will feel comfortable about adopting them.\" Maybe so, but don't expect things to be perfect along the way. \"If they sound like humans, it increases the expectations for what they can do. People might start asking subjective questions, like, 'My girlfriend broke up with me, and I'm sad\u2014what should I do?'\" Mohajer says. \"But in the long term, machines will be able to handle all those questions.\"\n\nUntil then, we'll have to make do with over-enunciating and dead ends. We'll have to make do with using the most human of inputs\u2014the voice\u2014and getting something not quite human in response.", "description": "Apple, Amazon, Google, and others are pushing us to use our voices rather than our fingers to interact with their products. But do we really want our assistants to be more human?", "authors": ["Rachel Z. Arndt"], "top_image": "https://hips.hearstapps.com/pop.h-cdn.co/assets/16/17/640x320/landscape-1461865191-gettyimages-141241255.jpg?resize=1200:*", "published_at": "2016-05-02"}