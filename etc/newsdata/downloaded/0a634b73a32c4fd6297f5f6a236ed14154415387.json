{"pub": "thenextweb", "url": "https://thenextweb.com/syndication/2019/10/06/heres-how-science-fiction-could-save-us-from-bad-technology", "downloaded_at": "2019-10-07 00:07:04.889426+00:00", "title": "Here\u2019s how science fiction could save us from bad technology", "language": "en", "text": "The short film \u201cSlaughterbots\u201d depicts a near future in which swarms of micro drones assassinate thousands of people for their political beliefs. Released in November 2017 by academics and activists warning of the dangers of advanced artificial intelligence (AI), it quickly went viral, attracting over 3 million views to date. It helped spark a public debate on the future of autonomous weapons and put pressure on diplomats meeting at the United Nations Convention on Conventional Weapons.\n\nBut this kind of speculative science fiction storytelling isn\u2019t just useful for attracting attention. The people who design and build advanced technology can use stories to consider the consequences of their work and ensure it is used for good. And we think this kind of \u201cscience fiction prototyping\u201d or \u201cdesign fiction\u201d could help prevent human biases from working their way into new technology, further entrenching society\u2019s prejudices and injustices.\n\nA bias can lead to the arbitrary preference of some categories (of results, people, or ideas) over others. For example, some people may be biased against hiring women for executive jobs, whether they are conscious of it or not.\n\nTechnology built around data that records such bias can end up replicating the problem. For instance, recruitment software designed to select the best CVs for a particular job might be programmed to look for characteristics that reflect an unconscious bias towards men. In which case, the algorithm will end up favoring men\u2019s CVs. And this isn\u2019t theoretical \u2013 it actually happened to Amazon.\n\nDesigning algorithms without considering possible negative implications has been compared to doctors \u201cwriting about the benefits of a given treatment and completely ignoring the side effects, no matter how serious they are\u201d.\n\nSome tech firms and researchers are trying to tackle the issue. For example, Google drew up a set of ethical principles to guide its development of AI. And UK academics have launched an initiative called Not-Equal that aims to encourage greater fairness and justice in the design and use of technology.\n\nThe problem is that, publicly, companies tend to deliver only a positive vision of the potential consequences of near-future technologies. For example, driverless cars are often portrayed as solving all our transport issues from cost to safety, ignoring the increased dangers of cyberattacks or the fact they could encourage people to walk or cycle less.\n\nThe difficulty in understanding how digital technologies work, especially those that are heavily driven by obscure algorithms, also makes it harder for people to have a complex and comprehensive view of the issues. This situation produces a tension between a reassuring positive narrative and the vague suspicion that biases are embedded to some degree in the technologies around us. This is where we think storytelling through design fiction can come in.\n\nStories are a natural method of thinking about possibilities and complex situations, and we have been hearing them all our lives. Science fiction can help us speculate on the impact of near-future technologies on society, as Slaughterbots does. This can even include issues of social justice, like the way certain groups, such as refugees and migrants, can be excluded from digital innovations.\n\nRevealing the (possible) future\n\nDesign fiction stories provide a novel way for designers, engineers and futurists (among others) to think about the impact of technology from a human perspective and link this to possible future needs. With a mixture of logic and imagination, design fiction can reveal aspects of how technology may be adopted and used, starting conversations about its future ramifications.\n\nFor example, the short story \u201cCrime-sourcing\u201d explores what might happen if AI was to use crowdsourced information and a criminal database to predict who might commit a murder. The researchers found that because the database was full of people in minority ethnic groups who, for social reasons, were statistically more likely to reoffend, the \u201ccrime-sourcing\u201d model was more likely to wrongly suspect minorities than white people.\n\nYou don\u2019t have to be a talented writer or make a slick film to produce design fiction. Brainstorming activities involving cards and storyboards have been used to develop design fiction and help develop the storytelling process. Making workshops that used these kinds of tools more common would enable more engineers, entrepreneurs and policymakers to use this method of assessment. And making the resulting work publicly available would help to expose potential biases in technologies before they affect society.\n\nEncouraging designers to create and share more stories in this way would ensure the narrative that underpins new technology wouldn\u2019t just present a positive picture, nor an extremely negative or dystopian one. Instead, people will be able to appreciate both aspects of what is happening around us.\n\nThis article is republished from The Conversation by Alessio Malizia, Professor of User Experience Design, University of Hertfordshire and Silvio Carta, Head of Art and Design and Chair of the Design Research Group, University of Hertfordshire under a Creative Commons license. Read the original article.\n\nRead next: An engineer explains how supercharged racing yachts go so fast", "description": "", "authors": ["The Conversation"], "top_image": "https://img-cdn.tnwcdn.com/image/tnw?filter_last=1&fit=1280%2C640&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2019%2F10%2F200-calories-2-2.png&signature=1dca2d78726553f60f140053a0a96577", "published_at": "2019-10-06"}