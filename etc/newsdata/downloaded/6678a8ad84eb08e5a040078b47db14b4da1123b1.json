{"pub": "axios", "url": "https://axios.com/ai-accuracy-bias-hidden-costs-145654ca-1507-46cf-b680-04a677dbd1e8.html", "downloaded_at": "2019-10-27 00:16:23.745467+00:00", "title": "AI comes with hidden costs", "language": "en", "text": "Why it matters: Some stumbles that have tarred high-profile AI systems \u2014 like facial recognition that fails more often on darker faces, or medical AI that gives potentially harmful advice \u2014 have resulted from unanticipated real-world scenarios.\n\nThe big picture: Research often guns for incremental advances, juicing an extra percentage point of accuracy out of a previously proposed model.\n\n\"We feel like this is the only thing that gets rewarded nowadays in the community,\" says Roy Schwartz, a researcher at the Allen Institute for Artificial Intelligence. \"We want to argue that there are other things to consider.\"\n\nIn a paper posted this summer, Schwartz and several co-authors proposed that researchers present not just the accuracy of their models but also the computing cost it took to get there \u2014 and the resulting environmental toll.\n\nThat's one of several hidden considerations that can drive up the cost of creating an AI model that works in the real world. Among the other important factors accuracy doesn't capture:\n\nThe cost of labeling training data, which is still mostly done by humans.\n\ntraining data, which is still mostly done by humans. The reliability of a system or, conversely, its tendency to make critical mistakes when it sees a new situation it hasn't been trained to deal with.\n\nor, conversely, its tendency to make critical mistakes when it sees a new situation it hasn't been trained to deal with. Vulnerability to adversarial examples, a special kind of attack that can cripple certain kinds of AI systems, potentially making an autonomous car blind to a fast-approaching stop sign.\n\na special kind of attack that can cripple certain kinds of AI systems, potentially making an autonomous car blind to a fast-approaching stop sign. Bias, or whether a model's accuracy varies depending on the kind of person or thing it is evaluating.\n\nor whether a model's accuracy varies depending on the kind of person or thing it is evaluating. Interpretability of a model's results, or how easy it is to understand why an AI system made a particular prediction.\n\n\"The machine learning model is just a tiny piece of the machine learning product,\" says Andrew Ng, founder of Landing.ai, a startup that helps companies set up AI processes.\n\n\"One of the challenges is that you ship a system and then the world changes in some weird and unpredictable way,\" says Ng, who previously started Google's and Baidu's AI operations.\n\n\"Anyone can download code from GitHub, but that's not the point,\" Ng tells Axios. \"You need all these other things.\"\n\nOne of the byproducts of the hidden costs associated with increasingly accurate AI systems is that they can make it hard for a new startup or cash-strapped university lab to compete.\n\n\"The AI models that are being designed and developed don't always contemplate the application of the model,\" says Josh Elliot, director of AI at Booz Allen Hamilton.\n\nBig companies offer pre-packaged AI programs \u2014 like one for detecting street signs, say \u2014 but users often lack the computing firepower required to tweak them.\n\nThat means the reigning players get to decide the important problems worth trying to solve with AI, Schwartz says, and everyone else has to go along.\n\nWhat's next: Schwartz, Ng and others propose putting more effort toward solving problems more efficiently rather than making a slightly more accurate model at an enormous cost.\n\nGo deeper: How not to replace humans", "description": "Considerations that matter little in the lab are huge hurdles for businesses.", "authors": [], "top_image": "https://images.axios.com/HDRdWeAvfacLlkUL7Kf4P7nlfX4=/0x0:1920x1080/1920x1080/2019/10/26/1572055038788.png", "published_at": "2019-10-26"}