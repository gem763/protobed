{"pub": "thenextweb", "url": "https://thenextweb.com/artificial-intelligence/2019/10/08/google-exploited-homeless-black-people-to-develop-the-pixel-4s-facial-recognition-ai", "downloaded_at": "2019-10-09 00:20:02.353446+00:00", "title": "Google exploited homeless black people to develop the Pixel 4\u2019s facial recognition AI", "language": "en", "text": "The US city of Atlanta, Georgia alleged last week that contractors working on behalf of Google used confusing, aggressive tactics to exploit black people in order to obtain their likeness for facial recognition AI research. Now Google\u2018s responded, saying the contractors were conducting work related to the Pixel 4\u2019s face unlock feature, and that it\u2019s suspended the program.\n\nThe research in question was conducted by temporary workers for Randstad, a company under contract with Google. The objective was to get people with darker skin tones to agree to record videos of themselves, on the temps\u2019 devices, so that their image and likeness could be sequenced for an AI training database.\n\nIn return for signing away the rights to their own face and aiding the construction of a database that could be used by bad actors to develop surveillance and tracking systems \u2013 in this case, targeted at the black community \u2013 subjects received a five-dollar gift card from Starbucks.\n\nThe contracted workers employed aggressive techniques including fast-talking to deliberately confuse their targets and, in some cases, outright lied.\n\nThe New York Daily News broke the story and spoke with several sources who allegedly worked on the project. According to it\u2019s report:\n\n[Contractors] were encouraged to rush subjects through survey questions and a consent agreement and walk away if people started to get suspicious, the for-hire workers said. \u201cOne of the days of training was basically building a vocabulary that distracts the user from the actual task at hand as much as possible,\u201d one of the former workers told The News. \u201cThe phrase \u2018mini-game\u2019 was brought up a lot,\u201d the former staffer who worked in Los Angeles said.\n\nWorkers were told to target homeless people because they \u201cdidn\u2019t know what was going on,\u201d and other marginalized groups who were less likely to object over privacy concerns or discuss things with the media. Furthermore, some workers reported being incentivized with the opportunity to become full time employees if they met their quotas.\n\nThe data was allegedly meant to help the Pixel 4 team make the upcoming phone\u2019s face unlock feature better.\n\nGoogle\u2019s response to the controversy has been to admit that it\u2019s trying to get data to overcome the inherent bias against non-white faces when it comes to facial recognition. But the company claims it was ignorant to the contractors\u2019 methods and will suspend the project.\n\nIt\u2019ll be interesting to see how Google moves forward in its ongoing efforts to create a database of black faces for facial recognition research \u2014 exploiting the homeless didn\u2019t work, perhaps it\u2019ll consider trying something ethical next.\n\nThe Pixel 4 launches in a week.", "description": "", "authors": ["Tristan Greene"], "top_image": "https://img-cdn.tnwcdn.com/image/tnw?filter_last=1&fit=1280%2C640&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2019%2F10%2Fgoogle-796x417.jpg&signature=d1c71c707019227b7d96c4f23bee6c70", "published_at": "2019-10-08"}