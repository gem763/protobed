{"pub": "marketwatch", "url": "https://marketwatch.com/story/this-is-breakthrough-technology-in-fighting-fake-videos-2019-10-07", "downloaded_at": "2019-10-07 23:32:53.103426+00:00", "title": "This is breakthrough technology in fighting fake videos", "language": "en", "text": "Fake news is a well-documented problem. Fake, but believable, artificial-intelligence-generated video is more frightening because anyone can be targeted. It\u2019s obvious that an AI-based technique is needed to counter that threat.\n\nAI-generated videos (also known as deepfakes) and images are easier to come up with than ever before. They can range from funny and quirky to much more sinister and dangerous, such as those of political statements that were never given, or shots of events that never took place.\n\nIt\u2019s easy to see how such content published on social networks or by reputable media outlets could be used to manipulate public opinion. There has been no easy way to combat this epidemic other than doing your own research. Until now.\n\nGetting ahead of deepfakes\n\nOne company, Singapore-based CVEDIA, is taking a \u201cfight fire with fire\u201d approach to combat fake news with technology that, according to its creators, is \u201cone step ahead of deepfakes.\u201d\n\nTo produce a deepfake video, a programmer needs to \u201ctrain\u201d the AI algorithm by feeding it copious amounts of visual and audio data. The algorithm then takes that data and uses it to find patterns and elements it can emulate to create its own footage.\n\nThis process can be reverse-engineered to train a similar algorithm \u2014 a \u201chunter\u201d of sorts, which can recognize fake videos and flag them appropriately. Unlike the deepfake AI that requires only the samples of person/environment it\u2019s meant to emulate, the hunter is trained on many different visual and auditory stimuli, because it needs to be ready to detect a wide range of threats.\n\nProviding an AI with this much data presents a big challenge. Not only is it expensive and time-consuming, but it can also be illegal to feed it imagery of real persons and places without their consent or proper government/institutional permissions.\n\nAn AI breakthrough\n\nBut what if the hunter AI does not need to be fed real-world info to detect fake videos? This is the approach that CVEDIA took.\n\nThe company specializes in machine-learning applications used to develop, train and validate the AI that are embedded in various sensor-enabled systems, such as vehicles or machinery. To do this, it uses SynCity, a platform that runs proprietary algorithms that simulate real-world physics, a multitude of lighting and environmental conditions, and renderings of people, animals and cars in a manner that AI systems interpret as real and lifelike.\n\nSince its algorithms are believable to the AI, CVEDIA argues they can also be used to train it to detect fake videos. Armed with this tool, AIs no longer need to rely on real-world data, and can instead be fed an infinite amount of simulated information built especially for them.\n\nThat paves the way for robust, video-authenticity verification systems that can be used to scan videos published online. Online services and social networks such as Facebook FB, -0.43% Alphabet GOOG, -0.11% GOOGL, -0.22% unit YouTube and others could use this technology to automatically scan all uploaded videos and tag them as fake.\n\nHowever, what if the hunter becomes the hunted? Making this technology or its data-acquisition model publicly available enables those spreading fake news to get their hands on it and figure out a way to trick the algorithm by making minute changes in the footage. If that happens, it would be up to those designing detection systems to up the ante and upgrade the algorithm to factor in such changes. And the cat and mouse game continues \u2026\n\nThe best protection\n\nTechnologies such as CVEDIA\u2019s are a big step toward much needed clarity on the global information highway, but they are not going to solve the problem of visual and auditory forgeries completely. We must also keep in mind that media outlets don\u2019t need deepfakes to skew the truth for their own agenda.\n\nThe best way to protect yourself from the torrent of misinformation available online is still good, old objectivism, research and fighting cognitive bias by reviewing information from multiple sources \u2014 especially if they present conflicting views. The truth is most often somewhere in between.\n\nJurica Dujmovic is a MarketWatch columnist.", "description": "CVEDIA uses a platform that runs proprietary algorithms that simulate real-world events.", "authors": ["Jurica Dujmovic"], "top_image": "http://s.marketwatch.com/public/resources/MWimages/MW-HS776_syncit_ZG_20191007101258.jpg", "published_at": "2019-10-07"}