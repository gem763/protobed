{"pub": "guardian", "url": "https://theguardian.com/technology/2019/sep/20/microsoft-boss-tech-firms-must-stop-if-its-legal-its-acceptable-approach", "downloaded_at": "2019-09-20 12:55:26.467730+00:00", "title": "Microsoft boss: tech firms must stop 'if it's legal, it's acceptable' approach", "language": "en", "text": "Exclusive: Brad Smith says firms must help define and live by standards before they are forced on them\n\nTech companies should stop behaving as though everything that is not illegal is acceptable, says Microsoft\u2019s second-in-command. Instead, they should focus on defining \u2013 and living by \u2013 the standards that they would like to see in regulation, before it gets forced on them anyway.\n\nFor some of the most potentially dangerous new technologies, such as facial recognition, that could mean voluntarily refusing to sell them to certain countries, for certain uses, or even agreeing to a moratorium altogether, said Brad Smith, the president and chief legal officer of the world\u2019s most valuable publicly-traded company.\n\nSpeaking to the Guardian before the launch of his new book, Tools and Weapons, Smith said that if technology firms wanted to be proud of how they changed the world for the better, they must take more responsibility for the ways they have made it worse.\n\nEx-Google worker fears 'killer robots' could cause mass atrocities Read more\n\n\u201cWhen you think about all of the issues that people worry about in the world today and what they spend their time arguing about, it\u2019s often issues like trade, immigration, nationalism, globalisation,\u201d Smith said. \u201cBut all of these sit on top of a foundation. And the foundation is really being driven by technology.\u201d\n\nSmith cites facial recognition software as one of the core battles still to be fought. Microsoft has already voluntarily imposed limits on how and to whom it sells the technology, he says, and he encourages other firms to do the same. \u201cWe\u2019re not willing to allow our facial recognition services to be used for mass surveillance \u2026 so if we thought that the US government or that [US immigration agency] Ice was going to deploy facial recognition for mass surveillance, we would object to that and I don\u2019t think we would do it.\n\n\u201cIf an agency in any government wants to deploy facial recognition in a manner that we believe will result in unfair bias and discrimination, that\u2019s something that we won\u2019t do.\u201d\n\nThe conversation around the technology has advanced rapidly, even in the gap between Smith finishing the manuscript and the book hitting shelves. \u201cI\u2019ve never seen an issue evolve as quickly as facial recognition has,\u201d Smith said. \u201cAnd I think there\u2019s a lot of food for thought in that. I say that in part because we feel it deeply ourselves.\u201d\n\n\u201cIt was just 13 months ago where we published a blogpost where we said: \u2018This is technology that is going to need to be regulated.\u2019 The reaction in Silicon Valley was like: \u2018What is wrong with you people at Microsoft, why are you doing this?\u2019 And then look at where we are now: we just saw the city of San Francisco, next door to Silicon Valley, ban public sector use of facial recognition.\u201d\n\nBut, although Smith calls for regulation generally, he argues against an all-out ban. \u201cThe first question one should ask is why, why is this happening? It is a technology that can be deployed in, literally, an Orwellian fashion. But I think whenever you want to ban a technology, you also have to ask, well, what are the potentials for it to do good as well? And so then the question is how do you strike the balance? I don\u2019t think that you strike that balance by banning all use. You strike that balance by banning the harmful use.\n\n\u201cNow, I respect the people who call for a moratorium, because implicit, or maybe explicit, in the word moratorium is the notion that this will not last forever. I worry about moratoriums nonetheless, just because it can make it more difficult to learn how to use the technology well if you can\u2019t put the technology to use. But I respect that point of view.\u201d\n\nA month after Smith spoke to the Guardian, 76 protesters were arrested picketing the Manhattan Microsoft store with signs reading \u201cNo Business With Ice\u201d, as part of the Close The Camps movement which demands an end to detention centres for migrants. The protest organisers told CNN that \u201cit is our responsibility to hold US corporations accountable \u2026 in the racist torture and trauma that is being inflicted. We have the power to end this cruelty.\u201d\n\nIn the book, Smith describes Microsoft\u2019s contract with Ice as a surprise to many in the company. A blogpost celebrating the deal, posted before the Trump administration started to set up detention camps on the US border, was rediscovered by activists in June.\n\n\u201cA marketing statement made several months earlier now looked a good deal different,\u201d Smith writes. \u201cAs we dug to the bottom of the matter, we learned that the contract wasn\u2019t being used for facial recognition at all. Nor, thank goodness, was Microsoft working on any projects to separate children from their families at the border.\u201d\n\nSmith says he distinguishes the sale of technology such as facial recognition from the more mundane productivity software that Microsoft does supply to Ice, and to other controversial state actors around the world.\n\n\u201cOne must assume responsibility for how your products are used in specific, well-defined, clearcut and relatively narrow ways. I think it\u2019s a different situation to try to deny access to all technology because you disagree with what people are doing in their lives or with their businesses, or as a government. So to say, \u2018I\u2019m not going to let you use Microsoft Word or our search engine on the internet\u2019, I think that\u2019s a very different dynamic.\u201d", "description": "Exclusive: Brad Smith says firms must help define and live by standards before they are forced on them", "authors": ["Alex Hern"], "top_image": "https://i.guim.co.uk/img/media/537bad9af861393dee55871b7e3ed024eb34ac11/0_508_3120_1871/master/3120.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=d7a01c6cc298cd256be5f434b68eda0c", "published_at": "2019-09-20"}