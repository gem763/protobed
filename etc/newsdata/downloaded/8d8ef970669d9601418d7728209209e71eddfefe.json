{"pub": "cbc", "url": "https://cbc.ca/radio/ideas/killer-robots-march-into-uncharted-ethical-territory-1.5289804", "downloaded_at": "2019-09-20 22:53:36.379424+00:00", "title": "CBC Radio", "language": "en", "text": "By Nahlah Ayed\n\nJody Williams has decades of peace activism under her belt, and a Nobel Prize for securing a global ban on anti-personnel landmines.\n\nBut as she told CBC IDEAS, her fight against killer robots is presenting a whole new level of daunting.\n\nThe effort to ban lethal autonomous weapons is growing more urgent \u2014 and more frustrating \u2014 given the lightning-fast progress in the technology that's edging them ever closer to becoming a reality. Stiff resistance from some world powers like the U.S., China and Russia is making it a ban much harder to achieve than the Ottawa Treaty to ban landmines.\n\nJody Williams was awarded the Nobel Prize in 1997 for her staunch efforts convincing governments to ban landmines, thereby eliminating threats to civilians. (Morten Holm/AFP/Getty Images)\n\nThe trend toward more artificial intelligence and autonomy in the modern battlefield is considered a \"third revolution\" in warfare, after gunpowder, and nuclear technology.\n\nBut put the image of \"The Terminator\" out of your head: the autonomous \"killer robot\" generation of weaponry under development and testing includes everything from tanks to drones, to vehicles.\n\nIt's the most urgent weapons issue facing us now. - Jody Williams, Stop Killer Robots campaign\n\nThe world's major powers see huge potential in the use of lethal autonomous weapons to improve speed, stealth and the protection of soldiers in combat.\n\nActivists say world powers are engaged in the beginnings of a new arms race \u2014 and whoever wins stands to rule the modern battlefield.\n\nStepping inside murky terrain\n\nProponents argue lethal autonomous weapons systems, or LAWS for short, could actually make fighting more humane \u2014 including lowering the number of civilian casualties.\n\nActivists, backed by academics, and a growing number of robotics and artificial intelligence experts, are warning such weapons are marching us into murky ethical territory we've never set foot in before.\n\n\"I think it's the most urgent weapons issue facing us now,\" said Williams, who's with the Campaign to Stop Killer Robots.\n\nThe campaign aims to see an international treaty signed that would preemptively ban any lethal weapon that could select targets and kill without meaningful human control.\n\nThe campaign helped elevate the matter to the UN's agenda nearly a decade ago. But the discussions in Geneva have been ongoing since 2013, without any significant move toward negotiating a treaty. Compare that with the landmines effort, which took a total of five years to produce a treaty.\n\n\"It's moving like molasses uphill in winter,\" said Williams.\n\nActivists pose in Geneva, next to a monument dedicated to the victims of landmines. Many of the campaign's activists are veterans of the fight to ban landmines. (Submitted by Campaign to Stop Killer Robots)\n\nMeantime, testing, development and improvement in LAWS continue.\n\nActivists say LAWS could tempt more military powers into more wars. Robotics experts say that as computer based technology, LAWS could be vulnerable to hacking. The technology could also fall into the wrong hands and unleash mayhem.\n\nActivists also have a considerable list of ethical concerns \u2014 including how to assign responsibility when war crimes are committed, and the question of whether to allow machines to take human life at all.\n\n\"The decision to kill should never be taken lightly,\" said Peter Asaro, professor of robotics and autonomous technology at the New School in New York. He's also a co-founder of the International Committee for Robot Arms Control.\n\n\"It's a very exceptional situation of warfare and self-defence that we allow people to kill because you're defending your own right to life in a sense. And machines don't have a right to life, they don't have a life, they don't understand what a life is, what it means, its significance, what it means to take it away.\"\n\nA way to eliminate suffering\n\nAt the opposite end of the argument, they insist that lethal autonomous weapons could provide moral gains: one example is machines could be more accurate and less emotional warriors than their human counterparts, who are prone to stress, depression, exhaustion or hunger\u2014 all leading to costly mistakes.\n\n\"Autonomous weapons systems simply don't suffer from any of those human psychological failings,\" said Don Howard, a philosophy professor at the University of Notre Dame.\n\n\"And so right away you have the possibility of eliminating the circumstances that we well know are productive of a lot of war crimes.\"\n\nHe also argues that autonomous weapons could allow countries to get involved in high-risk conflicts that might have been avoided in the past\u2013conflicts such as the Rwandan genocide \u2014 to avert mass killing at little risk.\n\nSmall robots are being tested as swarms at the Sheffield Robotics lab, not for military use but for possible application in space exploration. (Nahlah Ayed/CBC)\n\nThe talks at the UN's Convention on Certain Conventional Weapons in Geneva have been mired in debate over definitions and the utility of existing laws.\n\nCountries resisting the idea of a ban include the U.S., China, Russia, Israel, and South Korea. Their resistance makes a ban politically unfeasible, said Howard.\n\nThere's also the challenge of living in times when it's become, he adds, \"harder and harder to write new international law, to develop binding treaties that get the support of a sufficient majority of nations.\"\n\nPlease don't automate killing my children. - Noel Sharkey, robot expert\n\nProponents of these weapons say that existing international laws are sufficient.\n\nActivists say an international ban is the only way to protect against lethal autonomous weapons becoming an unchecked battlefield reality.\n\n\"You can automate building my car with no trouble,\" said Noel Sharkey, Emeritus professor of Robotics at Sheffield University.\n\n\"But please don't automate killing my children.\"\n\n\n\n\n\nGuests in this episode:\n\nRyan Gariepy is the chief technology officer at Clearpath Robotics\n\nis the chief technology officer at Clearpath Robotics Alain Tremblay is the vice president of business development and innovation at Rhinemetall Canada\n\nis the vice president of business development and innovation at Rhinemetall Canada Jody Williams is a Nobel laureate, activist and campaign ambassador for the International Campaign to Ban Landmines\n\nis a Nobel laureate, activist and campaign ambassador for the International Campaign to Ban Landmines Mary Wareham is the advocacy director of the Arms division of Human Rights Watch.\n\nis the advocacy director of the Arms division of Human Rights Watch. Erin Hunt is the program manager with Mines Action Canada\n\nis the program manager with Mines Action Canada Noel Sharkey is an Emeritus professor of AI and Robotics at the University of Sheffield\n\nis an Emeritus professor of AI and Robotics at the University of Sheffield Peter Asaro is a professor who specializes in Robotics and autonomous technology at the New School in New York.\n\nis a professor who specializes in Robotics and autonomous technology at the New School in New York. Paul Hannon is the executive director of Mines Action Canada\n\nis the executive director of Mines Action Canada Don Howard is a professor of philosophy at the University of Notre Dame\n\n\n\n\n\n** This episode was produced by Nahlah Ayed.", "description": "What happens if autonomous weapons fight our wars? What if they select and kill targets without any human intervention? The world is closer to this scenario than ever before. But there's no consensus on whether \u2014 or even how \u2014 it would ever be ethical. This episode delves into the complex conundrums of robot warfare.", "authors": ["Nahlah Ayed"], "top_image": "https://i.cbc.ca/1.5289848.1568990748!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_620/warning-about-autonomous-weapons.jpg", "published_at": "2013-09-20"}