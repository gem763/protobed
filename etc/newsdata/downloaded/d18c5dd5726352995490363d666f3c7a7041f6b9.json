{"pub": "cnn", "url": "https://cnn.com/2019/10/07/tech/deepfake-videos-increase/index.html", "downloaded_at": "2019-10-07 20:09:23.741651+00:00", "title": "The number of deepfake videos online is spiking. Most are porn", "language": "en", "text": "San Francisco (CNN) Deepfake videos are quickly becoming a problem, but there has been much debate about just how big the problem really is. One company is now trying to put a number on it.\n\nThere are at least 14,678 deepfake videos \u2014 and counting \u2014 on the internet, according to a recent tally by a startup that builds technology to spot this kind of AI-manipulated content. And nearly all of them are porn.\n\nThe number of deepfake videos is 84% higher than it was last December when Amsterdam-based Deeptrace found 7,964 deepfake videos during its first online count. The company conducted this more recent count in June and July, and the number has certainly grown since then, too.\n\nWhile much of the coverage about deepfakes has focused on its potential to be a tool for information warfare in politics, the Deeptrace findings show the more immediate issue is porn. In the report, released Monday, Deeptrace said 96% of the deepfakes spotted consisted of pornographic content, and all of that pornographic content featured women.\n\nDeeptrace CEO and chief scientist Giorgio Patrini told CNN Business that the growth the company charted over just seven months shows the potential for false content to be created and quickly circulated. Even if one of these deepfake videos isn't very realistic looking \u2014 at this point, plenty of them aren't \u2014 it could still be good enough to influence many people's opinions.\n\n\"That is a fairly worrying threat for social media,\" Patrini said.\n\nDeepfakes, which refer to a combination of the terms \"deep learning\" and \"fake\", use artificial intelligence to show people doing and saying something they didn't do or say. The medium is quite new: The first known videos, posted to Reddit in 2017, featured celebrities' faces swapped with those of porn stars.\n\nDeeptrace's attempt to quantify the deepfake videos online may be unique; because the technology is nascent and the videos so dispersed around the Web, it can be hard to know where to look for them, and creators don't always mark altered videos as deepfakes.\n\nFacebook FB Google GOOG On the face of it, Deeptrace's deepfake tally of less than 15,000 videos sounds like a pretty small figure, especially when you think of the countless number of videos online. Yet as the 2020 US presidential election approaches, politicians and government officials are worried about these kinds of videos being used to mislead voters . Companies such asandare so concerned about the possible spread of deepfakes on social media that they're creating their own sets of deepfake videos that they hope can be used to fight ones that pop up in the wild.\n\nAn image from a deepfake video by Paul Shales that purports to show Elon Musk as a baby. Such innocuous videos are a minority of the total number of deepfakes currently online, according to a new report.\n\nPatrini said Deeptrace is keeping track of deepfakes in order to understand the potential threat: things like the kinds of deepfakes that are being made and the places people are sharing them, as well as the places where tools (such as software or tutorials) for making them are being distributed.\n\n\"Doing modeling of your adversaries is, in a way, the first step for designing and developing a solution for the problem,\" he said. He echoed other deepfake experts in acknowledging that, like the ever-evolving field of cybersecurity at large, techniques for spotting deepfakes will have to keep changing as the technology behind it improves.\n\nThe vast majority of the deepfakes Deeptrace found, however, come from pornography websites, and particularly ones dedicated to offering visitors deepfake pornography \u2014 such as videos that feature a female celebrity or actress's face swapped onto another woman's body \u2014 and supported by advertising.\n\nAccording to Deeptrace's latest findings, more than 13,000 of the total number of deepfake videos were found on just nine deepfake-specific porn sites. Deeptrace found that eight of the top 10 pornography websites include some deepfakes in their content, too.\n\nPatrini won't disclose names of these sites, saying he doesn't want to give them more attention. But he said that the ones focused on deepfake pornography started popping up last year, based on Deeptrace's checks of when the websites' domain names were registered.\n\nDeeptrace also noticed a number of people and businesses that have started offering to make deepfakes for others. The report cited one service that claimed that it could make custom deepfakes in two days with 250 photos of the person that the buyer wants to see in the resulting video. Prices Deeptrace spotted were as low as $3 per video.\n\nDeeptrace only surveyed websites on the English-language internet, but Patrini said it was surprised to see plenty of deepfakes made with celebrities from countries in Asia, too, mainly in pornographic deepfakes but in non-pornographic ones as well.\n\nSam Gregory, program director for nonprofit Witness, which works with human rights defenders, called the uptick in deepfakes that Deeptrace spotted a \"troubling sign\".\n\n\"It's not growing exponentially yet,\" he said. But, he added: \"It's growing significantly.\"", "description": "Deepfake videos are quickly becoming a problem, but there has been much debate about just how big the problem really is. One company is now trying to put a number on it.", "authors": ["Rachel Metz", "Cnn Business"], "top_image": "https://cdn.cnn.com/cnnnext/dam/assets/190904192318-facebook-deepfake-190125-super-tease.jpg", "published_at": "2019-10-07"}