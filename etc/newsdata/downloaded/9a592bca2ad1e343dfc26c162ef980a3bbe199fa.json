{"pub": "cbc", "url": "https://cbc.ca/news/business/artificial-intelligence-crime-1.5271469", "downloaded_at": "2019-09-06 12:14:51.334130+00:00", "title": "Case of artificial intelligence crooks is a new warning for crime fighters: Don Pittis | CBC News", "language": "en", "text": "If your boss phoned and asked you to do something, would you do it? After reading this, maybe you'll think twice.\n\nWhen the first reports came in about a theft committed using a \"deep fake\" phone call \u2014 that ordered an employee to send a quarter of a million dollars to a secret account in Hungary \u2014 it was easy to scoff.\n\nBut now multiple reports have confirmed the story with the British energy company's French insurer, Euler Hermes.\n\nAccording to Rudiger Kirsch, an expert in fraud at the credit insurance company, the CEO of the company's British subsidiary clearly recognized the slight German accent and inflection of his boss, who asked him to transfer the 220,000 Euros.\n\n\"The caller said the request was urgent, directing the executive to pay within an hour, according to the company's insurance firm,\" reported the Wall Street Journal.\n\nThe fact that the British exec was willing to act on the call is evidence of the quality of the fake and an example of how ill-prepared we are in the face of unfamiliar new technology. Until now, the voice of a friend or acquaintance was enough to establish their bona fides. No more.\n\nAI accomplice\n\nSo far, the corporate victims of the scam have not been named and, while police are investigating, no suspects have been identified. The fact that the perpetrators knew the names of and relationships between the two executives, had a good sample of the senior person's voice and a idea of where he credibly might want money remains suspicious.\n\nBut whoever the crooks are, it seems artificial intelligence was an accomplice; the kind of AI that mimics famous people and makes them seem to say words they never uttered; sometimes with video to match.\n\nSo far, deep fakes have been used as a kind of internet party trick. But there have been warnings they could be used for villainy.\n\nNow that we know how convincing they can be, Canadians may be more wary \u2014 rightly or not \u2014 of politicians who seem to say outrageous things. Would a real person call teenage climate activist Greta Thunberg mentally unstable?\n\nAccording to most experts this is the first time voice imitation AI has been used to commit a crime. No one seems quite sure if AI of other kinds has been used for criminal activity. It may be hard to tell.\n\n\"The fact that these tools are so easy to get hold of and so easy to, sort of, craft to your own purposes means, I suspect, we're going to see a lot more of this stuff,\" said University of Regina computer science professor David Gerhard.\n\nWhen the late physicist Stephen Hawking warned about the menace of artificial intelligence, he was talking about the danger that machine intelligence could wipe people from the face of the earth.\n\nUnder the science fiction scenario posed by Arnold Schwarzenegger's Terminator movies, an artificial intelligence called Skynet takes over the world's missiles and battles humanity for control of the planet.\n\nWhile that would be bad, the warning of this deep fake fraud is that the more immediate danger of AI may be far more mundane.\n\nIt is well known that AI is already widely used as a security tool. Could AI be used to thwart it? As Canadian artificial intelligence pioneer Jonathan Schaeffer told me four years ago, banks were already commonly using AI to screen your credit card use, disallowing, say, an expensive watch in Vladivostok on a card you normally use for Winnipeg car rentals.\n\nGerard says, nowadays, AI remains a constant in our daily lives, with bots buying and selling stocks, and a complex machine-learning program deciding which ads you will see when you use a Google search.\n\nSo far, bank accounts and other automated security systems appear relatively resistant to AI penetration.\n\n\"Even if bad guys throw artificial intelligence at bank software, the software's not going to break. What's going to break first is the people, which is what this case is about,\" said Gerhard.\n\n\"It's not people trying to use software to break the encryption on the bank vault, it's trying to use artificial intelligence to trick a person who has the credentials to get into the bank vault.\"\n\nApparently experts are thinking of ways to use counter-AI to detect fake voices, but the real solution may require relatively simple human caution, such as a call back to confirm.\n\nAnd when the crooks are caught, it will likely be due to human error.\n\nIt seems the fraud was finally exposed when, on a subsequent call by the crooks, the executive the AI was imitating was already speaking on the other line.\n\nFollow Don on Twitter @don_pittis", "description": "We worried about artificial intelligence taking over the world. What about it emptying your bank account?", "authors": ["Business Columnist", "Don Pittis Was A Forest Firefighter", "A Ranger In Canada'S High Arctic Islands. After Moving Into Journalism", "He Was Principal Business Reporter For Radio Television Hong Kong Before The Handover To China. He Has Produced", "Reported For The Cbc In Saskatchewan", "Toronto", "The Bbc In London. He Is Currently Senior Producer At Cbc'S Business Unit.", "More Don Pittis"], "top_image": "https://i.cbc.ca/1.5272426.1567718669!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_620/175764161.jpg", "published_at": "2019-09-06"}