{"pub": "usatoday", "url": "https://usatoday.com/story/tech/2019/10/02/how-artificial-intelligence-bias-can-work-against-you/2417711001", "downloaded_at": "2019-10-05 14:16:58.431554+00:00", "title": "AI bias: How tech determines if you land job, get a loan or end up in jail", "language": "en", "text": "CLOSE One Georgia school district plans to spend $16.5 million to install artificial intelligence-powered surveillance cameras in its roughly 100 buildings in coming years. (Aug. 30) AP\n\nBusinesses across almost every industry deploy artificial intelligence to make jobs simpler for staff and tasks easier for consumers.\n\nComputer software teaches customer service agents how to be more compassionate, schools use machine learning to scan for weapons and mass shooters on campus, and doctors use AI to map the root cause of diseases.\n\nSectors such as cybersecurity, online entertainment and retail use the tech in combination with wide swaths of customer data in revolutionary ways to streamline services.\n\nThough these applications may seem harmless, perhaps even helpful, the AI is only as good as the information fed into it, which can have serious implications.\n\nYou might not realize it, but AI helps determine whether you qualify for a loan in some cases. There are products in the pipeline that could have police officers stopping you because software identified you as someone else.\n\nDeepfake 2020: New artificial intelligence battles altered videos before elections\n\nPew survey: Americans trust police more than tech giants to use facial recognition\n\nImagine if people on the street could take a photo of you, then a computer scanned a database to tell them everything about you, or if an airport's security camera flagged your face while a bad guy walked clean through TSA.\n\nThose are real-world possibilities when the tech that\u2019s supposed to bolster convenience has human bias baked into the framework.\n\n\"Artificial intelligence is a super powerful tool, and like any really powerful tool, it can be used to do a lot of things \u2013 some of which are good and some of which can be problematic,\" said Eric Sydell, executive vice president of innovation at Modern Hire, which develops AI-enabled software.\n\n\"In the early stages of any new technology like this, you see a lot of companies trying to figure out how to bring it into their business,\" Sydell said, \"and some are doing it better than others.\"\n\nArtificial intelligence tends to be a catch-all term to describe tasks performed by a computer that would usually require a human, such as speech recognition and decision making.\n\nWhether it's intentional or not, humans make judgments that can spill over into the code created for AI to follow. That means AI can contain implicit racial, gender and ideological biases, which prompted an array of federal and state regulatory efforts.\n\nCriminal justice\n\nIn June, Rep. Don Beyer, D-Va., offered two amendments to a House appropriations bill that would prevent federal funds from covering facial recognition technology by law enforcement and require the National Science Foundation to report to Congress on the social impacts of AI.\n\nCLOSE Cops are always on the lookout to fine those who are texting while driving. But now Australia is taking things to the next level and using artificial intelligence to catch drivers who are guilty of this offense. Veuer\u2019s Susana Victoria Perez has more. Buzz60\n\n\"I don\u2019t think we should ban all federal dollars from doing all AI. We just have to do it thoughtfully,\" Beyer told USA TODAY. He said computer learning and facial recognition software could enable police to falsely identify someone, prompting a cop to reach for a gun in extreme cases.\n\n\"I think very soon we will ask to ban the use of facial recognition technology on body cams because of the real-time concerns,\" Beyer said. \"When data is inaccurate, it could cause a situation to get out of control.\"\n\nAI is used in predictive analysis, in which a computer reveals how likely a person is to commit a crime. Though it's not quite to the extent of the \"precrime\" police units of the Tom Cruise sci-fi hit \"Minority Report,\" the technique has faced scrutiny over whether it improves safety or simply perpetuates inequities.\n\nAmericans have voiced mixed support of AI applications, and the majority (82%) agree that it should be regulated, according to a study this year from the Center for the Governance of AI and Oxford University\u2019s Future of Humanity Institute.\n\nWhen it comes to facial recognition specifically, Americans say law enforcement agencies will put the tech to good use.\n\nBody cams aren't going to make cops better: College degrees and higher standards will\n\nJobs\n\nNumerous studies suggest that automation will destroy jobs for humans. For example, Oxford academics Carl Benedikt Frey and Michael Osborne estimated that 47% of American jobs are at high risk of automation by the mid-2030s.\n\nAs workers worry about being displaced by computers, others are hired thanks to AI-enabled software.\n\nThe technology can match employees who have the ideal skill sets for a specific work environment with employers who may be too busy to have humans screen candidates.\n\nAutomation could impact both blue- and white-collar workers. (Photo: Getty Images)\n\nModern Hire uses data gathered from tests, audio interviews and resumes to predict how a person might behave on the job.\n\n\"Meaningful bits\" of information include \"how a person will work, how long they will stay, will they be a top sales performer or a high-quality worker,\" Sydell said.\n\nUsing AI, \"we can get rid of processes that don't work well or are redundant. And we can give candidates a better experience by giving them real-time feedback throughout the process,\" Sydell said.\n\nHe said if AI is deployed poorly, it can make the job environment worse, but if it's done thoughtfully, it can lead to fairer workplaces.\n\nRobots stealing jobs isn't the problem: This is.\n\nFinance\n\nFor better or worse, artificial intelligence affects the financial decisions people make, and it has for years. It plays an increasingly significant role inhow traders invest, and it's particularly effective at preventing credit card fraud, experts said.\n\nSome AI stocks are great buys. (Photo: Getty Images)\n\nWhere things get questionable is when the tech is used to decide whether you're worthy of borrowing money from a bank.\n\n\"Whenever you apply for a loan, there may be AI to figure out if that loan should be given or not,\" said Kunal Verma, co-founder of AppZen, an AI platform for finance teams with clients including WeWork and Amazon.\n\nThe technology is often touted as a faster and more accurate assessment of a potential loan borrower as it can sift through tons of data in seconds. However, there's room for error.\n\nIf the information fed into an algorithm shows that you live in an area where a lot of people have defaulted on their loans, the system may determine you are not reliable, Verma said.\n\n\"It may also happen that the area may have a lot of people of certain minorities or other characteristics that could lead to a bias in the algorithm,\" Verma said.\n\nThe problem with AI? Study says it's too white and male, calls for more women, minorities\n\nSolutions to bias\n\nBias can creep in at almost every stage of the deep-learning process; however, algorithms can also help reduce disparities caused by poor human judgment.\n\nAI can also help detect breast cancer. (Photo: Getty Images)\n\nOne type of solution involves altering sensitive attributes in a data set to offset the outcome. Another is prescreening data to maintain accuracy. Either way, the more data a company has, the more fair AI can be, Sydell said.\n\n\"There\u2019s a reason why Google, Facebook and Amazon are leaders in AI,\" Sydell said. \"It\u2019s because they have tons of data to crunch. Other companies have access to the same type of AI technology, but they may not have massive amounts of data to use and apply it to. That\u2019s the stumbling block.\"\n\nBeyer, the politician who wants to regulate AI, is in favor of having humans double-check decisions made by computers \"until the technology is perfect, if it ever is.\"\n\nHe said it may be worth it to question whether AI should be the go-to solution to every problem, including whether someone goes to jail.\n\n\"And when it\u2019s perfect, we have to start thinking about privacy. Like, is it reasonable to take a photo of someone and run that through a database?\" Beyer said. \"If AI can read an X-ray much more quickly, much more accurately and with less bias than a human, that\u2019s terrific. If we give AI the ability to declare war, we\u2019re in big trouble.\"\n\nFollow Dalvin Brown on Twitter: @Dalvin_Brown.\n\nRead or Share this story: https://www.usatoday.com/story/tech/2019/10/02/how-artificial-intelligence-bias-can-work-against-you/2417711001/", "description": "AI helps\u00a0determine\u00a0whether you qualify for a loan or get to be considered for a job. How can it be fair when human bias gets programmed in?", "authors": ["Dalvin Brown", "Published A.M. Et Oct."], "top_image": "https://www.gannett-cdn.com/-mm-/5536358a7b56e6877ef9eff4aa729bb3ff172e43/c=0-122-2102-1304/local/-/media/2019/09/08/USATODAY/usatsports/artificial-intelligence-ai-getty-6217.jpg?width=3200&height=1680&fit=crop", "published_at": "2019-10-02"}