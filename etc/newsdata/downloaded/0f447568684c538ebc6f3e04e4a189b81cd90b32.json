{"pub": "arstechnica", "url": "https://arstechnica.com/information-technology/2019/09/feds-say-boeing-737-needs-to-be-better-designed-for-humans", "downloaded_at": "2019-10-05 10:34:55.603337+00:00", "title": "Feds say Boeing 737 needs to be better designed for humans", "language": "en", "text": "The two 737 MAX crashes that killed 346 people and led to what is, so far, a six-month grounding of the jet, stemmed in part from Boeing\u2019s failure to accurately anticipate how pilots would respond to a malfunctioning feature that pointed the jets toward the ground. That\u2019s the key finding from a report the National Transportation Safety Board published Thursday, which included a series of recommendations to the Federal Aviation Administration. The NTSB advised the regulator to have Boeing consider how 737 MAX pilots would handle not just problems with the MCAS system alone, but how they respond to multiple simultaneous alerts and indicators. In short, the NTSB says Boeing was wrong to assume pilots would respond correctly to the problem that ended up killing them.\n\nThe crashes of Lion Air Flight 610, in October 2018, and Ethiopian Airlines Flight 302, in March, stemmed from a feature Boeing designed to prevent stalls. In both cases, the Maneuvering Characteristics Augmentation System, or MCAS, activated in response to a false reading from a faulty angle of attack sensor. The pilots fought to counteract the system, which pushed the nose of the plane down, but ultimately failed.\n\nWhen Boeing tested what would happen if the MCAS malfunctioned, it didn\u2019t account for other elements. The Lion Air and Ethiopian pilots on the doomed planes dealt with a cascade of problems and warnings: Their control sticks shook. Various alarms sounded. When the pilots retracted the flaps, the plane\u2019s downward push required extra force to keep the jet aloft. The result: Their reactions \u201cdid not match [Boeing\u2019s] assumptions,\u201d the NTSB found. \u201cAn aircraft system should be designed such that the consequences of any human error are limited.\u201d\n\nThe FAA hasn\u2019t said whether it will adopt the recommendations of the NTSB, which has no regulatory or enforcement power. And this is far from the end of the 737 MAX saga: Boeing and the FAA are still negotiating a fix to the plane\u2019s software, and congressional, international, and criminal investigations into the crashes are ongoing.\n\nBut as its title\u2014\u201cAssumptions Used in the Safety Assessment Process and the Effects of Multiple Alerts and Indications on Pilot Performance\u201d\u2014indicates, the NTSB report is about more than one troubled jet, one feature, one company, or even one country. The safety board wants the FAA to apply this sort of thinking to all the planes it certifies. And it hopes the agency will encourage its peers around the world to do the same. That\u2019s because the report is all about the question at the core of modern aviation safety: How to ensure that pilots can work with the computers that have taken on more of the work in the cockpit. It\u2019s about a field of study called \u201chuman factors.\u201d\n\n\u201cThe field of aviation has been the cradle of human factors, and its biggest beneficiary,\u201d says Najmedin Meshkati, who studies the field at the University of Southern California. Where ergonomics and biomechanics center on physical responses, human factors tends to center on the gray stuff packed into their skulls. It matters in fields from self-driving cars to coal mines\u2014anywhere people interact with machines. It\u2019s long been a major focus in aviation because so many crashes trace back to pilots\u2019 failure to understand what the plane\u2019s myriad and complex systems are doing, why, or how to influence them. \u201cWhenever you have a human error, and the consequence isn\u2019t immediately noticeable or reversible, human factors is important,\u201d Meshkati says.\n\nThat\u2019s often the case in aviation\u2014and the error doesn\u2019t always come from the human. The rising use of automation in aviation has produced major safety and practical benefits, but also distanced humans from the workings of the planes they\u2019re commanding. Meshkati draws a distinction between decision making and problem solving. The former is usually routine and procedure-based, like using your altitude, airspeed, and heading to calculate a landing path. Computers are very good at this. Problem solving comes in when some combination of factors means the procedures don\u2019t work, when a person needs to absorb information and devise a new formula that will keep them safe. This is where humanity has the edge, but hardly a guaranteed victory.\n\nAccording to the NTSB report, Boeing counted on pilots following a procedure that would get them out of a situation where MCAS malfunctioned. But Lion Air 610 and Ethiopian 302 demanded problem solving: Each set of pilots was fighting a plane that wanted to dive, while considering a cascade of malfunctions and signals. Better human factor thinking, Meshkati says, would have required less, or easier, problem solving. It could have produced a procedure that fit the actual conditions of the flights, allowing for good old decision making.\n\nOf course, the FAA has other things to consider. The NTSB\u2019s recommendations are \u201cabsolutely valid,\u201d says Clint Balog, a flight test pilot and human factors expert with the College of Aeronautics at Embry-Riddle University. But, he says, the safety agency trends toward idealism. \u201cThe FAA has to consider, what is realistic testing?\u201d If airplane makers had to test for every possible combination of malfunctions and cockpit alarms, they\u2019d never get another plane certified, he says. Not all pilots are equally skilled, by virtue of their natural talent, training, or experience. It doesn\u2019t make sense, Balog says, to design for the worst of the bunch\u2014or the best. Cockpits as physical spaces, he points out, are designed for pilots of many shapes and sizes. But designers had to settle on limits on who can sit comfortably or reach every control. \u201cWe\u2019ve got to figure out how to do the same thing for cognitive capability,\u201d Balog says.\n\nThis story first appeared on wired.com.", "description": "NTSB review suggests pilots may have been overwhelmed by multiple alerts and warnings.", "authors": ["Alex Davies"], "top_image": "https://cdn.arstechnica.net/wp-content/uploads/2019/03/Boeing_737_MAX_7-1-1-1-760x380.jpg", "published_at": "2019-09-28"}