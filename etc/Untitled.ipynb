{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.models import Newsdata\n",
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = Newsdata.objects.filter(publisher='cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp('financial economic')\n",
    "doc2 = nlp(news[150].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.537876448762856"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(CNN) Ten years after first showing an interest in the equine world, Sheikh Fahad bin Abdullah Al Thani has become a serious player as well as immersing himself in the heartbeat of British horse racing in Newmarket.\\n\\nAnd not just in horse racing -- in Newmarket seven-a-side football circles, Sheikh Fahad has earned himself a reputation as as a lethal defender.\\n\\nOn the surface, it is an unlikely moniker for the member of the Qatari Royal family, who has helped transform British horse racing from sponsoring the once struggling Champions Day by QIPCO to owning winners of races ranging from the Melbourne Cup to the St. Leger.\\n\\nHis racing manager David Redvers -- the man the sheikh first approached to get into the sport -- said: \"He\\'s exceptionally passionate about it. He lives in Newmarket and I don\\'t think he\\'s ever missed a race where we\\'ve had a runner.\\n\\n\"Plus, he sponsors a seven-a-side football team. I think he\\'s a lethal defender and you need to look after your ankles! But he\\'s made British racing his home and we\\'re lucky to have him.\"\\n\\nRedvers is particularly grateful. At the time he was first approached, Redvers\\' Tweenhills operation was struggling having, as he put it, \"just lost two stallions through premature demises,\" leaving his business in a precarious position.\\n\\nHe was contacted to say a Qatari sheikh wanted to buy a racehorse. At the same time, the so-called \"Fake Sheikh\" from the now defunct British newspaper the News of the World had been tricking high-profile celebrities, and Redvers was initially suspicious.\\n\\n\"When something like a sheikh wanting to buy comes out of the blue, of course you question it,\" he said. \"I had just landed in New Zealand but I immediately turned back round and came back.\"\\n\\nIn the meantime Redvers used a military contact to find out more about Sheikh Fahad , but almost missed what would prove to be a transformative meeting.\\n\\n\"It was 3 a.m. and I feel asleep at Sydney Airport so I missed my connecting flight,\" Redvers recalled, although he did manage to just make the meeting.\\n\\n\"We basically had a simple conversation in that he was fascinated with racing and wanted to get involved as an owner, to start small and, if it was profitable, to dip his toe in the water. It was music to my ears, I relished the challenge and rose to it.\"\\n\\nSheikh Fahad helped light the torch paper for the burgeoning horse racing interest from Qatar.\\n\\nMelbourne Cup glory\\n\\nThe first horse bought nearly doubled in value in the space of a week and, two years after that first conversation, they had won the prestigious Melbourne Cup with Dunaden.\\n\\n\"Suddenly, all the Qatari and racing world sat up bolt upright as to what one young nephew of the Emir had achieved on his own,\" said Redvers, who later helped the Sheikh and his brothers set up the hugely successful Qatar Racing as well as encouraging them to sponsor the Champions Series, a tie-up which still runs to this day.\\n\\n\"It\\'s been full-on investment from them and basically success breeds success. We thankfully had that right from the off.\"\\n\\nSheikh Fahad was just 20 when he first met Redvers. A decade on and the relationship has blossomed with the injection of interest and money from Qatar showing echoes of Dubai ruler Sheikh Mohammed bin Rashid Al Maktoum\\'s foray into British horse racing in the 1970s.\\n\\nAs for the key to his boss\\' success, Redvers is quite clear: \"One loves enthusiasm in someone and a shared enthusiasm is even better. From day one, I certainly felt this is a man I can work with. It\\'s obvious that you can use enthusiasm as a real force for good in horse racing.\\n\\n\"Take the British Champions Day concept for example. That was struggling to get off the ground, he loved the idea of Champions Day and that fact it was a wonderful opportunity to broaden the appeal of racing and bring in new people. It\\'s taken a lot of investment to make it happen and that can\\'t be relied on for ever.\"\\n\\nJUST WATCHED Why nutrition is important for race horses Replay More Videos ... MUST WATCH Why nutrition is important for race horses 02:42\\n\\n\\'You get less for murder these days\\'\\n\\nHigh-profile racing from Qatar is more than just Sheikh Fahad but his successful emergence also helped spawn Al Shaqab racing, owned by his uncle, with Redvers seeing Melbourne Cup-winner Dunaden as the key turning point.\\n\\n\"Suddenly Qataris who thought horse racing was the exclusive land of Sheikh Mohammed realized that anyone could give it a go and it raised the profile on the world stage,\" he added.\\n\\nRedvers refers to Sheikh Fahad \"as like family\" and likes to joke that \"you get less for murder these days\" of the decade they have been in partnership.\\n\\n\"He was 20 when I met him and he\\'s 30 now and I\\'ve enjoyed seeing him develop,\" said Redvers. \"He\\'s become an incredibly astute judge of form, there\\'s nothing for me to tell him now. Plus he\\'s very down to earth and very good company.\\n\\n\"He\\'s just as happy talking to the lads in the yard as he is any training. My remit is to run the business as profitably as I can. We made a significant profit last year and will do again this which is pretty rare in the horse racing world.\\n\\n\"Now we\\'re breeding the majority of the stock we race although we still buy a few to fill the gaps. He\\'ll continue to be large pat of this sport for years to come. Again, we\\'re lucky to have him.\"'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news[2].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------------------------------------] 1.0% 16.9/1662.8MB downloaded"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-516c0ee8b5a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'word2vec-google-news-300'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\downloader.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, return_path)\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 495\u001b[1;33m         \u001b[0m_download\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\downloader.py\u001b[0m in \u001b[0;36m_download\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"{fname}.gz\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[0mdst_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m         \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_progress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_calculate_md5_checksum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_get_checksum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m                 \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    445\u001b[0m             \u001b[1;31m# Amount is given, implement using readinto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    489\u001b[0m         \u001b[1;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[1;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1050\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1052\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    909\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 911\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    912\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = api.load('text8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [d for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tagged_document(list_of_list_of_words):\n",
    "    for i, list_of_words in enumerate(list_of_list_of_words):\n",
    "        yield gensim.models.doc2vec.TaggedDocument(list_of_words, [i, 'test'])\n",
    "        \n",
    "train_data = list(create_tagged_document(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = namedtuple('tagger', 'topic src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"tagger(topic='test1', src='cnn')\""
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(tagger(topic='test1', src='cnn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "td0 = gensim.models.doc2vec.TaggedDocument(data[0], ['all'])\n",
    "td1 = gensim.models.doc2vec.TaggedDocument(data[1], ['all'])\n",
    "td2 = gensim.models.doc2vec.TaggedDocument(data[2], ['all'])\n",
    "td3 = gensim.models.doc2vec.TaggedDocument(data[3], ['all'])\n",
    "td4 = gensim.models.doc2vec.TaggedDocument(data[4], ['all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-09 20:30:22,005 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-09 20:30:23,589 : INFO : collecting all words and their counts\n",
      "2019-09-09 20:30:23,589 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2019-09-09 20:30:23,589 : INFO : collected 7792 word types and 5 unique tags from a corpus of 5 examples and 50000 words\n",
      "2019-09-09 20:30:23,589 : INFO : Loading a fresh vocabulary\n",
      "2019-09-09 20:30:23,605 : INFO : effective_min_count=2 retains 3764 unique words (48% of original 7792, drops 4028)\n",
      "2019-09-09 20:30:23,605 : INFO : effective_min_count=2 leaves 45972 word corpus (91% of original 50000, drops 4028)\n",
      "2019-09-09 20:30:23,620 : INFO : deleting the raw counts dictionary of 7792 items\n",
      "2019-09-09 20:30:23,620 : INFO : sample=0.001 downsamples 42 most-common words\n",
      "2019-09-09 20:30:23,620 : INFO : downsampling leaves estimated 33573 word corpus (73.0% of prior 45972)\n",
      "2019-09-09 20:30:23,636 : INFO : estimated required memory for 3764 words and 50 dimensions: 3389600 bytes\n",
      "2019-09-09 20:30:23,636 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab([td0, td1, td2, td3, td4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-09 20:30:24,579 : INFO : training model with 3 workers on 3764 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-09-09 20:30:24,595 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:24,610 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:24,610 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:24,610 : INFO : EPOCH - 1 : training on 50000 raw words (33517 effective words) took 0.0s, 977109 effective words/s\n",
      "2019-09-09 20:30:24,641 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:24,641 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:24,657 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:24,657 : INFO : EPOCH - 2 : training on 50000 raw words (33585 effective words) took 0.0s, 937270 effective words/s\n",
      "2019-09-09 20:30:24,673 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:24,688 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:24,688 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:24,688 : INFO : EPOCH - 3 : training on 50000 raw words (33525 effective words) took 0.0s, 1002800 effective words/s\n",
      "2019-09-09 20:30:24,720 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:24,720 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:24,735 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:24,735 : INFO : EPOCH - 4 : training on 50000 raw words (33615 effective words) took 0.0s, 1014838 effective words/s\n",
      "2019-09-09 20:30:24,751 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:24,751 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:24,766 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:24,766 : INFO : EPOCH - 5 : training on 50000 raw words (33546 effective words) took 0.0s, 1066303 effective words/s\n",
      "2019-09-09 20:30:24,782 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:24,798 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:24,798 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:24,798 : INFO : EPOCH - 6 : training on 50000 raw words (33656 effective words) took 0.0s, 1002867 effective words/s\n",
      "2019-09-09 20:30:24,829 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:24,829 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:24,829 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:24,845 : INFO : EPOCH - 7 : training on 50000 raw words (33566 effective words) took 0.0s, 971480 effective words/s\n",
      "2019-09-09 20:30:24,860 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:24,876 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:24,876 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:24,876 : INFO : EPOCH - 8 : training on 50000 raw words (33603 effective words) took 0.0s, 1007574 effective words/s\n",
      "2019-09-09 20:30:24,891 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:24,907 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:24,907 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:24,907 : INFO : EPOCH - 9 : training on 50000 raw words (33550 effective words) took 0.0s, 1033991 effective words/s\n",
      "2019-09-09 20:30:24,923 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:24,938 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:24,938 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:24,938 : INFO : EPOCH - 10 : training on 50000 raw words (33540 effective words) took 0.0s, 1092754 effective words/s\n",
      "2019-09-09 20:30:24,969 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:24,969 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:24,969 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:24,969 : INFO : EPOCH - 11 : training on 50000 raw words (33535 effective words) took 0.0s, 1049090 effective words/s\n",
      "2019-09-09 20:30:25,001 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,001 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,016 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,016 : INFO : EPOCH - 12 : training on 50000 raw words (33489 effective words) took 0.0s, 1046028 effective words/s\n",
      "2019-09-09 20:30:25,032 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,048 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,048 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,048 : INFO : EPOCH - 13 : training on 50000 raw words (33610 effective words) took 0.0s, 1048118 effective words/s\n",
      "2019-09-09 20:30:25,063 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,079 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,079 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,079 : INFO : EPOCH - 14 : training on 50000 raw words (33547 effective words) took 0.0s, 1034319 effective words/s\n",
      "2019-09-09 20:30:25,110 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,110 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,110 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,126 : INFO : EPOCH - 15 : training on 50000 raw words (33582 effective words) took 0.0s, 940190 effective words/s\n",
      "2019-09-09 20:30:25,141 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,157 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,157 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,157 : INFO : EPOCH - 16 : training on 50000 raw words (33614 effective words) took 0.0s, 934226 effective words/s\n",
      "2019-09-09 20:30:25,188 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,188 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,188 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,188 : INFO : EPOCH - 17 : training on 50000 raw words (33608 effective words) took 0.0s, 978168 effective words/s\n",
      "2019-09-09 20:30:25,219 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,219 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,235 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,235 : INFO : EPOCH - 18 : training on 50000 raw words (33467 effective words) took 0.0s, 1035591 effective words/s\n",
      "2019-09-09 20:30:25,251 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,266 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,266 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,266 : INFO : EPOCH - 19 : training on 50000 raw words (33542 effective words) took 0.0s, 927951 effective words/s\n",
      "2019-09-09 20:30:25,298 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,298 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,313 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,313 : INFO : EPOCH - 20 : training on 50000 raw words (33527 effective words) took 0.0s, 906419 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-09 20:30:25,344 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,344 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,344 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,344 : INFO : EPOCH - 21 : training on 50000 raw words (33530 effective words) took 0.0s, 965106 effective words/s\n",
      "2019-09-09 20:30:25,376 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,376 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,391 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,391 : INFO : EPOCH - 22 : training on 50000 raw words (33667 effective words) took 0.0s, 904060 effective words/s\n",
      "2019-09-09 20:30:25,423 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,423 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,423 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,423 : INFO : EPOCH - 23 : training on 50000 raw words (33621 effective words) took 0.0s, 998334 effective words/s\n",
      "2019-09-09 20:30:25,454 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,454 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,454 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,469 : INFO : EPOCH - 24 : training on 50000 raw words (33561 effective words) took 0.0s, 1004288 effective words/s\n",
      "2019-09-09 20:30:25,485 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,485 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,501 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,501 : INFO : EPOCH - 25 : training on 50000 raw words (33539 effective words) took 0.0s, 1041173 effective words/s\n",
      "2019-09-09 20:30:25,516 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,532 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,532 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,532 : INFO : EPOCH - 26 : training on 50000 raw words (33569 effective words) took 0.0s, 967236 effective words/s\n",
      "2019-09-09 20:30:25,563 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,563 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,579 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,579 : INFO : EPOCH - 27 : training on 50000 raw words (33544 effective words) took 0.0s, 908603 effective words/s\n",
      "2019-09-09 20:30:25,594 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,610 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,610 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,610 : INFO : EPOCH - 28 : training on 50000 raw words (33594 effective words) took 0.0s, 1038191 effective words/s\n",
      "2019-09-09 20:30:25,626 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,641 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,641 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,641 : INFO : EPOCH - 29 : training on 50000 raw words (33632 effective words) took 0.0s, 1100419 effective words/s\n",
      "2019-09-09 20:30:25,657 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,672 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,672 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,672 : INFO : EPOCH - 30 : training on 50000 raw words (33498 effective words) took 0.0s, 985508 effective words/s\n",
      "2019-09-09 20:30:25,704 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,704 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,719 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,719 : INFO : EPOCH - 31 : training on 50000 raw words (33549 effective words) took 0.0s, 1022729 effective words/s\n",
      "2019-09-09 20:30:25,735 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,735 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,751 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,751 : INFO : EPOCH - 32 : training on 50000 raw words (33578 effective words) took 0.0s, 1160479 effective words/s\n",
      "2019-09-09 20:30:25,766 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,766 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,782 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,782 : INFO : EPOCH - 33 : training on 50000 raw words (33447 effective words) took 0.0s, 1091851 effective words/s\n",
      "2019-09-09 20:30:25,797 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,813 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,813 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,813 : INFO : EPOCH - 34 : training on 50000 raw words (33571 effective words) took 0.0s, 1085190 effective words/s\n",
      "2019-09-09 20:30:25,829 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,844 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,844 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,844 : INFO : EPOCH - 35 : training on 50000 raw words (33723 effective words) took 0.0s, 1087232 effective words/s\n",
      "2019-09-09 20:30:25,860 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,876 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,876 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,876 : INFO : EPOCH - 36 : training on 50000 raw words (33610 effective words) took 0.0s, 1095788 effective words/s\n",
      "2019-09-09 20:30:25,891 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,907 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,907 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,907 : INFO : EPOCH - 37 : training on 50000 raw words (33634 effective words) took 0.0s, 1137995 effective words/s\n",
      "2019-09-09 20:30:25,922 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,938 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,938 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,938 : INFO : EPOCH - 38 : training on 50000 raw words (33571 effective words) took 0.0s, 1094270 effective words/s\n",
      "2019-09-09 20:30:25,969 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:25,969 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:25,969 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:25,969 : INFO : EPOCH - 39 : training on 50000 raw words (33525 effective words) took 0.0s, 1104631 effective words/s\n",
      "2019-09-09 20:30:26,001 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-09 20:30:26,001 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-09 20:30:26,016 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-09 20:30:26,016 : INFO : EPOCH - 40 : training on 50000 raw words (33675 effective words) took 0.0s, 1044426 effective words/s\n",
      "2019-09-09 20:30:26,016 : INFO : training on a 2000000 raw words (1342862 effective words) took 1.4s, 937595 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model.train([td0, td1, td2, td3, td4], total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
