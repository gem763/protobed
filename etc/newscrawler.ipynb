{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import newspaper\n",
    "from newspaper import Article, Config\n",
    "from newsplease import NewsPlease\n",
    "from IPython.core.debugger import set_trace\n",
    "import extraction\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "import glob\n",
    "import pandas as pd\n",
    "import news_publishers\n",
    "from langdetect import detect\n",
    "from pubtime_extractor import extractArticlePublishedDate\n",
    "import asyncio\n",
    "from functools import partial\n",
    "\n",
    "# Suppress UnknownTimezoneWarning\n",
    "import warnings\n",
    "from dateutil.parser import UnknownTimezoneWarning\n",
    "warnings.filterwarnings('ignore', category=UnknownTimezoneWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _config():\n",
    "    config = Config()\n",
    "    config.fetch_images = False\n",
    "    config.memoize_articles = False\n",
    "    config.request_timeout = 10\n",
    "    config.language = 'en'\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_url(pub, url):\n",
    "    url = url.replace('http://', 'https://')\n",
    "    \n",
    "    if pub!='zdnet':\n",
    "    # zdnet은 반드시 www가 붙어야되는 듯 (2019.08.30)\n",
    "        url = url.replace('https://www.', 'https://')\n",
    "    \n",
    "    if pub!='thinkprogress' and url[-1]=='/':\n",
    "    # thinkprogress는 뒤의 /가 반드시 필요한 듯 (2019.09.04)\n",
    "        url = url[:-1]\n",
    "    \n",
    "    if pub=='reuters':\n",
    "    # reuters는 뒤에 의미없이 ?il=0 이 붙는 경우가 허다. 무슨뜬인지는 모름 (2019.09.04)\n",
    "        try: url = url[:url.index('?il=0')]\n",
    "        except: pass\n",
    "    \n",
    "    if pub=='marketwatch':\n",
    "        try: url = url[:url.index('?mod=')]\n",
    "        except: pass        \n",
    "    \n",
    "    if pub=='wsj':\n",
    "    # wsj paywall 뚫기\n",
    "        try: url = url[:url.index('?mod=')]\n",
    "        except: pass\n",
    "        \n",
    "        url += '?mod=rsswn'\n",
    "        \n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_urls(src):\n",
    "    s = time.time()\n",
    "    n = len(src)\n",
    "    n_done = [0]\n",
    "    status = '\\r{pct}% collected: {pub:<20}'\n",
    "    newspaper_config = partial(newspaper.build, config=_config())\n",
    "    \n",
    "    def progress(pub):\n",
    "        n_done[0] += 1  # 그냥 n_done으로는 외부에서 변수값을 바꿀수 없으므로\n",
    "        pct = '%.2f' % (n_done[0] / n * 100)\n",
    "        print(status.format(pub=pub, pct=pct), end='')\n",
    "        \n",
    "    \n",
    "    async def geturls(pub, domain):\n",
    "        resp = await loop.run_in_executor(None, newspaper_config, domain)\n",
    "        articles = resp.articles\n",
    "        urls = {clean_url(pub, article.url) for article in articles}\n",
    "        progress(pub)\n",
    "        return pub, urls\n",
    "\n",
    "\n",
    "    async def main():\n",
    "        fts = [asyncio.ensure_future(geturls(pub, val['domain'])) for pub, val in src.items()]\n",
    "        return await asyncio.gather(*fts)\n",
    "\n",
    "\n",
    "    result = None\n",
    "    asyncio.set_event_loop(asyncio.new_event_loop())\n",
    "    loop = asyncio.get_event_loop()\n",
    "\n",
    "    try:\n",
    "        # 다음 코드를 주피터에서 돌리려면, tornado를 downgrade 해야함\n",
    "        # pip install tornado==4.5.3\n",
    "        result = loop.run_until_complete(main())\n",
    "        result = dict(result) #set.union(*result)\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\n",
    "    finally:\n",
    "        loop.close()\n",
    "\n",
    "    print('\\nURLs collected: {0:.2f} seconds'.format(time.time() - s))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publish_time(article):\n",
    "    pubtime = article.publish_date\n",
    "    url = article.url\n",
    "    datesrc = 'newspaper'\n",
    "    \n",
    "    # articleDateExtractor 내부의 print 를 suppress 하기 위한 장치\n",
    "    # --- articleDateExtractor 코드 자체를 변경함 (2019.09.05)\n",
    "    #class HiddenPrints:\n",
    "    #    def __enter__(self):\n",
    "    #        self._original_stdout = sys.stdout\n",
    "    #        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    #    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "    #        sys.stdout.close()\n",
    "    #        sys.stdout = self._original_stdout\n",
    "        \n",
    "    \n",
    "    def _from_extractor(url):\n",
    "        try:\n",
    "            return extractArticlePublishedDate(url)\n",
    "        \n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    \n",
    "    def _from_newsplease(url):\n",
    "        try:\n",
    "            return NewsPlease.from_url(url).date_publish\n",
    "        \n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    \n",
    "    def _timize(time):\n",
    "        if time is None:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            time = pd.Timestamp(time)\n",
    "            \n",
    "            if time.tz is None:\n",
    "                return time.tz_localize('utc')\n",
    "            \n",
    "            else:\n",
    "                return time.tz_convert('utc')\n",
    "        \n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    \n",
    "    def _datize(time):\n",
    "        if time is None:\n",
    "            return ''\n",
    "\n",
    "        try:\n",
    "            time = pd.Timestamp(time)\n",
    "\n",
    "            if time.tz is None:\n",
    "                return str(time.date())\n",
    "\n",
    "            else:\n",
    "                return str(time.tz_convert('utc').date())\n",
    "            \n",
    "        except:\n",
    "            return ''\n",
    "            \n",
    "\n",
    "    if pubtime is None:\n",
    "        datesrc = 'extractor'\n",
    "        pubtime = _from_extractor(url)\n",
    "\n",
    "        if pubtime is None:\n",
    "            datesrc = 'newsplease'\n",
    "            pubtime = _from_newsplease(url)\n",
    "\n",
    "            if pubtime is None:\n",
    "                datesrc = 'fail'\n",
    "\n",
    "    #return _datize(pubtime)\n",
    "    return _timize(pubtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(urls):\n",
    "    \n",
    "    selected = {}\n",
    "    basedir = os.path.join(os.getcwd(), 'newsdata')\n",
    "    ext = '.json'\n",
    "\n",
    "    for pub, _urls in tqdm(urls.items()):\n",
    "        selected[pub] = set()\n",
    "\n",
    "        for _url in _urls:\n",
    "            hash_url = hashlib.sha1(_url.encode('utf-8')).hexdigest()\n",
    "            \n",
    "            file_in_saved = os.path.join(basedir, 'saved', hash_url[0], hash_url + ext)\n",
    "            file_in_downloaded = os.path.join(basedir, 'downloaded', hash_url + ext)\n",
    "            file_in_trash = os.path.join(basedir, 'trash', hash_url[0], hash_url + ext)\n",
    "\n",
    "            if os.path.isfile(file_in_saved) or os.path.isfile(file_in_downloaded) or os.path.isfile(file_in_trash):\n",
    "                continue\n",
    "                \n",
    "            else:\n",
    "                selected[pub].add(_url)\n",
    "                \n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
